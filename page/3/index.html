<!DOCTYPE html>
<html lang="en">

<head>
  <!-- Website mata -->
<meta charset="UTF-8" />
<meta http-equiv="X-UA-Compatible" content="IE=edge" />
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1" />

<!-- Disable transformation -->
<meta http-equiv="Cache-Control" content="no-transform" />
<meta http-equiv="Cache-Control" content="no-siteapp" />

<meta name="theme-color" content="#f8f5ec" />
<meta name="msapplication-navbutton-color" content="#f8f5ec">
<meta name="apple-mobile-web-app-capable" content="yes">
<meta name="apple-mobile-web-app-status-bar-style" content="#f8f5ec">

<!-- Website description -->


<!-- Website keywords -->




<!-- Website rss -->

<link rel="alternate" href="/atom.xml" title="Draco's Blog" type="application/atom+xml">


<!-- Website favicon -->

<link rel="shortcut icon" type="image/x-icon" href="/favicon.ico?v=3.0.0" />


<!-- Canonical, good for google search engine -->
<link rel="canonical" href="https://stardustorz.github.io/page/3/" />

<!-- Fancybox styling -->

<link rel="stylesheet" type="text/css" href="/lib/fancybox/jquery.fancybox.css" />


<!-- MathJax (LaTeX) support -->


<!-- Theme styling -->
<link rel="stylesheet" type="text/css" href="/css/style.css?v=3.0.0" />

<!-- Analytics and push -->



  



<!-- LeanCloud Counter -->


<script>
  window.config = {"leancloud":{"app_id":null,"app_key":null,"server_url":null,"cdn":null},"toc":true,"fancybox":true,"latex":false};
</script>
  
  <title>Draco&#39;s Blog</title>

<meta name="generator" content="Hexo 6.3.0"></head>

<body>
  <div class="scrollPercentage"></div>
  <div id="mobile-navbar" class="mobile-navbar">
  <div class="mobile-header-logo">
    <a href="/." class="logo">Draco&#39;s Blog</a>
  </div>
  <div class="mobile-navbar-icon">
    <span></span>
    <span></span>
    <span></span>
  </div>
</div>

<nav id="mobile-menu" class="mobile-menu slideout-menu">
  <ul class="mobile-menu-list">
    
    <a href="/">
      <li class="mobile-menu-item">
        
        
        Home              </li>
    </a>
    
    <a href="/archives/">
      <li class="mobile-menu-item">
        
        
        Archives              </li>
    </a>
    
    <a href="/tags/">
      <li class="mobile-menu-item">
        
        
        Tags              </li>
    </a>
    
    <a href="/categories/">
      <li class="mobile-menu-item">
        
        
        Categories              </li>
    </a>
    
    <a href="/links/">
      <li class="mobile-menu-item">
        
        
        Links              </li>
    </a>
    
    <a href="/about/">
      <li class="mobile-menu-item">
        
        
        About              </li>
    </a>
    
  </ul>
</nav>
  <div class="container" id="mobile-panel">
    <header id="header" class="header">
      <div class="logo-wrapper">  
  <a href="/." class="logo">Draco's Blog</a>  
</div>  
  
<nav class="site-navbar">  
    
    <ul id="menu" class="menu">  
        
        <li class="menu-item">  
          <a class="menu-item-link" href="/">  
              
              
              Home  
              
          </a>  
        </li>  
        
        <li class="menu-item">  
          <a class="menu-item-link" href="/archives/">  
              
              
              Archives  
              
          </a>  
        </li>  
        
        <li class="menu-item">  
          <a class="menu-item-link" href="/tags/">  
              
              
              Tags  
              
          </a>  
        </li>  
        
        <li class="menu-item">  
          <a class="menu-item-link" href="/categories/">  
              
              
              Categories  
              
          </a>  
        </li>  
        
        <li class="menu-item">  
          <a class="menu-item-link" href="/links/">  
              
              
              Links  
              
          </a>  
        </li>  
        
        <li class="menu-item">  
          <a class="menu-item-link" href="/about/">  
              
              
              About  
              
          </a>  
        </li>  
        
    </ul>  
    
</nav>  

    </header>
    <main id="main" class="main">
      <div class="content-wrapper">
        <div id="content" class="content">
          <section id="posts" class="posts">
  
  
  
  <article class="post">
  <header class="post-header">
    <h1 class="post-title">
      
      <a class="post-link" href="/2023/10/09/DevOps/Docker%E4%B8%8E%20K8S/"></a>
      
    </h1>

    <div class="post-meta">
      <span class="post-time">
        2023-10-09
      </span>
      
      
      
    </div>
  </header>

  

  <div class="post-content">
    
    
    

    
    <h1 id="Docker"><a href="#Docker" class="headerlink" title="Docker"></a>Docker</h1><p>基础<br>●Docker主要用于开发和运维的协作，可将整个项目的环境，依赖全部打包成镜像<br>●在集群中，使用一个镜像就可以很方便的进行部署<br>●Docker和虚拟机类似，但不需要去模拟硬件，启动会更快<br>○可以理解为一个浓缩版的Linux系统<br>○摒弃了Linux中不需要的很多东西<br>●概念<br>○镜像：镜像就相当于 Java类<br>○容器：容器就相当于Java对象，是一个个小型独立的Linux环境<br>○仓库：仓库是集中存放镜像的地方<br>●镜像可以生成容器实例，同一个镜像可以生成多个同时运行的容器<br>●容器可以启动，关闭，重启等等操作，就相当于一个虚拟机<br>●文档：<a target="_blank" rel="noopener" href="https://yeasy.gitbook.io/docker_practice/">文档-Gitbook</a>  </p>
<p>操作  </p>
<p>安装<br>●Docker有企业版和社区版，使用社区版(DockerCE)即可<br>●具体方法看开头Gitbook文档  </p>
<p>镜像加速<br>●阿里云推出的的Docker Hub镜像站，方便国内用户加速下载<br>●地址：<a target="_blank" rel="noopener" href="https://cr.console.aliyun.com/cn-hangzhou/instances/mirrors">https://cr.console.aliyun.com/</a><br>●获取镜像加速器地址(唯一的)<br>●配置方法在上面的地址<br>○配置文件没有的话就自己创建  </p>
<p>运行hello-world<br>●与编程语言的学习一样，都会有helloworld<br>●使用以下命令运行，如果没有就会去镜像仓库去拉取最新版到本地<br>○docker run hello-world  </p>
<p>底层原理<br>●Docker是一个Client-Server结构的系统<br>○Docker守护进程运行在主机上<br>○通过Socket连接从客户端访问<br>○守护进程从客户端接受命令并管理运行在主机上的容器<br>●Docker比虚拟机更快的原因是它有更少的抽象层，不需要去模拟硬件虚拟化。<br>●Docker直接使用宿主机的引擎和内核，多个容器也是，而虚拟机需要去重新加载多个内核<br>●</p>
<p><img src="https://cdn.nlark.com/yuque/0/2022/png/2145785/1672129612884-e7ec2dc4-181f-408d-8970-89f1d839da94.png?x-oss-process=image%2Fwatermark%2Ctype_d3F5LW1pY3JvaGVp%2Csize_36%2Ctext_QW9tc2ly%2Ccolor_FFFFFF%2Cshadow_50%2Ct_80%2Cg_se%2Cx_10%2Cy_10%2Fformat%2Cwebp" alt="image.png"></p>
<p>常用命令  </p>
<p>帮助命令<br>●docker version—版本信息<br>●docker info —全面的信息描述<br>●docker —help —帮助命令  </p>
<p>镜像命令<br>●docker images —-列出本地的镜像<br>○列出本地所有镜像 - docker images -a<br>■所有镜像(含中间镜像层)<br>○列出本地镜像的ID —docker images -qa<br>○镜像详细信息— docker images —digests<br>●docker search [option] 镜像名 —hub上搜索镜像<br>○罗列出点赞数为30以上的镜像—docker search -s 30 tomcat<br>●docker pull 镜像名[:tag]—丛hub拉取镜像到本地<br>○不写tag就是最新版<br>○arm架构的机器就需要加特定标签  </p>
<ul>
<li>docker rmi 镜像名[:tag]  <ul>
<li>删除单个—-docker rmi -f 镜像<br>○ 删除多个—-docker rmi -f 镜像1 镜像2<br>○ 删除全部—-docker rmi -f$(docker images -qa )<br>●docker system df<br>○查看镜像文件等占用的空间  </li>
</ul>
</li>
</ul>
<p>容器命令<br>●启动<br>○docker run -it 镜像ID<br>○docker run -it —name=”别名” 镜像ID<br>○ -it 代表启动交互式<br>○-d代表守护式交互，不会进入容器内去操作，会在后台挂着<br>○docker run -it ubuntu /bin/bash<br>●列出正在运行的全部容器<br>○docker ps<br>○正在运行/历史运行过的 docker ps -a<br>○上5次运行过的容器 docker ps -n 5<br>○列出刚刚运行过的容器 docker ps -l<br>○列出刚刚运行过的容器ID： docker ps -ql<br>●退出容器<br>○ctrl+p+q 容器不停止退出<br>○exit命令 容器停止并退出<br>●启动容器<br>○docker start 容器ID —用ps命令获取ID<br>●重启容器<br>○docker restart 容器ID<br>●停止容器<br>○docker stop 容器ID —温柔停止<br>○docker kill 容器ID —粗暴停止<br>●删除已停止的容器<br>○docker rm 容器ID<br>●查看容器内部细节<br>○docker inspect 容器ID<br>●进入正在运行的容器<br>○docker attach 容器ID<br>○docker exec 容器ID<br>■会有新的进程、用的多<br>■退出不会导致容器的停止<br>●拷贝docker内的文件到宿主机<br>○docker cp 容器ID:容器内路径以及文件名 宿主机路径<br>●导出所有<br>○docker export 容器ID&gt;xxx.tar<br>○cat xxx.tar|docker import - xxx:3.7将打的包换成镜像<br>●查看容器日志<br>○docker logs 容器ID  </p>
<p>镜像发布  </p>
<p>镜像原理<br>●Docker的镜像是一个分层的结构<br>●从底层一层层的向上，像一个画卷<br>●Docker使用的UnionFS 联合文件系统<br>●比如我拉一个Tomcat镜像，里面就有Linux内核，JDK运行环境，Tomcat等等<br>○我就可以使用Linux内核和JDK制作一个镜像<br>○然后使用这个基础镜像+不同版本的Tomcat进行操作  </p>
<p>创建<br>●Docker拉取的是精简的镜像，没有用的东西都会丢掉，比如vim<br>●制作一个带有vim的centos镜像<br>○运行一个centos容器，使用yum安装vim<br>○使用下述命令进行创建<br>○docker commit -m=”add vim” -a=”aomsir” 容器ID 新镜像名字  </p>
<p>发布  </p>
<p>阿里云<br>●这里使用的Hub是使用的阿里云的Hub<br>○<a target="_blank" rel="noopener" href="https://cr.console.aliyun.com/cn-hangzhou/instances">阿里云容器镜像服务</a><br>●docker tag 8ecc2667bae7 registry.cn-hangzhou.aliyuncs.com/aomsir/ubuntu_vim:1.0-镜像ID<br>●docker push registry.cn-hangzhou.aliyuncs.com/aomsir/ubuntu_vim:1.0 - 推送<br>●docker pull registry.cn-hangzhou.aliyuncs.com/aomsir/ubuntu_vim:1.0  </p>
<p>本地私有库<br>●拉取库：docker pull registry<br>●运行：docker run -d -p 5000:5000 -v /aomsir/myregistry/:/tmp/registry —privileged=true registry<br>●打包镜像：docker tag redis:latest 192.168.1.113:5000/redis:latest<br>●修改权限-vim /etc/docker/daemon.json，将其支持http<br>●push推送到私有库：docker push 192.168.1.113:5000/redis:1.0<br>●查看库中的镜像：curl -XGET <a target="_blank" rel="noopener" href="http://192.168.1.113:5000/v2/_catalog">http://192.168.1.113:5000/v2/_catalog</a>  </p>
<p>容器数据卷<br>●容器数据卷的作用是用于将容器内的数据进行映射，进行持久化到本地主机目录<br>●命令docker run -it —privileged=true -v /宿主机绝对路径:/容器内目录 镜像名<br>○-v 代表 volumes<br>●宿主机目录和容器目录会双向同步<br>●容器可实现可读可写，可写等操作，一般都是可读可写<br>●卷的继承和共享<br>○容器1完成和宿主机的映射<br>○容器2继承容器1的卷规则<br>●应用场景<br>○MySQL容器重启以后数据都丢失，有了容器卷就不会<br>○当我新运行一个容器，就可以使用原来的数据直接跑  </p>
<p>常用应用<br>●拉取镜像的时候一定要去Docker Hub看看有没对应自己芯片架构的镜像<br>●启动服务的时候去看一下宿主机有没有安装对应的服务<br>●对应服务在宿主机有安装的话就给Docke的r容器换个端口  </p>
<p>Tomcat<br>●最新版Tomcat安装启动后没有首页<br>○进tomcat将webapps删除<br>○将webapps.dist改名为webapps<br>●docker run -d -p 8080:8080 -name tomcat1 /bin/bash  </p>
<p>MySQL<br>●使用oracle是因为有arm架构<br>●操作<br>○创建容器<br>○/root/aomsir/mysql/conf目录下新建my.cnf文件<br>○添加下面的内容,因为容器里的mysql没有utf8编码<br>●数据备份<br>○可以使用容器卷直接转移<br>○也可以使用dump命令将SQL文件导出  </p>
<p>Redis<br>●要去官网下载对应版本的Redis配置文件<br>●创建容器<br>○将redis.conf文件放一个在宿主机的数据卷目录  </p>
<p>Nginx<br>●如下  </p>
<p>Docker网络<br>●Docker网络可以 和 主机和虚拟机的网络相结合理解<br>●可用于容器间的通信<br>○用于编排，比如a容器的接口服务，访问b容器的redis<br>●</p>
<p>简介</p>
<p>网络模式</p>
<p>为每个容器分配,设置IP等,并将容器连接到一个DOCKERO</p>
<p>BRIDGE</p>
<p>虚拟网桥,默认为该模式</p>
<p>容器将不会虚拟出自己的网卡,配置自己的IP等,而是使用</p>
<p>HOST</p>
<p>宿主机的IP和端口</p>
<p>容器有独立的NETWORK NAMESPACE,但:</p>
<p>.但并没有对其进行任</p>
<p>NONE</p>
<p>何网络设置,如分配VETHPAIR和网桥连接,IP等</p>
<p>新创建的容器不会创建自己的网桥和配置自己的IP,而是和</p>
<p>CONTAINER</p>
<p>一个指定的容器共享IP和端口范围</p>
<p><img src="https://cdn.nlark.com/yuque/0/2022/png/2145785/1672131504934-9089d9fe-9263-44b6-a069-e6278cdfe2dd.png?x-oss-process=image%2Fwatermark%2Ctype_d3F5LW1pY3JvaGVp%2Csize_34%2Ctext_QW9tc2ly%2Ccolor_FFFFFF%2Cshadow_50%2Ct_80%2Cg_se%2Cx_10%2Cy_10%2Fformat%2Cwebp%2Fresize%2Cw_1198%2Climit_0" alt="image.png"></p>
<p>基础<br>●Docker启动以后在宿主机上会有一个docker0的虚拟网桥<br>●docker会有3大网络模式  </p>
<p>网络模式<br>●bridge<br>○Docker服务启动以后，会在宿主机上创建一块虚拟网卡，名为docker0(桥接模式)<br>■创建容器不指定网卡就默认使用docker0这块虚拟网卡<br>■启动一个默认服务时，容器内会生成一个eth0接口，docker0网卡会虚拟出一个vethxxx接口进行连接<br>○</p>
<p>DOCKER CONTAINER</p>
<p>DOCKER CONTAINER</p>
<p>DOCKER CONTAINER</p>
<p>ETHO</p>
<p>ETHO</p>
<p>ETHO</p>
<p>VETH1</p>
<p>VETH3</p>
<p>VETH2</p>
<p>DOCKERO</p>
<p>ETHO(ENS33)</p>
<p><img src="https://cdn.nlark.com/yuque/0/2023/png/2145785/1677821386653-4fe071e0-655d-4265-816e-354aba01a4a4.png?x-oss-process=image%2Fwatermark%2Ctype_d3F5LW1pY3JvaGVp%2Csize_62%2Ctext_QW9tc2ly%2Ccolor_FFFFFF%2Cshadow_50%2Ct_80%2Cg_se%2Cx_10%2Cy_10%2Fformat%2Cwebp" alt="image.png"></p>
<p>●host<br>○这个是主机模式，共用宿主机的IP和端口，不需要端口映射<br>○假如说宿主机啥服务都没有，使用host服务开一个tomcat，直接用宿主机ip➕端口即可访问<br>○不推荐这么使用<br>●none<br>○就是没有网络设置，不推荐这么使用<br>●container<br>○容器模式，a容器去公用b容器的网络设置  </p>
<p>自定义网桥<br>●docker0网卡很方便，但也有很多的弊端<br>○使用其的每个容器的IP都是动态的，每次重启都会变化<br>○容器间的通信只可以通过IP，而不可以通过hostname<br>○容器多了会降低网络传递的效率<br>●因为有弊端，所以可以自定义网桥<br>●自定义网桥操作<br>○docker nerwork create -d bridge(默认有的,可不写) 网络名称 - 创建网络<br>○自定义网段<br>■docker network create —subnet=172.18.0.0/18 my_net<br>■创建容器的时候指定容器的IP —net my_net —ip 172.18.0.2 \<br>○docker nwtwork ls - 查看现有网络<br>○docker network inspect 网络名称 - 查看某个网络的详细信息<br>○docker network rm 网络名称 - 删除某个网络<br>○使用自定义网络<br>■docker run -d —network 网络名称 - 创建容器的时候指定<br>■docker network connect 网络名称 容器名称 - 已创建的容器加入指定网络<br>●将容器加入到新建网桥中(未创建/创建容器)<br>○把启动容器的命令重新跑一遍，把network加上<br>●注意：任何模式都不可跨桥通信  </p>
<p>Dockerfile  </p>
<p>理论学习<br>●重点中的重点，学好以后可以把所有的项目使用Dockerfile进行构建<br>●Dockerfile可以认为是Docker镜像的描述文件，是由一系列命令和参数构成的脚本。主要作用是用来构建Docker镜像的构建文件<br>●官方的一个个镜像无法满足我们实际的业务需求<br>●作用：可以通过Dockerfile构建自己的镜像文件<br>●步骤<br>○<a target="_blank" rel="noopener" href="https://docs.docker.com/engine/reference/builder/">官方文档</a><br>○编写dockerfile文件，如下demo<br>■注意每一行是一条完整指令<br>■第一行必须是FROM命令<br>■RUN命令后面写法很多，参照官网<br>■ADD命令与COPY命令用法一致<br>■COPY只能复制，ADD后面还可以写url，会自动去这个url下载<br>■ENTRYPOINT&amp;CMD<br>●都是用于指定容器启动时默认的执行命令(思考为啥run redis，Redis就会启动)<br>●使用语法一致，CMD如果有多条，只有最后一个有效<br>●CMD命令可以使用JSON数组的格式<br>●两者区别在于运行容器时覆盖操作 - [参考redis容器的创建]<br>○docker run 镜像:版本号 覆盖的命令 ls /<br>○docker run —entrypoint=”要覆盖的指令” 镜像:版本号 传递的参数<br>●通常EHTRYPOINT与CMD搭配进行使用<br>○使用 docker build -t xx:1.0 .(指定的dockerfile所在的位置)进行构建<br>■.代表当前目录，保证Dockerfile文件所在目录下没有无关文件，因为会一起打进去<br>○注意<br>■RUN命令是构建镜像的时候使用的，CMD是启动容器时默认执行的  </p>
<p>实战操作<br>●发布一个SpringBoot项目<br>●操作<br>○打jar包，同目录下写Dockerfile文件<br>○然后进行构建启动[需要的中间件等提前准备好]  </p>
<p>Docker-Compose  </p>
<p>理论学习<br>●现有Docker在进行项目部署的时候还是有很多的问题<br>●完成一个项目肯定会用到N个容器去进行业务的开发，用到后就一定会产生一些依赖(比如容器的启动时间)<br>●新需求：把服务器A的容器迁移至服务器B，很麻烦。因为部署的时候没有站在项目的角度<br>●容器的编排就显得至关重要，所以就需要使用Docker-Compose<br>●DockerCompose是Docker官方的项目<br>○Compose负责实现对Docker实现快速编排的工具<br>○一个项目一个compose文件 - docker-compose.yml<br>○project与service<br>●Compose<br>○只有Linux上面安装Docker后没有默认安装DockerCompose的<br>○Linux平台将docker-compose文件下载放到/usr/local/bin下面，赋予权限即可  </p>
<p>操作<br>●步骤<br>○编写docker-compose.yml配置文件<br>○在配置文件所在目录下执行 docker-compose up -d<br>○使用depends_on解决容器的编排<br>●注意<br>○docker-compose up用一次就会对配置有所缓存，可以使用对应的down进行操作<br>○docker-compose的命令有很多的操作，比如只启动一个服务，停一个服务等等<br>■用到的时候去看文档  </p>
<p>YAML</p>
<p>1</p>
<p>2</p>
<p>3</p>
<p>4</p>
<p>5</p>
<p>6</p>
<p>7</p>
<p>8</p>
<p>9</p>
<p>10</p>
<p>11</p>
<p>12</p>
<p>13</p>
<p>14</p>
<p>15</p>
<p>16</p>
<p>17</p>
<p>18</p>
<p>19</p>
<p>20</p>
<p>21</p>
<p>22</p>
<p>23</p>
<p>24</p>
<p>25</p>
<p>26</p>
<p>27</p>
<p>28</p>
<p>29</p>
<p>30</p>
<p>31</p>
<p>32</p>
<p>version: ‘3.8’ # docker-compose的版本号,要看具体的docker引擎</p>
<p>services:</p>
<p>tomcat:</p>
<p>image: tomcat:8.0 # 代表使用的是什么镜像</p>
<p>ports: # 代表容器与宿主机之间的映射</p>
<ul>
<li>‘8080:8080’</li>
</ul>
<p>redis:</p>
<p>image: redis:6.5.0</p>
<p>container_name: redis # 给容器起别名,推荐使用默认的</p>
<p>ports:</p>
<ul>
<li>‘6379:6379’</li>
</ul>
<p>networks:</p>
<ul>
<li>ems</li>
</ul>
<p>volumes:</p>
<ul>
<li>/root/redis/data/:/data</li>
</ul>
<p>command: redis-server</p>
<p>mysql:</p>
<p>image: mysql:8.0</p>
<p>ports:</p>
<ul>
<li>‘3306:3306’</li>
</ul>
<p>environment: # 代表给当前容器启动制定环境</p>
<ul>
<li>‘MYSQL_ROOT_PASSWORD=root’</li>
</ul>
<p>volumes:</p>
<ul>
<li>/root/mysqldata1:/var/lib/mysql</li>
</ul>
<p>depends_on:</p>
<p>tomcat # 依赖于tomcat,需要让其先启动</p>
<p>networks:</p>
<p>ems:</p>
<p>实战操作<br>●Docker-Compose基于Dockerfile去构建镜像<br>●需要使用Compose就去看人家使用镜像是怎么操作的<br>●操作<br>○使用build命令  </p>
<p>YAML</p>
<p>1</p>
<p>2</p>
<p>3</p>
<p>4</p>
<p>5</p>
<p>6</p>
<p>7</p>
<p>8</p>
<p>9</p>
<p>10</p>
<p>11</p>
<p>12</p>
<p>13</p>
<p>14</p>
<p>15</p>
<p>16</p>
<p>17</p>
<p>18</p>
<p>19</p>
<p>20</p>
<p>21</p>
<p>22</p>
<p>23</p>
<p>24</p>
<p>25</p>
<p>26</p>
<p>version: ‘3.8’</p>
<p>services:</p>
<p>tomcat:</p>
<p>image: tomcat:8.0</p>
<p>ports:</p>
<ul>
<li>‘8080:8080’</li>
</ul>
<p>networks:</p>
<ul>
<li>dangdang</li>
</ul>
<p>apps:</p>
<p>build:</p>
<p>context: ./ # dockerfile的上下文目录</p>
<p>dockerfile: Dockerfile # 文件名</p>
<p>ports:</p>
<ul>
<li>‘80:7891’</li>
</ul>
<p>command: [“test.jar”]</p>
<p>env_file:</p>
<p>./.env # 将环境文件写到.env中</p>
<p>networks:</p>
<ul>
<li>dangdang</li>
</ul>
<p>restart: always</p>
<p>networks:</p>
<p>dangdang: # 声明网桥</p>
<p>经验之谈<br>●DockerDesktop<br>○macOS上的Docker Desktop很重，占用大打开慢，可以考虑使用OrbStack进行替代<br>○注意：Docker Desktop和Orbstack同时安装的情况下，会有两套Docker Engine、Server、CLI等。容器是隔离的，注意切换上下文<br>○docker context use orbstack/docker context use desktop-linux<br>●避免镜像推不上DockerHub ，使用docker login</p>
<h3 id="1-docker的工作原理是什么，讲一下"><a href="#1-docker的工作原理是什么，讲一下" class="headerlink" title="1 docker的工作原理是什么，讲一下"></a>1 docker的工作原理是什么，讲一下</h3><p>docker是一个Client-Server结构的系统，docker<a target="_blank" rel="noopener" href="https://www.zhihu.com/search?q=%E5%AE%88%E6%8A%A4%E8%BF%9B%E7%A8%8B&amp;search_source=Entity&amp;hybrid_search_source=Entity&amp;hybrid_search_extra=%7B%22sourceType%22%3A%22answer%22%2C%22sourceId%22%3A2708298459%7D">守护进程</a>运行在宿主机上，守护进程从<a target="_blank" rel="noopener" href="https://www.zhihu.com/search?q=%E5%AE%A2%E6%88%B7%E7%AB%AF&amp;search_source=Entity&amp;hybrid_search_source=Entity&amp;hybrid_search_extra=%7B%22sourceType%22%3A%22answer%22%2C%22sourceId%22%3A2708298459%7D">客户端</a>接受命令并管理运行在主机上的容器，容器是一个运行时环境，这就是我们说的集装箱。</p>
<h3 id="2-docker的组成包含哪几大部分"><a href="#2-docker的组成包含哪几大部分" class="headerlink" title="2 docker的组成包含哪几大部分"></a>2 docker的组成包含哪几大部分</h3><p>一个完整的docker有以下几个部分组成： 1、docker client，客户端，为用户提供一系列可执行命令，用户用这些命令实现跟 docker daemon 交互；</p>
<p>2、docker daemon，守护进程，一般在宿主主机后台运行，等待接收来自客户端的请求消息；</p>
<p>3、docker image，镜像，镜像run之后就生成为docker容器；</p>
<p>4、docker container，容器，一个系统级别的服务，拥有自己的ip和系统目录结构；运行容器前需要本地存在对应的镜像，如果本地不存在该镜像则就去镜像仓库下载。</p>
<p>docker 使用客户端-服务器 (C/S) 架构模式，使用远程api来管理和创建docker容器。docker 容器通过 docker 镜像来创建。容器与镜像的关系类似于面向对象编程中的对象与类。</p>
<h3 id="3-docker与传统虚拟机的区别什么？"><a href="#3-docker与传统虚拟机的区别什么？" class="headerlink" title="3 docker与传统虚拟机的区别什么？"></a>3 docker与传统<a target="_blank" rel="noopener" href="https://www.zhihu.com/search?q=%E8%99%9A%E6%8B%9F%E6%9C%BA&amp;search_source=Entity&amp;hybrid_search_source=Entity&amp;hybrid_search_extra=%7B%22sourceType%22%3A%22answer%22%2C%22sourceId%22%3A2708298459%7D">虚拟机</a>的区别什么？</h3><p>1、传统虚拟机是需要安装整个<a target="_blank" rel="noopener" href="https://www.zhihu.com/search?q=%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F&amp;search_source=Entity&amp;hybrid_search_source=Entity&amp;hybrid_search_extra=%7B%22sourceType%22%3A%22answer%22%2C%22sourceId%22%3A2708298459%7D">操作系统</a>的，然后再在上面安装业务应用，启动应用，通常需要几分钟去启动应用，而docker是直接使用镜像来运行业务容器的，其容器启动属于秒级别；</p>
<p>2、Docker需要的资源更少，Docker在操作系统级别进行虚拟化，Docker容器和内核交互，几乎没有性能损耗，而虚拟机运行着整个操作系统，占用物理机的资源就比较多;</p>
<p>3、Docker更轻量，Docker的架构可以共用一个内核与共享应用程序库，所占内存极小;同样的硬件环境，Docker运行的镜像数远多于虚拟机数量，对系统的利用率非常高;</p>
<p>4、与虚拟机相比，Docker隔离性更弱，Docker属于进程之间的隔离，虚拟机可实现系统级别隔离;</p>
<p>5、Docker的安全性也更弱，Docker的租户root和宿主机root相同，一旦容器内的用户从普通用户权限提升为<a target="_blank" rel="noopener" href="https://www.zhihu.com/search?q=root%E6%9D%83%E9%99%90&amp;search_source=Entity&amp;hybrid_search_source=Entity&amp;hybrid_search_extra=%7B%22sourceType%22%3A%22answer%22%2C%22sourceId%22%3A2708298459%7D">root权限</a>，它就直接具备了宿主机的root权限，进而可进行无限制的操作。虚拟机租户root权限和宿主机的root虚拟机权限是分离的，并且虚拟机利用如Intel的VT-d和VT-x的ring-1硬件隔离技术，这种技术可以防止虚拟机突破和彼此交互，而容器至今还没有任何形式的硬件隔离;</p>
<p>6、Docker的集中化管理工具还不算成熟，各种<a target="_blank" rel="noopener" href="https://www.zhihu.com/search?q=%E8%99%9A%E6%8B%9F%E5%8C%96%E6%8A%80%E6%9C%AF&amp;search_source=Entity&amp;hybrid_search_source=Entity&amp;hybrid_search_extra=%7B%22sourceType%22%3A%22answer%22%2C%22sourceId%22%3A2708298459%7D">虚拟化技术</a>都有成熟的管理工具，比如：VMware vCenter提供完备的虚拟机管理能力;</p>
<p>7、Docker对业务的高可用支持是通过快速重新部署实现的，虚拟化具备负载均衡，高可用、容错、迁移和数据保护等经过生产实践检验的成熟保障机制，Vmware可承诺虚拟机99.999%高可用，保证业务连续性;</p>
<p>8、虚拟化创建是分钟级别的，Docker容器创建是秒级别的，Docker的快速迭代性，决定了无论是开发、测试、部署都可以节省大量时间;</p>
<p>9、虚拟机可以通过镜像实现环境交付的一致性，但镜像分发无法体系化，Docker在Dockerfile中记录了容器构建过程，可在集群中实现快速分发和快速部署。</p>
<h3 id="4-docker技术的三大核心概念是什么？"><a href="#4-docker技术的三大核心概念是什么？" class="headerlink" title="4 docker技术的三大核心概念是什么？"></a>4 docker技术的三大核心概念是什么？</h3><p>镜像：镜像是一种轻量级、可执行的独立软件包，它包含运行某个软件所需的所有内容，我们把应用程序和配置依赖打包好形成一个可交付的运行环境(包括代码、运行时需要的库、环境变量和配置文件等)，这个打包好的运行环境就是image镜像文件。</p>
<p>容器：容器是基于镜像创建的，是镜像运行起来之后的一个实例，容器才是真正运行业务程序的地方。如果把镜像比作程序里面的类，那么容器就是对象。</p>
<p>镜像仓库：存放镜像的地方，研发工程师打包好镜像之后需要把镜像上传到镜像仓库中去，然后就可以运行有仓库权限的人拉取镜像来运行容器了。</p>
<h3 id="5-centos镜像几个G，但是docker-centos镜像才几百兆，这是为什么？"><a href="#5-centos镜像几个G，但是docker-centos镜像才几百兆，这是为什么？" class="headerlink" title="5 centos镜像几个G，但是docker centos镜像才几百兆，这是为什么？"></a>5 centos镜像几个G，但是docker centos镜像才几百兆，这是为什么？</h3><p>一个完整的Linux操作系统包含Linux内核和rootfs根文件系统，即我们熟悉的<code>/dev</code>、<code>/proc/</code>、<code>/bin</code>等目录。我们平时看到的CentOS除了rootfs，还会选装很多软件，服务，图形桌面等，所以CentOS镜像有好几个G也不足为奇。</p>
<p>而对于容器镜像而言，所有容器都是共享宿主机的Linux 内核的，而对于docker镜像而言，docker镜像只需要提供一个很小的rootfs即可，只需要包含最基本的命令，工具，程序库即可，所有docker镜像才会这么小。</p>
<h3 id="6-讲一下镜像的分层结构以及为什么要使用镜像的分层结构？"><a href="#6-讲一下镜像的分层结构以及为什么要使用镜像的分层结构？" class="headerlink" title="6 讲一下镜像的分层结构以及为什么要使用镜像的分层结构？"></a>6 讲一下镜像的分层结构以及为什么要使用镜像的分层结构？</h3><p>一个新的镜像其实是从 base 镜像一层一层叠加生成的。每安装一个软件，dockerfile中使用<code>RUN</code>指令，就会在现有镜像的基础上增加一层，这样一层一层的叠加最后构成整个镜像。所以我们<code>docker pull</code>拉取一个镜像的时候会看到docker是一层层拉去的。</p>
<p>分层机构最大的一个好处就是 ： 共享资源。比如：有多个镜像都从相同的 base 镜像构建而来，那么 Docker Host 只需在磁盘上保存一份 base 镜像；同时内存中也只需加载一份 base 镜像，就可以为所有容器服务了。而且镜像的每一层都可以被共享。</p>
<h3 id="7-讲一下容器的copy-on-write特性，修改容器里面的内容会修改镜像吗？"><a href="#7-讲一下容器的copy-on-write特性，修改容器里面的内容会修改镜像吗？" class="headerlink" title="7 讲一下容器的copy-on-write特性，修改容器里面的内容会修改镜像吗？"></a>7 讲一下容器的copy-on-write特性，修改容器里面的内容会修改镜像吗？</h3><p>我们知道，镜像是分层的，镜像的每一层都可以被共享，同时，镜像是只读的。当一个容器启动时，一个新的可写层被加载到镜像的顶部，这一层通常被称作“容器层”，“容器层”之下的都叫“镜像层”。</p>
<p>所有对容器的改动 - 无论添加、删除、还是修改文件，都只会发生在容器层中，因为只有容器层是可写的，容器层下面的所有镜像层都是只读的。镜像层数量可能会很多，所有镜像层会联合在一起组成一个统一的文件系统。如果不同层中有一个相同路径的文件，比如<code>/a</code>，上层的 <code>/a</code> 会覆盖下层的<code>/a</code>，也就是说用户只能访问到上层中的文件 <code>/a</code>。在容器层中，用户看到的是一个叠加之后的文件系统。</p>
<p>添加文件时：在容器中创建文件时，新文件被添加到容器层中。</p>
<p>读取文件：在容器中读取某个文件时，Docker 会从上往下依次在各镜像层中查找此文件。一旦找到，立即将其复制到容器层，然后打开并读入内存。</p>
<p>修改文件：在容器中修改已存在的文件时，Docker 会从上往下依次在各镜像层中查找此文件。一旦找到，立即将其复制到容器层，然后修改之。</p>
<p>删除文件：在容器中删除文件时，Docker 也是从上往下依次在镜像层中查找此文件。找到后，会在容器层中记录下此删除操作。</p>
<p>只有当需要修改时才复制一份数据，这种特性被称作 Copy-on-Write。可见，容器层保存的是镜像变化的部分，不会对镜像本身进行任何修改。</p>
<h3 id="8-简单描述一下Dockerfile的整个构建镜像过程"><a href="#8-简单描述一下Dockerfile的整个构建镜像过程" class="headerlink" title="8 简单描述一下Dockerfile的整个构建镜像过程"></a>8 简单描述一下Dockerfile的整个构建镜像过程</h3><p>1、首先，创建一个目录用于存放应用程序以及构建过程中使用到的各个文件等；</p>
<p>2、然后，在这个目录下创建一个Dockerfile文件，一般建议Dockerfile的<a target="_blank" rel="noopener" href="https://www.zhihu.com/search?q=%E6%96%87%E4%BB%B6%E5%90%8D&amp;search_source=Entity&amp;hybrid_search_source=Entity&amp;hybrid_search_extra=%7B%22sourceType%22%3A%22answer%22%2C%22sourceId%22%3A2708298459%7D">文件名</a>就是Dockerfile；</p>
<p>3、编写Dockerfile文件，编写指令，如，使用<code>FORM指</code>令指定基础镜像，<code>COPY</code>指令复制文件，<code>RUN</code>指令指定要运行的命令，<code>ENV</code>设置环境变量，<code>EXPOSE</code>指定容器要暴露的端口，<code>WORKDIR</code>设置当前工作目录，<code>CMD</code>容器启动时运行命令，等等指令构建镜像；</p>
<p>4、Dockerfile编写完成就可以构建镜像了，使用<code>docker build -t 镜像名:tag .</code>命令来构建镜像，最后一个点是表示当前目录，docker会默认寻找当前目录下的Dockerfile文件来构建镜像，如果不使用默认，可以使用<code>-f</code>参数来指定dockerfile文件，如：<code>docker build -t 镜像名:tag -f /xx/xxx/Dockerfile</code>；</p>
<p>5、使用<code>docker build</code>命令构建之后，docker就会将当前目录下所有的文件发送给docker daemon，顺序执行Dockerfile文件里的指令，在这过程中会生成临时容器，在临时容器里面安装RUN指定的命令，安装成功后，docker底层会使用类似于<code>docker commit</code>命令来将容器保存为镜像，然后删除临时容器，以此类推，一层层的构建镜像，运行临时容器安装软件，直到最后的镜像构建成功。</p>
<h3 id="9-Dockerfile构建镜像出现异常，如何排查？"><a href="#9-Dockerfile构建镜像出现异常，如何排查？" class="headerlink" title="9 Dockerfile构建镜像出现异常，如何排查？"></a>9 Dockerfile构建镜像出现异常，如何排查？</h3><p>首先，Dockerfile是一层一层的构建镜像，期间会产生一个或多个临时容器，构建过程中其实就是在临时容器里面安装应用，如果因为临时容器安装应用出现异常导致镜像构建失败，这时容器虽然被清理掉了，但是期间构建的中间镜像还在，那么我们可以根据异常时上一层已经构建好的临时镜像，将临时镜像运行为容器，然后在容器里面运行安装命令来定位具体的异常。</p>
<h3 id="10-Dockerfile的基本指令有哪些？"><a href="#10-Dockerfile的基本指令有哪些？" class="headerlink" title="10 Dockerfile的基本指令有哪些？"></a>10 Dockerfile的基本指令有哪些？</h3><p><code>FROM</code> 指定基础镜像（必须为第一个指令，因为需要指定使用哪个基础镜像来构建镜像）；</p>
<p><code>MAINTAINER</code> 设置镜像作者相关信息，如作者名字，日期，邮件，联系方式等；</p>
<p><code>COPY</code> 复制文件到镜像；</p>
<p><code>ADD</code> 复制文件到镜像（<code>ADD</code>与<code>COPY</code>的区别在于，<code>ADD</code>会自动解压tar、zip、tgz、xz等归档文件，而<code>COPY</code>不会，同时<code>ADD</code>指令还可以接一个url下载文件地址，一般建议使用COPY复制文件即可，文件在宿主机上是什么样子复制到镜像里面就是什么样子这样比较好）；</p>
<p><code>ENV</code> 设置环境变量；</p>
<p><code>EXPOSE</code> 暴露容器进程的端口，仅仅是提示别人容器使用的哪个端口，没有过多作用；</p>
<p><code>VOLUME</code> 数据卷持久化，挂载一个目录；</p>
<p><code>WORKDIR</code> 设置工作目录，如果目录不在，则会自动创建目录；</p>
<p><code>RUN</code>在容器中运行命令，<code>RUN</code>指令会创建新的镜像层，<code>RUN</code>指令经常被用于安装软件包；</p>
<p><code>CMD</code> 指定容器启动时默认运行哪些命令，如果有多个<code>CMD</code>，则只有最后一个生效，另外，<code>CMD</code>指令可以被<code>docker run</code>之后的参数替换；</p>
<p><code>ENTRYOINT</code> 指定容器启动时运行哪些命令，如果有多个<code>ENTRYOINT</code>，则只有最后一个生效，另外，如果Dockerfile中同时存在<code>CMD</code>和<code>ENTRYOINT</code>，那么<code>CMD</code>或<code>docker run</code>之后的参数将被当做参数传递给<code>ENTRYOINT</code>；</p>
<h3 id="11-如何进入容器？使用哪个命令"><a href="#11-如何进入容器？使用哪个命令" class="headerlink" title="11 如何进入容器？使用哪个命令"></a>11 如何进入容器？使用哪个命令</h3><p>进入容器有两种方法：<code>docker attach</code>、<code>docker exec</code>；</p>
<p><code>docker attach</code>命令是attach到容器启动命令的终端，<code>docker exec</code>是另外在容器里面启动一个TTY终端。</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">docker run -d centos /bin/bash -c <span class="string">&quot;while true;do sleep 2;echo I_am_a_container;done&quot;</span></span><br><span class="line">3274412d88ca4f1d1292f6d28d46f39c14c733da5a4085c11c6a854d30d1cde0</span><br><span class="line">docker attach 3274412d88ca4f                        <span class="comment">#attach进入容器</span></span><br><span class="line">Ctrl + c  退出，Ctrl + c会直接关闭容器终端，这样容器没有进程一直在前台运行就会死掉了</span><br><span class="line">Ctrl + pq 退出（不会关闭容器终端停止容器，仅退出）</span><br><span class="line"></span><br><span class="line">docker <span class="built_in">exec</span> -it 3274412d88ca /bin/bash              <span class="comment">#exec进入容器   </span></span><br><span class="line">[root@3274412d88ca /]<span class="comment"># ps -ef                       #进入到容器了开启了一个bash进程</span></span><br><span class="line">UID         PID   PPID  C STIME TTY          TIME CMD</span><br><span class="line">root          1      0  0 05:31 ?        00:00:01 /bin/bash -c <span class="keyword">while</span> <span class="literal">true</span>;<span class="keyword">do</span> <span class="built_in">sleep</span> 2;<span class="built_in">echo</span> I_am_a_container;<span class="keyword">done</span></span><br><span class="line">root        306      0  1 05:41 pts/0    00:00:00 /bin/bash</span><br><span class="line">root        322      1  0 05:41 ?        00:00:00 /usr/bin/coreutils --coreutils-prog-shebang=<span class="built_in">sleep</span> /usr/bin/sleep 2</span><br><span class="line">root        323    306  0 05:41 pts/0    00:00:00 ps -ef</span><br><span class="line">[root@3274412d88ca /]<span class="comment">#exit                          #退出容器，仅退出我们自己的bash窗口</span></span><br></pre></td></tr></table></figure>
<p>小结：attach是直接进入容器启动命令的终端，不会启动新的进程；exec则是在容器里面打开新的终端，会启动新的进程；一般建议已经exec进入容器。</p>
<h3 id="12-什么是k8s？说出你的理解"><a href="#12-什么是k8s？说出你的理解" class="headerlink" title="12 什么是k8s？说出你的理解"></a>12 什么是k8s？说出你的理解</h3><p>K8s是kubernetes的简称，其本质是一个开源的容器编排系统，主要用于管理容器化的应用，其目标是让部署容器化的应用简单并且高效（powerful）,Kubernetes提供了应用部署，规划，更新，维护的一种机制。</p>
<p>说简单点：k8s就是一个编排容器的系统，一个可以管理容器应用全生命周期的工具，从创建应用，应用的部署，应用提供服务，扩容缩容应用，应用更新，都非常的方便，而且还可以做到故障自愈，所以，k8s是一个非常强大的容器编排系统。</p>
<h3 id="13-k8s的组件有哪些，作用分别是什么？"><a href="#13-k8s的组件有哪些，作用分别是什么？" class="headerlink" title="13 k8s的组件有哪些，作用分别是什么？"></a>13 k8s的组件有哪些，作用分别是什么？</h3><p>k8s主要由master节点和node节点构成。master节点负责管理集群，node节点是容器应用真正运行的地方。 master节点包含的组件有：kube-api-server、kube-controller-manager、kube-scheduler、etcd。 node节点包含的组件有：kubelet、kube-proxy、container-runtime。</p>
<p>kube-api-server：以下简称api-server，api-server是k8s最重要的核心组件之一，它是k8s集群管理的统一访问入口，提供了RESTful API接口, 实现了认证、授权和准入控制等安全功能；api-server还是其他组件之间的数据交互和通信的枢纽，其他组件彼此之间并不会直接通信，其他组件对资源对象的增、删、改、查和监听操作都是交由api-server处理后，api-server再提交给etcd<a target="_blank" rel="noopener" href="https://www.zhihu.com/search?q=%E6%95%B0%E6%8D%AE%E5%BA%93&amp;search_source=Entity&amp;hybrid_search_source=Entity&amp;hybrid_search_extra=%7B%22sourceType%22%3A%22answer%22%2C%22sourceId%22%3A2708298459%7D">数据库</a>做持久化存储，只有api-server才能直接操作etcd数据库，其他组件都不能直接操作etcd数据库，其他组件都是通过api-server间接的读取，写入数据到etcd。</p>
<p>kube-controller-manager：以下简称controller-manager，controller-manager是k8s中各种控制器的的管理者，是k8s集群内部的管理控制中心，也是k8s<a target="_blank" rel="noopener" href="https://www.zhihu.com/search?q=%E8%87%AA%E5%8A%A8%E5%8C%96&amp;search_source=Entity&amp;hybrid_search_source=Entity&amp;hybrid_search_extra=%7B%22sourceType%22%3A%22answer%22%2C%22sourceId%22%3A2708298459%7D">自动化</a>功能的核心；controller-manager内部包含replication controller、node controller、deployment controller、endpoint controller等各种资源对象的控制器，每种控制器都负责一种特定资源的控制流程，而controller-manager正是这些controller的核心管理者。</p>
<p>kube-scheduler：以下简称scheduler，scheduler负责集群资源调度，其作用是将待调度的pod通过一系列复杂的调度算法计算出最合适的node节点，然后将pod绑定到目标节点上。shceduler会根据pod的信息，全部节点信息列表，过滤掉不符合要求的节点，过滤出一批候选节点，然后给候选节点打分，选分最高的就是最佳节点，scheduler就会把目标pod安置到该节点。</p>
<p>Etcd：etcd是一个分布式的键值对存储数据库，主要是用于保存k8s集群状态数据，比如，pod，service等资源对象的信息；etcd可以是单个也可以有多个，多个就是etcd数据库集群，etcd通常部署奇数个实例，在大规模集群中，etcd有5个或7个节点就足够了；另外说明一点，etcd本质上可以不与master节点部署在一起，只要master节点能通过<a target="_blank" rel="noopener" href="https://www.zhihu.com/search?q=%E7%BD%91%E7%BB%9C%E8%BF%9E%E6%8E%A5&amp;search_source=Entity&amp;hybrid_search_source=Entity&amp;hybrid_search_extra=%7B%22sourceType%22%3A%22answer%22%2C%22sourceId%22%3A2708298459%7D">网络连接</a>etcd数据库即可。</p>
<p>kubelet：每个node节点上都有一个kubelet服务进程，kubelet作为连接master和各node之间的桥梁，负责维护pod和容器的生命周期，当监听到master下发到本节点的任务时，比如创建、更新、终止pod等任务，kubelet 即通过控制docker来创建、更新、销毁容器； 每个kubelet进程都会在api-server上注册本节点自身的信息，用于定期向master汇报本节点资源的使用情况。</p>
<p>kube-proxy：kube-proxy运行在node节点上，在Node节点上实现Pod网络代理，维护网络规则和四层负载均衡工作，kube-proxy会监听api-server中从而获取service和endpoint的变化情况，创建并维护路由规则以提供服务IP和负载均衡功能。简单理解此进程是Service的透明代理兼负载均衡器，其核心功能是将到某个Service的访问请求转发到后端的多个Pod实例上。</p>
<p>container-runtime：容器运行时环境，即运行容器所需要的一系列程序，目前k8s支持的容器运行时有很多，如docker、rkt或其他，比较受欢迎的是docker，但是新版的k8s已经宣布弃用docker。</p>
<h3 id="14-kube-api-server的端口是多少？各个pod是如何访问kube-api-server的？"><a href="#14-kube-api-server的端口是多少？各个pod是如何访问kube-api-server的？" class="headerlink" title="14 kube-api-server的端口是多少？各个pod是如何访问kube-api-server的？"></a>14 kube-api-server的端口是多少？各个pod是如何访问kube-api-server的？</h3><p>kube-api-server的端口是8080和6443，前者是http的端口，后者是https的端口，以我本机使用kubeadm安装的k8s为例：</p>
<p>在命名空间的kube-system命名空间里，有一个名称为kube-api-master的pod，这个pod就是运行着kube-api-server进程，它绑定了master主机的ip地址和6443端口，但是在default命名空间下，存在一个叫kubernetes的服务，该服务对外暴露端口为443，目标端口6443，这个服务的ip地址是clusterip地址池里面的第一个地址，同时这个服务的yaml定义里面并没有指定标签选择器，也就是说这个kubernetes服务所对应的endpoint是手动创建的，该endpoint也是名称叫做kubernetes，该endpoint的yaml定义里面代理到master节点的6443端口，也就是kube-api-server的IP和端口。这样一来，其他pod访问kube-api-server的整个流程就是：pod创建后嵌入了环境变量，pod获取到了kubernetes这个服务的ip和443端口，请求到kubernetes这个服务其实就是转发到了master节点上的6443端口的kube-api-server这个pod里面。</p>
<h3 id="15-k8s中命名空间的作用是什么？"><a href="#15-k8s中命名空间的作用是什么？" class="headerlink" title="15 k8s中命名空间的作用是什么？"></a>15 k8s中命名空间的作用是什么？</h3><p>amespace是kubernetes系统中的一种非常重要的资源，namespace的主要作用是用来实现多套环境的资源隔离，或者说是多租户的资源隔离。</p>
<p>k8s通过将集群内部的资源分配到不同的namespace中，可以形成逻辑上的隔离，以方便不同的资源进行隔离使用和管理。不同的命名空间可以存在同名的资源，命名空间为资源提供了一个作用域。</p>
<p>可以通过k8s的授权机制，将不同的namespace交给不同的租户进行管理，这样就实现了多租户的资源隔离，还可以结合k8s的资源配额机制，限定不同的租户能占用的资源，例如CPU使用量、内存使用量等等来实现租户可用资源的管理。</p>
<h3 id="16-k8s提供了大量的REST接口，其中有一个是Kubernetes-Proxy-API接口，简述一下这个Proxy接口的作用，已经怎么使用。"><a href="#16-k8s提供了大量的REST接口，其中有一个是Kubernetes-Proxy-API接口，简述一下这个Proxy接口的作用，已经怎么使用。" class="headerlink" title="16 k8s提供了大量的REST接口，其中有一个是Kubernetes Proxy API接口，简述一下这个Proxy接口的作用，已经怎么使用。"></a>16 k8s提供了大量的REST接口，其中有一个是Kubernetes Proxy API接口，简述一下这个Proxy接口的作用，已经怎么使用。</h3><p>好的。kubernetes proxy <a target="_blank" rel="noopener" href="https://www.zhihu.com/search?q=api%E6%8E%A5%E5%8F%A3&amp;search_source=Entity&amp;hybrid_search_source=Entity&amp;hybrid_search_extra=%7B%22sourceType%22%3A%22answer%22%2C%22sourceId%22%3A2708298459%7D">api接口</a>，从名称中可以得知，proxy是代理的意思，其作用就是代理rest请求；</p>
<p>Kubernets API server 将接收到的rest请求转发到某个node上的kubelet守护进程的rest接口，由该kubelet进程负责响应。我们可以使用这种Proxy接口来<a target="_blank" rel="noopener" href="https://www.zhihu.com/search?q=%E7%9B%B4%E6%8E%A5%E8%AE%BF%E9%97%AE&amp;search_source=Entity&amp;hybrid_search_source=Entity&amp;hybrid_search_extra=%7B%22sourceType%22%3A%22answer%22%2C%22sourceId%22%3A2708298459%7D">直接访问</a>某个pod，这对于逐一排查pod异常问题很有帮助。 下面是一些简单的例子：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">http://&lt;kube-api-server&gt;:&lt;api-sever-port&gt;/api/v1/nodes/node名称/proxy/pods    <span class="comment">#查看指定node的所有pod信息</span></span><br><span class="line">http://&lt;kube-api-server&gt;:&lt;api-sever-port&gt;/api/v1/nodes/node名称/proxy/stats   <span class="comment">#查看指定node的物理资源统计信息</span></span><br><span class="line">http://&lt;kube-api-server&gt;:&lt;api-sever-port&gt;/api/v1/nodes/node名称/proxy/spec    <span class="comment">#查看指定node的概要信息</span></span><br><span class="line"></span><br><span class="line">http://&lt;kube-api-server&gt;:&lt;api-sever-port&gt;/api/v1/namespace/命名名称/pods/pod名称/pod服务的url/   <span class="comment">#访问指定pod的程序页面</span></span><br><span class="line">http://&lt;kube-api-server&gt;:&lt;api-sever-port&gt;/api/v1/namespace/命名名称/servers/svc名称/url/      <span class="comment">#访问指定server的url程序页面</span></span><br></pre></td></tr></table></figure>
<h3 id="17-pod是什么？"><a href="#17-pod是什么？" class="headerlink" title="17 pod是什么？"></a>17 pod是什么？</h3><p>在kubernetes的世界中，k8s并不直接处理容器，而是使用多个容器共存的理念，这组容器就叫做pod。pod是k8s中可以创建和管理的最小单元，是资源对象模型中由用户创建或部署的最小资源对象模型，其他的资源对象都是用来支撑pod对象功能的，比如，pod控制器就是用来管理pod对象的，service或者ingress资源对象是用来暴露pod引用对象的，persistentvolume资源是用来为pod提供存储等等，简而言之，k8s不会直接处理容器，而是pod，pod才是k8s中可以创建和管理的最小单元，也是基本单元。</p>
<h3 id="18-pod的原理是什么？"><a href="#18-pod的原理是什么？" class="headerlink" title="18 pod的原理是什么？"></a>18 pod的原理是什么？</h3><p>在<a target="_blank" rel="noopener" href="https://www.zhihu.com/search?q=%E5%BE%AE%E6%9C%8D%E5%8A%A1&amp;search_source=Entity&amp;hybrid_search_source=Entity&amp;hybrid_search_extra=%7B%22sourceType%22%3A%22answer%22%2C%22sourceId%22%3A2708298459%7D">微服务</a>的概念里，一般的，一个容器会被设计为运行一个进程，除非进程本身产生子进程，这样，由于不能将多个进程聚集在同一个单独的容器中，所以需要一种更高级的结构将容器绑定在一起，并将它们作为一个单元进行管理，这就是k8s中pod的背后原理。</p>
<h3 id="19-pod有什么特点？"><a href="#19-pod有什么特点？" class="headerlink" title="19 pod有什么特点？"></a>19 pod有什么特点？</h3><p>1、每个pod就像一个独立的逻辑机器，k8s会为每个pod分配一个集群内部唯一的IP地址，所以每个pod都拥有自己的IP地址、主机名、进程等；</p>
<p>2、一个pod可以包含1个或多个容器，1个容器一般被设计成只运行1个进程，1个pod只可能运行在单个节点上，即不可能1个pod跨节点运行，pod的生命周期是短暂，也就是说pod可能随时被消亡（如节点异常，pod异常等情况）；</p>
<p>3、每一个pod都有一个特殊的被称为”根容器”的pause容器，也称info容器，pause容器对应的镜像属于k8s平台的一部分，除了pause容器，每个pod还包含一个或多个跑业务相关组件的应用容器；</p>
<p>4、一个pod中的容器共享network命名空间；</p>
<p>5、一个pod里的多个容器共享pod IP，这就意味着1个pod里面的多个容器的进程所占用的端口不能相同，否则在这个pod里面就会产生端口冲突；既然每个pod都有自己的IP和端口空间，那么对不同的两个pod来说就不可能存在端口冲突；</p>
<p>6、应该将应用程序组织到多个pod中，而每个pod只包含紧密相关的组件或进程；</p>
<p>7、pod是k8s中扩容、缩容的基本单位，也就是说k8s中扩容缩容是针对pod而言而非容器。</p>
<h3 id="20-pause容器作用是什么？"><a href="#20-pause容器作用是什么？" class="headerlink" title="20 pause容器作用是什么？"></a>20 pause容器作用是什么？</h3><p>每个pod里运行着一个特殊的被称之为pause的容器，也称根容器，而其他容器则称为业务容器；创建pause容器主要是为了为业务容器提供 Linux命名空间，共享基础：包括 pid、icp、net 等，以及启动 init 进程，并收割僵尸进程；这些业务容器共享pause容器的网络命名空间和volume挂载卷，当pod被创建时，pod首先会创建pause容器，从而把其他业务容器加入pause容器，从而让所有业务容器都在同一个命名空间中，这样可以就可以实现网络共享。pod还可以共享存储，在pod级别引入数据卷volume，业务容器都可以挂载这个数据卷从而实现持久化存储。</p>
<h3 id="21-pod的重启策略有哪些？"><a href="#21-pod的重启策略有哪些？" class="headerlink" title="21 pod的重启策略有哪些？"></a>21 pod的重启策略有哪些？</h3><p>pod重启容器策略是指针对pod内所有容器的重启策略，不是重启pod，其可以通过<code>restartPolicy</code>字段配置pod重启容器的策略，如下：</p>
<ul>
<li><code>Always</code>: 当容器终止退出后，总是重启容器，默认策略就是<code>Always</code>。</li>
<li><code>OnFailure</code>: 当容器异常退出，退出状态码非0时，才重启容器。</li>
<li><code>Never</code>: 当容器终止退出，不管退出状态码是什么，从不重启容器。</li>
</ul>
<h3 id="22-pod的镜像拉取策略有哪几种？"><a href="#22-pod的镜像拉取策略有哪几种？" class="headerlink" title="22 pod的镜像拉取策略有哪几种？"></a>22 pod的镜像拉取策略有哪几种？</h3><p>pod镜像拉取策略可以通过<code>imagePullPolicy</code>字段配置镜像拉取策略，主要有3中镜像拉取策略，如下：</p>
<ul>
<li><code>IfNotPresent</code>: 默认值，镜像在node节点宿主机上不存在时才拉取。</li>
<li><code>Always</code>: 总是重新拉取，即每次创建pod都会重新从镜像仓库拉取一次镜像。</li>
<li><code>Never</code>: 永远不会主动拉取镜像，仅使用本地镜像，需要你手动拉取镜像到node节点，如果node节点不存在镜像则pod启动失败。</li>
</ul>
<h3 id="23-pod的存活探针有哪几种？"><a href="#23-pod的存活探针有哪几种？" class="headerlink" title="23 pod的存活探针有哪几种？"></a>23 pod的存活探针有哪几种？</h3><p>kubernetes可以通过存活探针检查容器是否还在运行，可以为pod中的每个容器单独定义存活探针，kubernetes将定期执行探针，如果探测失败，将杀死容器，并根据<code>restartPolicy</code>策略来决定是否重启容器，kubernetes提供了3种探测容器的存活探针，如下：</p>
<ul>
<li><code>httpGet</code>：通过容器的IP、端口、路径发送http 请求，返回200-400范围内的状态码表示成功。</li>
<li><code>exec</code>：在容器内执行shell命令，根据命令退出状态码是否为0进行判断，0表示健康，非0表示不健康。</li>
<li><code>TCPSocket</code>：与容器的端口建立TCP Socket链接。</li>
</ul>
<h3 id="24-存活探针的属性参数有哪几个？"><a href="#24-存活探针的属性参数有哪几个？" class="headerlink" title="24 存活探针的属性参数有哪几个？"></a>24 存活探针的属性参数有哪几个？</h3><p>存活探针的附加属性参数有以下几个：</p>
<ul>
<li><code>initialDelaySeconds</code>：表示在容器启动后延时多久秒才开始探测；</li>
<li><code>periodSeconds</code>：表示执行探测的频率，即间隔多少秒探测一次，默认间隔周期是10秒，最小1秒；</li>
<li><code>timeoutSeconds</code>：表示探测超时时间，默认1秒，最小1秒，表示容器必须在超时时间范围内做出响应，否则视为本次探测失败；</li>
<li><code>successThreshold</code>：表示最少连续探测成功多少次才被认定为成功，默认是1，对于liveness必须是1，最小值是1；</li>
<li><code>failureThreshold</code>：表示连续探测失败多少次才被认定为失败，默认是3，连续3次失败，k8s 将根据pod重启策略对容器做出决定；</li>
</ul>
<p>注意：定义存活探针时，一定要设置<code>initialDelaySeconds</code>属性，该属性为初始延时，如果不设置，默认容器启动时探针就开始探测了，这样可能会存在应用程序还未启动就绪，就会导致探针检测失败，k8s就会根据pod重启策略杀掉容器然后再重新创建容器的莫名其妙的问题。</p>
<p>在生产环境中，一定要定义一个存活探针。</p>
<h3 id="25-pod的就绪探针有哪几种？"><a href="#25-pod的就绪探针有哪几种？" class="headerlink" title="25 pod的就绪探针有哪几种？"></a>25 pod的就绪探针有哪几种？</h3><p>我们知道，当一个pod启动后，就会立即加入service的endpoint ip列表中，并开始接收到客户端的链接请求，假若此时pod中的容器的业务进程还没有初始化完毕，那么这些客户端链接请求就会失败，为了解决这个问题，kubernetes提供了就绪探针来解决这个问题的。</p>
<p>在pod中的容器定义一个就绪探针，就绪探针周期性检查容器，如果就绪探针检查失败了，说明该pod还未准备就绪，不能接受客户端链接，则该pod将从endpoint列表中移除，被剔除了service就不会把请求分发给该pod，然后就绪探针继续检查，如果随后容器就绪，则再重新把pod加回endpoint列表。k8s提供了3种就绪探针，如下：</p>
<ul>
<li><code>exec</code>：在容器中执行命令并检查命令退出的状态码，如果状态码为0，则说明容器已经准备就绪；</li>
<li><code>httpGet</code>：向容器发送http get请求，通过响应的http状态码判断容器是否准备就绪；</li>
<li><code>tcpSocket</code>：打开一个tcp连接到容器的指定端口，如果连接已建立，则认为容器已经准备就绪。</li>
</ul>
<h3 id="26-就绪探针的属性参数有哪些"><a href="#26-就绪探针的属性参数有哪些" class="headerlink" title="26 就绪探针的属性参数有哪些"></a>26 就绪探针的属性参数有哪些</h3><p>就绪探针的附加属性参数有以下几个：</p>
<ul>
<li><code>initialDelaySeconds</code>：延时秒数，即容器启动多少秒后才开始探测，不写默认容器启动就探测；</li>
<li><code>periodSeconds</code> ：执行探测的频率（秒），默认为10秒，最低值为1；</li>
<li><code>timeoutSeconds</code> ：超时时间，表示探测时在超时时间内必须得到响应，负责视为本次探测失败，默认为1秒，最小值为1；</li>
<li><code>failureThreshold</code> ：连续探测失败的次数，视为本次探测失败，默认为3次，最小值为1次；</li>
<li><code>successThreshold</code> ：连续探测成功的次数，视为本次探测成功，默认为1次，最小值为1次；</li>
</ul>
<h3 id="27-就绪探针与存活探针区别是什么？"><a href="#27-就绪探针与存活探针区别是什么？" class="headerlink" title="27 就绪探针与存活探针区别是什么？"></a>27 就绪探针与存活探针区别是什么？</h3><p>两者作用不一样，存活探针是将检查失败的容器杀死，创建新的启动容器来保持pod正常工作；</p>
<p>就绪探针是，当就绪探针检查失败，并不重启容器，而是将pod移出endpoint，就绪探针确保了service中的pod都是可用的，确保客户端只与正常的pod交互并且客户端永远不会知道系统存在问题。</p>
<h3 id="28-简单讲一下-pod创建过程"><a href="#28-简单讲一下-pod创建过程" class="headerlink" title="28 简单讲一下 pod创建过程"></a>28 简单讲一下 pod创建过程</h3><p>1、用户通过kubectl或其他api客户端工具提交需要创建的pod信息给apiserver；</p>
<p>2、apiserver验证客户端的用户权限信息，验证通过开始处理创建请求生成pod对象信息，并将信息存入etcd，然后返回确认信息给客户端；</p>
<p>3、apiserver开始反馈etcd中pod对象的变化，其他组件使用watch机制跟踪apiserver上的变动；</p>
<p>4、scheduler发现有新的pod对象要创建，开始调用内部算法机制为pod分配最佳的主机，并将结果信息更新至apiserver；</p>
<p>5、node节点上的kubelet通过watch机制跟踪apiserver发现有pod调度到本节点，尝试调用docker启动容器，并将结果反馈apiserver；</p>
<p>6、apiserver将收到的pod状态信息存入etcd中。</p>
<p>至此，整个pod调度完成，创建完毕。</p>
<h3 id="29-简单描述一下pod的终止过程"><a href="#29-简单描述一下pod的终止过程" class="headerlink" title="29 简单描述一下pod的终止过程"></a>29 简单描述一下pod的终止过程</h3><p>1、用户向apiserver发送删除pod对象的命令；</p>
<p>2、apiserver中的pod对象信息会随着时间的推移而更新，在宽限期内（默认30s），pod被视为dead；</p>
<p>3、将pod标记为terminating状态；</p>
<p>4、kubectl在监控到pod对象为terminating状态了就会启动pod关闭过程；</p>
<p>5、endpoint控制器监控到pod对象的关闭行为时将其从所有匹配到此endpoint的server资源endpoint列表中删除；</p>
<p>6、如果当前pod对象定义了preStop钩子处理器，则在其被标记为terminating后会意同步的方式启动执行；</p>
<p>7、pod对象中的容器进程收到停止信息；</p>
<p>8、宽限期结束后，若pod中还存在运行的进程，那么pod对象会收到立即终止的信息；</p>
<p>9、kubelet请求apiserver将此pod资源的宽限期设置为0从而完成删除操作，此时pod对用户已不可见。</p>
<h3 id="30-pod的生命周期有哪几种？"><a href="#30-pod的生命周期有哪几种？" class="headerlink" title="30 pod的生命周期有哪几种？"></a>30 pod的生命周期有哪几种？</h3><p>pod生命周期有的5种状态（也称5种相位），如下：</p>
<ul>
<li><strong>Pending</strong>（挂起）：API server已经创建pod，但是该pod还有一个或多个容器的镜像没有创建，包括正在下载镜像的过程；</li>
<li><strong>Running</strong>（运行中）：Pod内所有的容器已经创建，且至少有一个容器处于运行状态、正在启动括正在重启状态；</li>
<li><strong>Succeed</strong>（成功）：Pod内所有容器均已退出，且不会再重启；</li>
<li><strong>Failed</strong>（失败）：Pod内所有容器均已退出，且至少有一个容器为退出失败状态</li>
<li><strong>Unknown</strong>（未知）：某于某种原因apiserver无法获取该pod的状态，可能由于网络通行问题导致；</li>
</ul>
<h3 id="31-pod的初始化容器是干什么的？"><a href="#31-pod的初始化容器是干什么的？" class="headerlink" title="31 pod的初始化容器是干什么的？"></a>31 pod的初始化容器是干什么的？</h3><p>init container，初始化容器用于在启动应用容器之前完成应用容器所需要的前置条件，初始化容器本质上和应用容器是一样的，但是初始化容器是仅允许一次就结束的任务，初始化容器具有两大特征：</p>
<p>1、初始化容器必须运行完成直至结束，若某初始化容器运行失败，那么kubernetes需要重启它直到成功完成；</p>
<p>2、初始化容器必须按照定义的顺序执行，当且仅当前一个初始化容器成功之后，后面的一个初始化容器才能运行；</p>
<h3 id="32-pod的资源请求、限制如何定义？"><a href="#32-pod的资源请求、限制如何定义？" class="headerlink" title="32 pod的资源请求、限制如何定义？"></a>32 pod的资源请求、限制如何定义？</h3><p>pod的资源请求、资源限制可以直接在pod中定义，主要包括两块内容，limits，限制pod能使用的最大cpu和内存，requests，pod启动时申请的cpu和内存。</p>
<figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">resources:</span>                  <span class="comment">#资源配额</span></span><br><span class="line">  <span class="attr">limits:</span>                   <span class="comment">#限制最大资源，上限</span></span><br><span class="line">    <span class="attr">cpu:</span> <span class="number">2</span>                  <span class="comment">#CPU限制，单位是code数</span></span><br><span class="line">    <span class="attr">memory:</span> <span class="string">2G</span>              <span class="comment">#内存最大限制</span></span><br><span class="line">  <span class="attr">requests:</span>                 <span class="comment">#请求资源（最小，下限）</span></span><br><span class="line">    <span class="attr">cpu:</span> <span class="number">1</span>                  <span class="comment">#CPU请求，单位是code数</span></span><br><span class="line">    <span class="attr">memory:</span> <span class="string">500G</span>            <span class="comment">#内存最小请求</span></span><br></pre></td></tr></table></figure>
<h3 id="33-标签及标签选择器是什么，如何使用？"><a href="#33-标签及标签选择器是什么，如何使用？" class="headerlink" title="33 标签及标签选择器是什么，如何使用？"></a>33 标签及标签选择器是什么，如何使用？</h3><p>标签是键值对类型，标签可以附加到任何资源对象上，主要用于管理对象，查询和筛选。标签常被用于标签选择器的匹配度检查，从而完成资源筛选；一个资源可以定义一个或多个标签在其上面。</p>
<p>标签选择器，标签要与标签选择器结合在一起，标签选择器允许我们选择标记有特定标签的资源对象子集，如pod，并对这些特定标签的pod进行查询，删除等操作。</p>
<p>标签和标签选择器最重要的使用之一在于，在deployment中，在pod模板中定义pod的标签，然后在deployment定义标签选择器，这样就通过标签选择器来选择哪些pod是受其控制的，service也是通过标签选择器来关联哪些pod最后其服务后端pod。</p>
<h3 id="34-service是如何与pod关联的？"><a href="#34-service是如何与pod关联的？" class="headerlink" title="34 service是如何与pod关联的？"></a>34 service是如何与pod关联的？</h3><p>答案是通过标签选择器，每一个由deployment创建的pod都带有标签，这样，service就可以定义标签选择器来关联哪些pod是作为其后端了，就是这样，service就与pod管联在一起了。</p>
<h3 id="35-service的域名解析格式、pod的域名解析格式"><a href="#35-service的域名解析格式、pod的域名解析格式" class="headerlink" title="35 service的域名解析格式、pod的域名解析格式"></a>35 service的<a target="_blank" rel="noopener" href="https://www.zhihu.com/search?q=%E5%9F%9F%E5%90%8D%E8%A7%A3%E6%9E%90&amp;search_source=Entity&amp;hybrid_search_source=Entity&amp;hybrid_search_extra=%7B%22sourceType%22%3A%22answer%22%2C%22sourceId%22%3A2708298459%7D">域名解析</a>格式、pod的域名解析格式</h3><p>service的DNS域名表示格式为<code>&lt;servicename&gt;.&lt;namespace&gt;.svc.&lt;clusterdomain&gt;</code>，servicename是service的名称，namespace是service所处的命名空间，clusterdomain是k8s集群设置的域名后缀，一般默认为 <code>cluster.local</code></p>
<p>pod的DNS域名格式为：<code>&lt;pod-ip&gt;.&lt;namespace&gt;.pod.&lt;clusterdomain&gt;</code>，其中，<code>pod-ip</code>需要使用<code>-</code>将<code>ip</code>直接的点替换掉，namespace为pod所在的命名空间，clusterdomain是k8s集群设置的域名后缀，一般默认为<code>cluster.local</code> .</p>
<h3 id="36-一个应用pod是如何发现service的，或者说，pod里面的容器用于是如何连接service的？"><a href="#36-一个应用pod是如何发现service的，或者说，pod里面的容器用于是如何连接service的？" class="headerlink" title="36 一个应用pod是如何发现service的，或者说，pod里面的容器用于是如何连接service的？"></a>36 一个应用pod是如何发现service的，或者说，pod里面的容器用于是如何连接service的？</h3><p>答：有两种方式，一种是通过环境变量，另一种是通过service的dns域名方式。</p>
<p>1、环境变量：当pod被创建之后，k8s系统会自动为容器注入集群内有效的service名称和端口号等信息为环境变量的形式，这样容器应用直接通过取环境变量值就能访问service了，如<code>curl http://$&#123;WEBAPP_SERVICE_HOST&#125;:&#123;WEBAPP_SERVICE_PORT&#125;</code></p>
<p>2、DNS方式：使用dns域名解析的前提是k8s集群内有DNS域名解析服务器，默认k8s中会有一个CoreDNS作为k8s集群的默认DNS服务器提供域名解析服务器；service的DNS域名表示格式为<code>&lt;servicename&gt;.&lt;namespace&gt;.svc.&lt;clusterdomain&gt;</code>，servicename是service的名称，namespace是service所处的命名空间，clusterdomain是k8s集群设置的域名后缀，一般默认为 cluster.local ，这样容器应用直接通过service域名就能访问service了，如<code>wget http://svc-deployment-nginx.default.svc.cluster.local:80</code>，另外，service的port端口如果定义了名称，那么port也可以通过DNS进行解析，格式为：<code>_&lt;portname&gt;._&lt;protocol&gt;.&lt;servicename&gt;.&lt;namespace&gt;.svc.&lt;clusterdomain&gt;</code></p>
<h3 id="37-如何创建一个service代理外部的服务，或者换句话来说，在k8s集群内的应用如何访问外部的服务，如数据库服务，缓存服务等"><a href="#37-如何创建一个service代理外部的服务，或者换句话来说，在k8s集群内的应用如何访问外部的服务，如数据库服务，缓存服务等" class="headerlink" title="37 如何创建一个service代理外部的服务，或者换句话来说，在k8s集群内的应用如何访问外部的服务，如数据库服务，缓存服务等?"></a>37 如何创建一个service代理外部的服务，或者换句话来说，在k8s集群内的应用如何访问外部的服务，如数据库服务，缓存服务等?</h3><p>答：可以通过创建一个没有标签选择器的service来代理集群外部的服务。</p>
<p>1、创建service时不指定selector标签选择器，但需要指定service的port、targetPort、协议等，这样创建出来的service因为没有指定标签选择器就不会自动创建endpoint；</p>
<p>2、手动创建一个与service同名的endpoint，endpoint中定义外部服务的IP和端口，endpoint的名称一定要与service的名称一样，协议也要一样，不然endpoint不能与service进行关联。 完成以上两步，k8s会自动将service和同名的endpoint进行关联，这样，k8s集群内的应用服务直接访问这个service就可以相当于访问外部的服务了。</p>
<h3 id="38-service、endpoint、kube-proxys三种的关系是什么？"><a href="#38-service、endpoint、kube-proxys三种的关系是什么？" class="headerlink" title="38 service、endpoint、kube-proxys三种的关系是什么？"></a>38 service、endpoint、kube-proxys三种的关系是什么？</h3><p>service：在kubernetes中，service是一种为一组功能相同的pod提供单一不变的接入点的资源。当service被建立时，service的IP和端口不会改变，这样外部的客户端（也可以是集群内部的客户端）通过service的IP和端口来建立链接，这些链接会被路由到提供该服务的任意一个pod上。通过这样的方式，客户端不需要知道每个单独提供服务的pod地址，这样pod就可以在集群中随时被创建或销毁。</p>
<p>endpoint：service维护一个叫endpoint的资源列表，endpoint资源对象保存着service关联的pod的ip和端口。从表面上看，当pod消失，service会在endpoint列表中剔除pod，当有新的pod加入，service就会将pod ip加入endpoint列表；但是正在底层的逻辑是，endpoint的这种自动剔除、添加、更新pod的地址其实底层是由endpoint controller控制的，endpoint controller负责监听service和对应的pod副本的变化，如果监听到service被删除，则删除和该service同名的endpoint对象，如果监听到新的service被创建或者修改，则根据该service<a target="_blank" rel="noopener" href="https://www.zhihu.com/search?q=%E4%BF%A1%E6%81%AF%E8%8E%B7%E5%8F%96&amp;search_source=Entity&amp;hybrid_search_source=Entity&amp;hybrid_search_extra=%7B%22sourceType%22%3A%22answer%22%2C%22sourceId%22%3A2708298459%7D">信息获取</a>得相关pod列表，然后创建或更新service对应的endpoint对象，如果监听到pod事件，则更新它所对应的service的endpoint对象。</p>
<p>kube-proxy：kube-proxy运行在node节点上，在Node节点上实现Pod网络代理，维护网络规则和四层负载均衡工作，kube-proxy会监听api-server中从而获取service和endpoint的变化情况，创建并维护路由规则以提供服务IP和负载均衡功能。简单理解此进程是Service的透明代理兼负载均衡器，其核心功能是将到某个Service的访问请求转发到后端的多个Pod实例上。</p>
<h3 id="39-deployment怎么扩容或缩容？"><a href="#39-deployment怎么扩容或缩容？" class="headerlink" title="39 deployment怎么扩容或缩容？"></a>39 deployment怎么扩容或缩容？</h3><p>答：直接修改pod副本数即可，可以通过下面的方式来修改pod副本数：</p>
<p>1、直接修改yaml文件的replicas字段数值，然后<code>kubectl apply -f xxx.yaml</code>来实现更新；</p>
<p>2、使用<code>kubectl edit deployment xxx</code>修改replicas来实现在线更新；</p>
<p>3、使用<code>kubectl scale --replicas=5 deployment/deployment-nginx</code>命令来扩容缩容。</p>
<h3 id="40-deployment的更新升级策略有哪些？"><a href="#40-deployment的更新升级策略有哪些？" class="headerlink" title="40 deployment的更新升级策略有哪些？"></a>40 deployment的更新升级策略有哪些？</h3><p>答：deployment的升级策略主要有两种。</p>
<p>1、<code>Recreate</code> 重建更新：这种更新策略会杀掉所有正在运行的pod，然后再重新创建的pod；</p>
<p>2、<code>rollingUpdate</code> 滚动更新：这种更新策略，deployment会以滚动更新的方式来逐个更新pod，同时通过设置滚动更新的两个参数<code>maxUnavailable、maxSurge</code>来控制更新的过程。</p>
<h3 id="41-deployment的滚动更新策略有两个特别主要的参数，解释一下它们是什么意思？"><a href="#41-deployment的滚动更新策略有两个特别主要的参数，解释一下它们是什么意思？" class="headerlink" title="41 deployment的滚动更新策略有两个特别主要的参数，解释一下它们是什么意思？"></a>41 deployment的滚动更新策略有两个特别主要的参数，解释一下它们是什么意思？</h3><p>答：deployment的滚动更新策略，<code>rollingUpdate</code> 策略，主要有两个参数，<code>maxUnavailable</code>、<code>maxSurge</code>。</p>
<ul>
<li><code>maxUnavailable</code>：最大不可用数，<code>maxUnavailable</code>用于指定deployment在更新的过程中不可用状态的pod的最大数量，<code>maxUnavailable</code>的值可以是一个整数值，也可以是pod期望副本的百分比，如25%，计算时向下取整。</li>
<li><code>maxSurge</code>：最大激增数，<code>maxSurge</code>指定deployment在更新的过程中pod的总数量最大能超过pod副本数多少个，<code>maxUnavailable</code>的值可以是一个整数值，也可以是pod期望副本的百分比，如25%，计算时向上取整。</li>
</ul>
<h3 id="42-deployment更新的命令有哪些？"><a href="#42-deployment更新的命令有哪些？" class="headerlink" title="42 deployment更新的命令有哪些？"></a>42 deployment更新的命令有哪些？</h3><p>答：可以通过三种方式来实现更新deployment。</p>
<p>1、直接修改yaml文件的镜像版本，然后<code>kubectl apply -f xxx.yaml</code>来实现更新；</p>
<p>2、使用<code>kubectl edit deployment xxx</code>实现在线更新；</p>
<p>3、使用<code>kubectl set image deployment/nginx busybox=busybox nginx=nginx:1.9.1</code>命令来更新。</p>
<h3 id="43-简述一下deployment的更新过程"><a href="#43-简述一下deployment的更新过程" class="headerlink" title="43 简述一下deployment的更新过程?"></a>43 简述一下deployment的更新过程?</h3><p>deployment是通过控制replicaset来实现，由replicaset真正创建pod副本，每更新一次deployment，都会创建新的replicaset，下面来举例deployment的更新过程： 假设要升级一个nginx-deployment的版本镜像为<code>nginx:1.9</code>，deployment的定义滚动更新参数如下：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">replicas: 3</span><br><span class="line">deployment.spec.strategy.type: RollingUpdate</span><br><span class="line">maxUnavailable：25%</span><br><span class="line">maxSurge：25%</span><br></pre></td></tr></table></figure>
<p>通过计算我们得出，3*25%=0.75，<code>maxUnavailable</code>是向下取整，则<code>maxUnavailable=0</code>，<code>maxSurge</code>是向上取整，则<code>maxSurge=1</code>，所以我们得出在整个deployment升级镜像过程中，不管旧的pod和新的pod是如何创建消亡的，pod总数最大不能超过<code>3+maxSurge=4</code>个，最大pod不可用数<code>3-maxUnavailable=3</code>个。</p>
<p>现在具体讲一下deployment的更新升级过程： 使用<code>kubectl set image deployment/nginx nginx=nginx:1.9 --record</code>命令来更新；</p>
<p>1、deployment创建一个新的replaceset，先新增1个新版本pod，此时pod总数为4个，不能再新增了，再新增就超过pod总数4个了；旧=3，新=1，总=4；</p>
<p>2、减少一个旧版本的pod，此时pod总数为3个，这时不能再减少了，再减少就不满足最大pod不可用数3个了；旧=2，新=1，总=3；</p>
<p>3、再新增一个新版本的pod，此时pod总数为4个，不能再新增了；旧=2，新=2，总=4；</p>
<p>4、减少一个旧版本的pod，此时pod总数为3个，这时不能再减少了；旧=1，新=2，总=3；</p>
<p>5、再新增一个新版本的pod，此时pod总数为4个，不能再新增了；旧=1，新=3，总=4；</p>
<p>6、减少一个旧版本的pod，此时pod总数为3个，更新完成，pod都是新版本了；旧=0，新=3，总=3；</p>
<h3 id="44-deployment的回滚使用什么命令"><a href="#44-deployment的回滚使用什么命令" class="headerlink" title="44 deployment的回滚使用什么命令"></a>44 deployment的回滚使用什么命令</h3><p>在升级deployment时kubectl set image 命令加上 —record 参数可以记录具体的升级历史信息，使用<code>kubectl rollout history deployment/deployment-nginx</code>命令来查看指定的deployment升级历史记录，如果需要回滚到某个指定的版本，可以使用<code>kubectl rollout undo deployment/deployment-nginx --to-revision=2</code>命令来实现。</p>
<h3 id="45-讲一下都有哪些存储卷，作用分别是什么"><a href="#45-讲一下都有哪些存储卷，作用分别是什么" class="headerlink" title="45 讲一下都有哪些存储卷，作用分别是什么?"></a>45 讲一下都有哪些存储卷，作用分别是什么?</h3><div class="table-container">
<table>
<thead>
<tr>
<th>卷</th>
<th>作用</th>
<th>常用场景</th>
</tr>
</thead>
<tbody>
<tr>
<td>emptyDir</td>
<td>用于存储临时数据的简单空目录</td>
<td>一个pod中的多个容器需要共享彼此的数据 ，emptyDir的数据随着容器的消亡也会销毁</td>
</tr>
<tr>
<td>hostPath</td>
<td>用于将目录从工作节点的文件系统挂载到pod中</td>
<td>不常用，缺点是，pod的调度不是固定的，也就是当pod消失后deployment重新创建一个pod，而这pod如果不是被调度到之前pod的节点，那么该pod就不能访问之前的数据</td>
</tr>
<tr>
<td>configMap</td>
<td>用于将非敏感的数据保存到键值对中，使用时可以使用作为环境变量、命令行参数arg，存储卷被pods挂载使用</td>
<td>将应用程序的不敏感配置文件创建为configmap卷，在pod中挂载configmap卷，可是实现热更新</td>
</tr>
<tr>
<td>secret</td>
<td>主要用于存储和管理一些敏感数据，然后通过在 Pod 的容器里挂载 Volume 的方式或者环境变量的方式访问到这些 Secret 里保存的信息了，pod会自动解密Secret 的信息</td>
<td>将应用程序的账号密码等敏感信息通过secret卷的形式挂载到pod中使用</td>
</tr>
<tr>
<td>downwardApi</td>
<td>主要用于暴露pod元数据，如pod的名字</td>
<td>pod中的应用程序需要指定pod的name等元数据，就可以通过downwardApi 卷的形式挂载给pod使用</td>
</tr>
<tr>
<td>projected</td>
<td>这是一种特殊的卷，用于将上面这些卷一次性的挂载给pod使用</td>
<td>将上面这些卷一次性的挂载给pod使用</td>
</tr>
<tr>
<td>pvc</td>
<td>pvc是存储卷声明</td>
<td>通常会创建pvc表示对存储的申请，然后在pod中使用pvc</td>
</tr>
<tr>
<td>网络存储卷</td>
<td>pod挂载网络存储卷，这样就能将数据持久化到后端的存储里</td>
<td>常见的网络存储卷有nfs存储、glusterfs 卷、ceph rbd存储卷</td>
</tr>
</tbody>
</table>
</div>
<p><strong>pv的访问模式有哪几种</strong></p>
<ul>
<li><code>ReadWriteOnce</code>，简写：RWO 表示，只仅允许单个节点以读写方式挂载；</li>
<li><code>ReadOnlyMany</code>，简写：ROX 表示，可以被许多节点以只读方式挂载；</li>
<li><code>ReadWriteMany</code>，简写：RWX 表示，可以被多个节点以读写方式挂载；</li>
</ul>
<h3 id="46-pv的回收策略有哪几种"><a href="#46-pv的回收策略有哪几种" class="headerlink" title="46 pv的回收策略有哪几种"></a>46 pv的回收策略有哪几种</h3><p>主要有3中回收策略：Retain 、Delete、Recycle。</p>
<ul>
<li>Retain：保留，该策略允许手动回收资源，当删除PVC时，PV仍然存在，PV被视为已释放，管理员可以手动回收卷。</li>
<li>Delete：删除，如果Volume插件支持，删除PVC时会同时删除PV，动态卷默认为Delete，目前支持Delete的存储后端包括AWS EBS，GCE PD，Azure Disk，OpenStack Cinder等。</li>
<li>Recycle：回收，如果Volume插件支持，Recycle策略会对卷执行<code>rm -rf</code>清理该PV，并使其可用于下一个新的PVC，但是本策略将来会被弃用，目前只有NFS和HostPath支持该策略。（这种策略已经被废弃，不用记）</li>
</ul>
<h3 id="47-在pv的生命周期中，一般有几种状态"><a href="#47-在pv的生命周期中，一般有几种状态" class="headerlink" title="47 在pv的生命周期中，一般有几种状态"></a>47 在pv的生命周期中，一般有几种状态</h3><p>创建pv后，pv的的状态有以下4种：</p>
<ul>
<li><code>Available</code>，表示pv已经创建正常，处于可用状态；</li>
<li><code>Bound</code>，表示pv已经被某个pvc绑定，注意，一个pv一旦被某个pvc绑定，那么该pvc就独占该pv，其他pvc不能再与该pv绑定；</li>
<li><code>Released</code>，表示pvc被删除了，pv状态就会变成已释放；</li>
<li><code>Failed</code>，表示pv的自动回收失败；</li>
</ul>
<h3 id="48-存储类的资源回收策略"><a href="#48-存储类的资源回收策略" class="headerlink" title="48 存储类的资源回收策略:"></a>48 存储类的资源回收策略:</h3><p>主要有2中回收策略，Delete 、Retain。默认就是Delete策略</p>
<ul>
<li>Retain：保留，该策略允许手动回收资源，当删除PVC时，PV仍然存在，PV被视为已释放，管理员可以手动回收卷。</li>
<li>Delete：删除，如果Volume插件支持，删除PVC时会同时删除PV，动态卷默认为Delete，目前支持Delete的存储后端包括AWS EBS，GCE PD，Azure Disk，OpenStack Cinder等。</li>
</ul>
<p>注意：使用存储类动态创建的pv默认继承存储类的回收策略，当然当pv创建后你也可以手动修改pv的回收策略。</p>
<h3 id="49-pv存储空间不足怎么扩容"><a href="#49-pv存储空间不足怎么扩容" class="headerlink" title="49 pv存储空间不足怎么扩容?"></a>49 pv存储空间不足怎么扩容?</h3><p>一般的，我们会使用动态分配存储资源，在创建<code>storageclass</code>时指定参数 <code>allowVolumeExpansion：true</code>，表示允许用户通过修改pvc申请的存储空间自动完成pv的扩容，当增大pvc的存储空间时，不会重新创建一个pv，而是扩容其绑定的后端pv。这样就能完成扩容了。但是<code>allowVolumeExpansion</code>这个特性只支持扩容空间不支持减少空间。</p>

    
    
  </div>

  

  

</article>
  
  <article class="post">
  <header class="post-header">
    <h1 class="post-title">
      
      <a class="post-link" href="/2023/09/11/System-Design/Raft/"></a>
      
    </h1>

    <div class="post-meta">
      <span class="post-time">
        2023-09-11
      </span>
      
      
      
    </div>
  </header>

  

  <div class="post-content">
    
    
    

    
    <figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"></span><br></pre></td></tr></table></figure>
<h2 id="1-核心概念"><a href="#1-核心概念" class="headerlink" title="1. 核心概念"></a>1. 核心概念</h2><div class="table-container">
<table>
<thead>
<tr>
<th><strong>中文术语</strong></th>
<th><strong>英文术语</strong></th>
<th><strong>含义</strong></th>
</tr>
</thead>
<tbody>
<tr>
<td>领导者</td>
<td>leader</td>
<td>节点的三种角色之一. 集群的首脑，负责发起”提议“、”提交“被多数派认可的决断.</td>
</tr>
<tr>
<td>跟随者</td>
<td>follower</td>
<td>节点的三种角色之一. 需要对 leader 的 ”提议“ 、”提交“和 candidate 的 ”竞选“ 进行响应.</td>
</tr>
<tr>
<td>候选人</td>
<td>candidate</td>
<td>节点的三种角色之一. 是一种处于竞选流程中的临时状态，根据多数派投票的结果会切为 leader 或 follower 的稳定态.</td>
</tr>
<tr>
<td>最终一致性</td>
<td>finnal consistency</td>
<td>中强一致性. 对于写请求，服务端保证最终一定能提供出正确的结果，但需要同步时间. 同步期间，可能被读到不一致的老数据.</td>
</tr>
<tr>
<td>即时一次性</td>
<td>immediate consistency</td>
<td>强一致性. 服务端要求做到写入立即可读.</td>
</tr>
<tr>
<td>预写日志</td>
<td>write ahead log</td>
<td>记录写请求明细的日志.（单指 raft 算法下狭义的预写日志）</td>
</tr>
<tr>
<td>状态机</td>
<td>state machine</td>
<td>节点内存储数据的介质.</td>
</tr>
<tr>
<td>提议</td>
<td>proposal</td>
<td>两阶段提交的第一个阶段. 指的是 leader 向所有节点发起日志同步请求的过程.</td>
</tr>
<tr>
<td>提交</td>
<td>commit</td>
<td>两阶段提交的第二个阶段. 指的是 leader 认可一笔写请求已经被系统采纳的动作.</td>
</tr>
<tr>
<td>应用</td>
<td>apply</td>
<td>指的是将预写日志记录内记录的写操作应用到状态机的过程.</td>
</tr>
<tr>
<td>任期</td>
<td>term</td>
<td>任期是用于标识 leader 更迭的概念. 每个任期内至多只允许有一个 leader.</td>
</tr>
<tr>
<td>日志索引</td>
<td>index</td>
<td>日志在预写日志数组中的位置.</td>
</tr>
<tr>
<td>脑裂</td>
<td>brain split</td>
<td>同一任期内，集群出现两个 leader，导致秩序崩盘.</td>
</tr>
</tbody>
</table>
</div>
<h3 id="1-1-多数派原则"><a href="#1-1-多数派原则" class="headerlink" title="1.1 多数派原则"></a>1.1 多数派原则</h3><blockquote>
<p>系统的决断无需全员参与,多数派达成的共识即可视为整个系统的答复</p>
<ul>
<li>以集群存在 5 个节点为例，多数派则需要集齐 3 个及 3 个以上节点，至多可以允许 2 个节点存在开小差背离主流的情况. 同理，倘若集群 6 个节点，则多数派需要集齐 4 个及 4 个以上节点，因此同样至多允许 2 个节点开小差. 综上，这是奉行多数派原则的集群通常将节点个数设置为奇数的原因之一.</li>
<li>多数派原则是提高分布式系统可用性 A 的关键. 对于整个系统而言，执行一项操作要求全员共同响应以实现强 C 的保证是过于苛刻的，因为我们无法保证所有节点都能健康运作，这种底线思维是研发人员所必须具备的素养. 但是倘若退而求其次，只要多数派达成共识即可正常决断和响应，这样下限就提高很多了. 由全员响应进化为多数派共识，这将把一种底线思维下的随机性问题进化为一个数学期望问题.</li>
</ul>
</blockquote>
<h3 id="1-2-一主多从、读写分离"><a href="#1-2-一主多从、读写分离" class="headerlink" title="1.2 一主多从、读写分离"></a>1.2 一主多从、读写分离</h3><ul>
<li>raft 算法下系统中的节点分为领导者 leader 和跟随者 follower 两类角色;leader拥有更广阔的视野，需要总览全局，领导一些日常事务的推进；follower 职责相对简单但同样重要，因为这是一个基于多数派原则运作的民众团体，所有角色只要拧成一股绳，聚成了多数派，就能代表整个系统进行决断，甚至包括推翻 leader.</li>
<li>读操作可以由集群的任意节点提供服务；写操作统一需要由 leader 收口处理，并向 follower 同步. 倘若 follower 率先收到了来自客户端的写请求，也需要转发给 leader 进行处理.</li>
</ul>
<h3 id="1-3-状态机与预写日志"><a href="#1-3-状态机与预写日志" class="headerlink" title="1.3  状态机与预写日志"></a>1.3  状态机与预写日志</h3><ul>
<li>状态机 （state machine）是节点实际存储数据的容器,写请求的最后一步是将结果写入状态机，而读请求也需要从状态机中获取数据进行响应.</li>
<li>预写日志（write ahead log，简称 wal）是通过日志的方式记录下每一笔写请求的明细（例如 set x = 3 这样一笔记录），使得变更历史有迹可循. 在 raft 算法中，写请求会先组织成预写日志的形式添加到日志数组中，当一个日志（写请求）达到集群多数派的认可后，才能够被提交，将变更应用到状态机当中.<h3 id="1-4-两阶段提交"><a href="#1-4-两阶段提交" class="headerlink" title="1.4  两阶段提交"></a>1.4  两阶段提交</h3>（1）leader 接收到来自客户端的一笔写请求；<br>（2）leader 将写请求添加到本地的预写日志中，并向集群中其他节点广播同步这笔写请求. 这个过程可以称之为“提议”（proposal）；<br>（3）集群中各节点接收到同步请求后，会一套检验机制判断是否能执行同步（添加到预写日志），校验机制这里不细述，留待 4.1 小节细说；<br>（4）倘若集群总计半数以上的节点（包括 leader 自身）都将这笔请求添加预写日志，并给予了 leader 肯定的答复（ack），那么 leader 此时会“提交”这个请求，并给予客户端写请求已成功处理的响应；<br>（5）其他节点在随后的时段中，会通过与 leader 的交互（心跳或其他同步数据的请求）感知到这个“提交”动作，最终也在预写日志中提交这笔请求；<br>（6）被提交的预写日志具备了被应用到状态机的资格. 但应用的时机取决于实现方式，倘若只追求最终一致性，可以选择异步应用；倘若追求立即一致性，则会要求 leader 先应用到状态机，才能给予客户端 ack.<h3 id="1-5-Leader选举"><a href="#1-5-Leader选举" class="headerlink" title="1.5  Leader选举"></a>1.5  Leader选举</h3></li>
<li>leader 需要定期向 follower 发送心跳，证明自己仍然健在. 与之对应的，follower 会建立一个心跳检测定时器，当超过指定时长未收到 leader 的心跳，则认为 leader 已死，会切换成候选人（candidate）发起竞选，尝试补位成为新的 leader.</li>
<li>follower 成为 candidate 后,会广播向所有节点拉票，当投赞同票的节点数（包括candidate 本身）达到多数派的时候，该 candidate 会胜任，成为新的 leader.</li>
</ul>
<h3 id="1-6-任期与日志索引"><a href="#1-6-任期与日志索引" class="headerlink" title="1.6  任期与日志索引"></a>1.6  任期与日志索引</h3><ul>
<li>每当一个 candidate 发起一轮竞选时，会将当前 term 在旧任期的基础上加1，倘若胜任成为新的 leader，这就将成为自己的“国号”.</li>
<li>值得一提的是，不是每个 term 都有 leader，因为可能在 candidate 未胜出的前提下，term 又进一步进行了累加，从而实现朝代的跨越.</li>
<li>但能够保证的是，<code>每个 term 至多只会有一个 leader</code></li>
<li>节点中的预写日志存放在一个数组中，每则日志在数组中的位置称之为索引 index.</li>
<li>于是，每一则预写日志会有两个核心的标识属性：<ul>
<li>term：标志了这则日志是哪个任期的 leader 在位时同步写入的；</li>
<li>index：标志了这则日志在预写日志数组的位置.</li>
</ul>
</li>
<li>通过 {term , index} 二元组可以组成一个全局唯一键，定位到一则日志，并且能够保证位于不同节点中日志，只要其 term 和 index 均相同，其内容一定完全一致</li>
</ul>
<h2 id="2-角色流转"><a href="#2-角色流转" class="headerlink" title="2. 角色流转"></a>2. 角色流转</h2><h3 id="2-1-角色定义及切换"><a href="#2-1-角色定义及切换" class="headerlink" title="2.1 角色定义及切换"></a>2.1 角色定义及切换</h3><ul>
<li><code>leader -&gt; follower</code><ul>
<li>倘若 leader 发现当前系统中出现了更大的任期，则会进行“禅让”，主动退位成 follower.</li>
<li>这里 leader 发现更大任期的方式包括：I 向 follower 提交日志同步请求时,从 follower 的响应参数中获得; II 收到了来自新任 leader 的心跳或者同步日志请求；III 收到了任期更大的 candidate 的拉票请求.</li>
</ul>
</li>
<li><code>follower -&gt; candidate</code><ul>
<li>leader 需要定期向 follower 发送心跳，告知自己仍健在的消息.</li>
<li>倘若 follower 超过一定时长没收到 leader 心跳时，会将状态切换为 candidate ，在当前任期的基础上加 1 作为竞选任期，发起竞选尝试补位.</li>
</ul>
</li>
<li><code>candidate -&gt; follower</code><ul>
<li>candidate 参与竞选过程中，出现以下两种情形时会退回 follower：<ul>
<li>多数派投了反对票；</li>
<li>竞选期间，收到了任期大于等于自身竞选任期的 leader 传来的请求.</li>
</ul>
</li>
</ul>
</li>
<li><code>candidate -&gt; leader</code><ul>
<li>candidate 竞选时，倘若多数派投了赞同票，则切换为 leader.</li>
</ul>
</li>
<li><code>candidate -&gt; candidate</code><ul>
<li>candidate 的竞选流程有一个时间阈值. 倘若超时仍未形成有效结论（多数派赞同或拒绝），则会维持 candidate 身份，将竞选任期加1，发起新一轮竞选.<h3 id="2-2-领导者"><a href="#2-2-领导者" class="headerlink" title="2.2 领导者"></a>2.2 领导者</h3>领导者是写请求的统一入口，在接收到来自客户端的写请求时，会开启“两阶段提交”的流程：</li>
</ul>
</li>
<li>广播 proposal，向所有节点同步这一请求；</li>
<li>当请求得到多数派的赞同后，才会提交这一请求.</li>
<li>leader 还需要周期性地向集群中所有节点发送自己的心跳，告知自己的健康状况，用途包括：</li>
<li>让 follower 重置心跳检测定时器，避免其切换成 candidate 发起竞选；</li>
<li>在心跳请求中携带上 leader 最新已提交日志的标识 id（term + index），推动 follower 更新日志提交进度.<h3 id="2-3-跟随者"><a href="#2-3-跟随者" class="headerlink" title="2.3 跟随者"></a>2.3 跟随者</h3></li>
<li>负责同步 leader 传来的写请求，此时也有一个参与民主反馈的过程，倘若同步成功，会给予 leader 正向反馈，当 leader 的同步请求收到半数以上的认可时，会提交日志；</li>
<li>通过接收 leader 心跳的方式，获取到携带的 commitIndex 信息，及时完成已被多数派认可的预写日志的提交，以推进其写入状态机的进度. 这一项相当于做到了数据的备份，也被读请求最终一致性提供了保证;</li>
<li>负责为参与竞选 candidate 的投票</li>
<li>通过心跳检测定时器时时关注 leader 的健康状态，当超时未收到心跳时，会切换为 candidate 发起竞选.<h3 id="2-4-候选人"><a href="#2-4-候选人" class="headerlink" title="2.4 候选人"></a>2.4 候选人</h3></li>
<li>倘若 follower 切为 candidate，会将当前任期加1，作为竞选任期；</li>
<li>会将自身的一票投给自己；</li>
<li>广播向所有节点拉票；</li>
<li>倘若拉票请求超时前，得到多数派认可，则上位为 leader；</li>
<li>倘若拉票请求超时前，遭到多数派拒绝，则老实退回 follower；</li>
<li>倘若拉票请求超时前，收到了任期大于等于自身竞选任期的 leader 的请求，则老实退回 follower；</li>
<li>倘若拉票请求超时，则竞选任期加 1，发起新一轮竞选拉票请求.</li>
</ul>
<h2 id="3-常见问题"><a href="#3-常见问题" class="headerlink" title="3. 常见问题"></a>3. 常见问题</h2><h3 id="3-1-为什么能保证一个任期内至多只有一个领导者？"><a href="#3-1-为什么能保证一个任期内至多只有一个领导者？" class="headerlink" title="3.1 为什么能保证一个任期内至多只有一个领导者？"></a>3.1 为什么能保证一个任期内至多只有一个领导者？</h3><p>可以，通过选举的机制可以保证.</p>
<ul>
<li>首先，candidate 竞选前会自增 term，因此 term 在总体上为单调递增趋势；</li>
<li>其次，在选举机制上，一个 term 内，一个 follower 只有一票，因此只能投票给一个 candidate；</li>
<li>最后，基于多数派原则，一个 candidate 只有拿到半数以上的赞同票才能当选 leader.</li>
<li>因此，同一个 term 内，不可能出现有两个 candidate 同时获得半数以上的赞同票，因此一个 term 至多只有一个 leader.<h3 id="3-2-为什么能保证通过任期和索引相同的日志内容一定相同？"><a href="#3-2-为什么能保证通过任期和索引相同的日志内容一定相同？" class="headerlink" title="3.2 为什么能保证通过任期和索引相同的日志内容一定相同？"></a>3.2 为什么能保证通过任期和索引相同的日志内容一定相同？</h3></li>
<li>首先，预写日志具有 append-only 的性质，只作追加，不存在更新和删除操作；</li>
<li>其次，同一个 term 只有一个 leader；</li>
<li>因此，在 term 相同的情况下，所有节点在同一个 index 上的日志都会与 term 内 leader 对应 index 位置的日志保持一致；</li>
<li>综上，term 和 index 共同组成了一个全局唯一标识键. 只要term 和 index 均相同，日志内容一定相同<h3 id="3-3-关于选举机制方面，如何解决选票瓜分引发的问题？"><a href="#3-3-关于选举机制方面，如何解决选票瓜分引发的问题？" class="headerlink" title="3.3 关于选举机制方面，如何解决选票瓜分引发的问题？"></a>3.3 关于选举机制方面，如何解决选票瓜分引发的问题？</h3></li>
<li>每个节点在心跳超时阈值和竞选超时阈值上添加一个随机扰动值，通过这一扰动，避免多个节点在进入完全相同的竞选节奏. 于是进入 candidate 状态的节点有了先后之分，胜负自然就可见分晓.<h3 id="3-4-为什么新任-leader-一定拥有旧-leader-已提交的日志？"><a href="#3-4-为什么新任-leader-一定拥有旧-leader-已提交的日志？" class="headerlink" title="3.4 为什么新任 leader 一定拥有旧 leader 已提交的日志？"></a>3.4 为什么新任 leader 一定拥有旧 leader 已提交的日志？</h3>由两阶段提交和选举流程中的多数派原则保证的：</li>
<li>只有被集群多数派完成同步的日志才会被 leader 提交；</li>
<li>在选举流程中，节点只会把票投给日志进度不滞后于自身的 candidate；</li>
<li>在竞选流程，candidate 需要获取多数派的赞同票才能胜任，成为新任 leader.</li>
<li>可知，新任 leader 的日志进度一定能在竞选流程的多数派中出于不滞后的地位.</li>
<li>而在集群节点个数固定的情况下，本轮竞选流程的多数派和认可前任 leader 同步日志请求的多数派至少存在一个重复的节点，否则就违背了多数派的语义（集群半数以上），因此可以得知，新任 leader 一定拥有前任 leader 那笔被多数派认可的日志，即旧 leader 提交的日志.</li>
</ul>
<h3 id="3-5-leader-向-follower-同步日志时，如何保证不出现乱序、丢失、重复的问题？"><a href="#3-5-leader-向-follower-同步日志时，如何保证不出现乱序、丢失、重复的问题？" class="headerlink" title="3.5 leader 向 follower 同步日志时，如何保证不出现乱序、丢失、重复的问题？"></a>3.5 leader 向 follower 同步日志时，如何保证不出现乱序、丢失、重复的问题？</h3><ul>
<li>不乱序、不重复：follower 同步日志前，会校验上一笔日志是否和 leader 的上一笔完全一致，只有这样才会执行同步动作.</li>
<li>不丢失：基于 ack 机制保证. 倘若 leader 超时未收到 follower 同步日志的 ack，会重发同步日志请求.</li>
</ul>
<h3 id="3-6-如何保证各节点已提交的预写日志顺序和内容都完全一致？"><a href="#3-6-如何保证各节点已提交的预写日志顺序和内容都完全一致？" class="headerlink" title="3.6 如何保证各节点已提交的预写日志顺序和内容都完全一致？"></a>3.6 如何保证各节点已提交的预写日志顺序和内容都完全一致？</h3><ul>
<li>假设节点 a 最后一笔已提交的预写日志的 term = x、index = y，这说明集群中有多数派认同了 term 为 x 的 leader 同步该笔日志的请求.</li>
<li>首先证明：倘若其他节点在 index = y 位置的日志已提交了，则这笔日志的 term 一定也为 x.</li>
<li>证明思路：倘若节点 b 在 index = y 处的日志已提交，且任期为 z，那么就说明集群中有多数派认可了任期为 z 的 leader 同步的 term = z、index = y 的日志的请求. 由于集群不可能存在两个对立的多数派，因此唯一的可能性就是 z = x，原题得证.</li>
<li>接下来基于 7.2 小节的证明结论，我们可以得知各节点在 term = x、index = y 前面部分的日志也都完全一致，即各节点已提交的预写日志顺序和内容都完全一致.</li>
</ul>
<h3 id="3-7-如何保证状态机数据的最终一致性？"><a href="#3-7-如何保证状态机数据的最终一致性？" class="headerlink" title="3.7 如何保证状态机数据的最终一致性？"></a>3.7 如何保证状态机数据的最终一致性？</h3><ul>
<li>被提交的预写日志顺序和内容都必然是完全一致的.</li>
<li>又由于只有被提交的预写日志才能被应用到状态机，因此状态机的数据必然会按照正确的顺序和请求内容被依次更新，最终一致性得以保证.</li>
</ul>
<h3 id="3-8-如何解决网络分区引发的无意义选举问题？"><a href="#3-8-如何解决网络分区引发的无意义选举问题？" class="headerlink" title="3.8 如何解决网络分区引发的无意义选举问题？"></a>3.8 如何解决网络分区引发的无意义选举问题？</h3><ul>
<li>倘若集群产生网络分区，部分处于小分区的节点由于无法接收到 leader 的心跳，导致进入选举流程. 又因为网络分区问题，导致选举始终无法获得多数派的响应，最终 candidate 会无限自增 term. 直到网络恢复的那一刻，由于 candidate 异常的高 term，导致 leader 退位，集群进入新一轮的选举流程.</li>
<li>尽管小分区中的节点由于数据的滞后不可能在选举中胜出，最后必然是大分区中的节点胜任，节点数据的一致性依然可以得到保证. 但是这个无意义的选举过程同样会导致集群陷入暂不可用的阶段. 因此，我们可以通过这样的措施来避免这类无意义的选举：</li>
<li>每个 candidate 发起真实选举之前，会有一个提前试探的过程，试探机制是向集群所有节点发送请求，只有得到多数派的响应，证明自己不存在网络环境问题时，才会将竞选任期自增，并且发起真实的选举流程.</li>
</ul>
<h3 id="3-9-如果保证客户端提交写请求不丢失、不重复？"><a href="#3-9-如果保证客户端提交写请求不丢失、不重复？" class="headerlink" title="3.9 如果保证客户端提交写请求不丢失、不重复？"></a>3.9 如果保证客户端提交写请求不丢失、不重复？</h3><ul>
<li>不丢失：通过 ack 机制保证. 客户端超时未收到服务端的 ack，则会重发请求.</li>
<li>不重复：客户端记录写请求的序列号，与服务端交互时透传这个序列号. 最终由服务端的 leader 实现对相同序列号写请求的幂等去重.</li>
</ul>

    
    
  </div>

  

  

</article>
  
  <article class="post">
  <header class="post-header">
    <h1 class="post-title">
      
      <a class="post-link" href="/2023/09/10/System-Design/%E5%88%86%E5%B8%83%E5%BC%8F%E7%90%86%E8%AE%BA/"></a>
      
    </h1>

    <div class="post-meta">
      <span class="post-time">
        2023-09-10
      </span>
      
      
      
    </div>
  </header>

  

  <div class="post-content">
    
    
    

    
    <figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"></span><br></pre></td></tr></table></figure>
<blockquote>
<p>分布式实际上就是单一的本地一体解决方案，在硬件或者资源上不够业务需求，而采取的一种分散式多节点，可以扩容资源的一种解决思路。</p>
<h2 id="1-一、从本地事务到分布式理论"><a href="#1-一、从本地事务到分布式理论" class="headerlink" title="1 一、从本地事务到分布式理论"></a>1 一、从本地事务到分布式理论</h2><p>事务提供一种机制将一个活动涉及的所有操作纳入到一个不可分割的执行单元，组成事务的所有操作只有在所有操作均能正常执行的情况下方能提交，只要其中任一操作执行失败，都将导致整个事务的回滚。</p>
<h3 id="1-1-1、ACID理论"><a href="#1-1-1、ACID理论" class="headerlink" title="1.1 1、ACID理论"></a>1.1 1、ACID理论</h3><ul>
<li><strong>原子性（Atomicity）</strong> 所有操作，要么全部完成，要么全部不完成</li>
<li><strong>一致性（Consistency）</strong> 在事务开始之前和事务结束以后，数据库数据的一致性约束没有被破坏。 不能说凭空多了 100 块钱</li>
<li><strong>隔离性（Isolation）</strong> 不受未提交事务的影响。隔离性可以防止多个事务并发执行时由于交叉执行而导致数据的不一致。</li>
<li><strong>持久性（Durability</strong>   事务处理结束后，对数据的修改就是永久的，即便系统故障也不会丢失。<h3 id="1-2-2、CAP-理论"><a href="#1-2-2、CAP-理论" class="headerlink" title="1.2 2、CAP 理论"></a>1.2 2、CAP 理论</h3>一个分布式系统最多只能同时满足<code>一致性（Consistency）</code>、<code>可用性（Availability）</code>和<code>分区容忍性（Partition Tolerance）</code>这三项中的两项。</li>
<li><strong><em>一致性</em></strong>   指“所有节点同时看到相同的数据”，即更新操作成功并返回客户端完成后，所有节点在同一时间的数据完全一致，等同于所有节点拥有数据的最新版本。</li>
<li><strong><em>可用性</em></strong>   指“任何时候，读写都是成功的”，即服务一直可用，而且是正常响应时间。</li>
<li><strong><em>分区容忍性</em></strong> 指“当部分节点出现消息丢失或者分区故障的时候，分布式系统仍然能够继续运行”，即系统容忍网络出现分区，并且在遇到某节点或网络分区之间网络不可达的情况下，仍然能够对外提供满足一致性和可用性的服务。</li>
<li>其中，<code>P 是确定的</code>，因为网络断开是客观存在的，因此就是选择 <strong>AP 架构</strong>还是 <strong>CP 架构</strong>的问题，实现更好的<strong>一致性和可用性</strong>。</li>
</ul>
</blockquote>
<pre><code>CP、AP 架构的取舍案例。Zookeeper用来解决分布式集群中应用系统的协调和一致性问题，因此是 CP。 Eureka等服务发现组件是为了保证可用性，因此是 AP。
</code></pre><h3 id="1-3-3、Base-理论"><a href="#1-3-3、Base-理论" class="headerlink" title="1.3 3、Base 理论"></a>1.3 3、Base 理论</h3><blockquote>
<p>BASE是 <code>Basically Available(基本可用）</code>、<code>Soft state(软状态）</code>和 <code>Eventually consistent(最终一致性）</code>三个短语的简写。核心思想是<code>最终一致性</code>。</p>
<ul>
<li><em>基本可用</em>： 允许损失部分可用性，延长响应时间，降级服务，限流等时段。</li>
<li><em>软状态</em>： 允许系统在多个不同节点的数据副本存在数据延时。</li>
<li><em>最终一致性</em>： 数据不能一直处于软状态，在一个时间期限后保证所有副本的数据一致性。</li>
<li>Base 是对 CAP 的实际应用，放弃强一致性，实现基本可用。</li>
</ul>
</blockquote>
<h2 id="2-二、分布式事务解决方案"><a href="#2-二、分布式事务解决方案" class="headerlink" title="2 二、分布式事务解决方案"></a>2 二、分布式事务解决方案</h2><blockquote>
<p>两阶段和三阶段提交协议、 TCC 分段提交，和基于消息队列的最终一致性设计。</p>
<h3 id="2-1-1、2PC-两阶段提交"><a href="#2-1-1、2PC-两阶段提交" class="headerlink" title="2.1 1、2PC 两阶段提交"></a>2.1 1、2PC 两阶段提交</h3><p>Two-phase Commit Protocol  一致性、中心化的原子提交协议</p>
<ul>
<li><strong>提交请求阶段</strong>：协调者将通知事务参与者准备提交事务，然后进入表决过程。在表决过程中，参与者将告知协调者自己的决策。</li>
<li><strong>提交阶段</strong>：协调者基于投票结果进行决策，所有参与者同意则提交事务。</li>
<li><strong>问题</strong>：资源阻塞，协调者单点故障，通知丢失造成数据不一致。<h3 id="2-2-2、3PC-三阶段提交"><a href="#2-2-2、3PC-三阶段提交" class="headerlink" title="2.2 2、3PC 三阶段提交"></a>2.2 2、3PC 三阶段提交</h3>在 2PC 之上扩展的提交协议，主要是为了解决两阶段提交协议的阻塞问题，从原来的两个阶段扩展为三个阶段，增加了超时机制。</li>
<li>CanCommit 阶段：协调者向参与者发送 Can-Commit 请求</li>
<li>PreCommit 阶段：协调者发送预提交请求，全部通过则进入 Prepared 阶段。</li>
<li>DoCommit 阶段：进行事务提交和没收到通知后进行超时提交。</li>
<li>优点和问题：引入超时机制和预提交阶段，保证在最后提交前各节点状态一致<h3 id="2-3-3、TCC-分段提交"><a href="#2-3-3、TCC-分段提交" class="headerlink" title="2.3 3、TCC 分段提交"></a>2.3 3、TCC 分段提交</h3>分布式事务的处理模型，将事务过程拆分为 Try、Confirm、Cancel 三个步骤，在保证强一致性的同时，最大限度提高系统的可伸缩性与可用性。</li>
<li><strong><em>Try 阶段</em></strong>：先对资源进行锁定，资源处于中间态但不处于最终态</li>
<li><strong><em>Confirm 或 Cancel 阶段</em></strong>：在 Try 操作的基础上，真正提交这次修改操作还是回滚这次变更操作</li>
<li><code>事务协调器 TX Manager</code>：负责统筹分布式事务的执行，串联 Try -&gt; Confirm/Cancel 的两阶段流程. 在第一阶段中批量调用 TCC Component 的 Try 接口，根据其结果，决定第二阶段是批量调用 TCC Component 的 Confirm 接口还是 Cancel 接口<h3 id="2-4-4、基于消息补偿的最终一致性"><a href="#2-4-4、基于消息补偿的最终一致性" class="headerlink" title="2.4 4、基于消息补偿的最终一致性"></a>2.4 4、基于消息补偿的最终一致性</h3>具体实现上，基于消息补偿的一致性主要有本地消息表和第三方可靠消息队列等。<h4 id="2-4-1-基于-MQ-实现分布式事务"><a href="#2-4-1-基于-MQ-实现分布式事务" class="headerlink" title="2.4.1 基于 MQ 实现分布式事务"></a>2.4.1 基于 MQ 实现分布式事务</h4></li>
<li>MQ可以保证至少被消费一次，但是不能解决消息的重复性问题</li>
<li>消费者需要基于消息的唯一键执行幂等去重操作<h2 id="3-三、Paxos-算法"><a href="#3-三、Paxos-算法" class="headerlink" title="3 三、Paxos 算法"></a>3 三、Paxos 算法</h2><h3 id="3-1-1、Quorum-机制"><a href="#3-1-1、Quorum-机制" class="headerlink" title="3.1 1、Quorum 机制"></a>3.1 1、Quorum 机制</h3>在 N 个副本中，一次更新成功的如果有 W 个，那么我在读取数据时是要从大于 N－W 个副本中读取，这样就能至少读到一个更新的数据了。<br>  WARO：全部更新完成才能写，保证所有副本一致</li>
<li>定义： 限定一次最少要读的副本数，如共 N 个副本，更新了 W 个，则要读取 N-W+1 个，保证读的数据是最新的。</li>
<li>需要配合版本号机制来确认。<h3 id="3-2-2、Paxos-节点构成"><a href="#3-2-2、Paxos-节点构成" class="headerlink" title="3.2 2、Paxos 节点构成"></a>3.2 2、Paxos 节点构成</h3>  角色有三种，一个节点可以同时成为这三者</li>
<li>提案者（Proposer）：提出议案value，比如修改某个变量，一轮只批准一个 value。</li>
<li>批准者 （Acceptor）：value 超过半数（N/2+1）的 Acceptor 批准后才能通过</li>
<li>学习者（Learner）： 学习被批准的 value，参考 Quorum机制，至少读 N/2+1 个 Accpetor来学习到通过的 value。</li>
<li>Client 产生议题者<h3 id="3-3-3、选举过程"><a href="#3-3-3、选举过程" class="headerlink" title="3.3 3、选举过程"></a>3.3 3、选举过程</h3></li>
<li>准备阶段：Proposer生成唯一的 ProposalID，发送 Prepare 请求。Acceptor 收到后，本地持久化并返回已经接收的提案。</li>
<li>选举阶段：<ul>
<li>Proposer 发送 Accept，回复大于一半，发出accept 请求，并带上自己指定的 value。</li>
<li>Acceptor 应答 Accept，回复提交结果。</li>
<li>Proposer 统计投票，过半数回复成功，广播结果。失败则回到准备阶段。<h2 id="4-四、Raft-算法"><a href="#4-四、Raft-算法" class="headerlink" title="4 四、Raft 算法"></a>4 四、Raft 算法</h2><h3 id="4-1-1、-概念介绍"><a href="#4-1-1、-概念介绍" class="headerlink" title="4.1 1、 概念介绍"></a>4.1 1、 概念介绍</h3>使用了分治思想把算法流程分为三个子问题：选举（Leader election）、日志复制（Log replication）、安全性（Safety）三个子问题</li>
</ul>
</li>
<li>节点被分为 Leader Follower Cabdidate 三种角色：<ul>
<li><strong>Leader</strong>：处理与客户端的交互和与 follower 的日志复制等，一般只有一个 Leader；</li>
<li><strong>Follower</strong>：被动学习 Leader 的日志同步，同时也会在 leader 超时后转变为 Candidate 参与竞选；</li>
<li><strong>Candidate</strong>：在竞选期间参与竞选；</li>
</ul>
</li>
<li><strong><em>Term</em></strong>：<strong>Raft 算法将时间划分成为任意不同长度的任期（term）</strong>。任期用连续的数字进行表示。<strong>每一个任期的开始都是一次选举（election），一个或多个候选人会试图成为领导人</strong>。如果一个候选人赢得了选举，它就会在该任期的剩余时间担任领导人。在某些情况下，选票会被瓜分，有可能没有选出领导人，那么，将会开始另一个任期，并且立刻开始下一次选举。<strong>Raft 算法保证在给定的一个任期最多只有一个领导人</strong>。</li>
<li><strong><em>随机超时时间</em></strong>：Follower 节点每次收到 Leader 的心跳请求后，会设置一个随机的，区间位于（150ms, 300ms)的超时时间。如果超过超时时间，还没有收到 Leader 的下一条请求，则认为 Leader 过期/故障了。</li>
<li><strong>心跳续命</strong>：Leader 在当选期间，会以一定时间间隔向其他节点发送心跳请求，以维护自己的 Leader 地位。</li>
<li>Raft 算法中服务器节点之间通信使用远程过程调用（RPC）<ul>
<li>RequestVote RPC：候选人在选举期间发起。</li>
<li>AppendEntries RPC：领导人发起的一种心跳机制，复制日志也在该命令中完成。</li>
<li>installSnapshot RPC: 领导者使用该RPC来发送快照给太落后的追随者。<h3 id="4-2-2、协议流程"><a href="#4-2-2、协议流程" class="headerlink" title="4.2 2、协议流程"></a>4.2 2、协议流程</h3></li>
</ul>
</li>
<li><em>选举流程</em><ul>
<li>当某个 follower 节点在超时时间内未收到 Leader 的请求，将发起选举， 从一个 Follower 变成 Candidate</li>
<li>如果一个 Candidate 收到了超过半数的投票，则该节点晋升为 Leader，会广播给所有节点；开始进行日志同步、处理客户端请求等</li>
<li>term用来保证请求的合法性</li>
</ul>
</li>
<li><em>日志复制</em><ul>
<li><code>复制状态机</code>：不同节点从相同的初始状态出发，执行相同顺序的输入指令集后，会得到相同的结束状态。</li>
<li>节点初始化后具有相同初始状态，将一个客户端请求（command）封装到一个<code>log entry</code> 中。Leader 负责将这些 log entries 复制到所有的 Follower 节点，然后节点按照相同的顺序应用 commands，达到<code>最终的一致状态</code></li>
<li>Leader执行请求过程：<ul>
<li>本地追加日志信息；</li>
<li>并行发出 AppendEntries RPC 请求；</li>
<li>等待大多数 Follower 的回应。收到查过半数节点的成功提交回应，代表该日志被复制到了大多数节点中(committed)；</li>
<li>在状态机上执行 entry command。既将该日志应用到状态机，真正影响到节点状态(applied)；</li>
<li>回应 Client 执行结果；</li>
<li>确认 Follower 也执行了这条 command；如果 Follower 崩溃、运行缓慢或者网络丢包，Leader 将无限期地重试 AppendEntries RPC，直到所有 Followers 应用了所有日志条目。<h3 id="4-3-3、安全性及约束"><a href="#4-3-3、安全性及约束" class="headerlink" title="4.3 3、安全性及约束"></a>4.3 3、安全性及约束</h3><h4 id="4-3-1-选举安全性"><a href="#4-3-1-选举安全性" class="headerlink" title="4.3.1 选举安全性"></a>4.3.1 选举安全性</h4></li>
</ul>
</li>
</ul>
</li>
<li>任一任期内最多一个 leader 被选出，有多余的 Leader就是脑裂了<ul>
<li>一个节点某一任期内最多只能投一票；而节点 B 的 term 必须比 A 的新，A 才能给 B 投票</li>
<li>只有获得多数投票的节点才会成为 leader<h4 id="4-3-2-日志-append-only"><a href="#4-3-2-日志-append-only" class="headerlink" title="4.3.2 日志 append only"></a>4.3.2 日志 append only</h4></li>
</ul>
</li>
<li>leader 在某一 term 的任一位置只会创建一个 log entry，且 log entry 是 append-only</li>
<li>一致性检查，请求中会包含最新 log entry 的前一个 log 的 term 和 index，如果 follower 在对应的 term index 找不到日志就会重新进行同步<h4 id="4-3-3-日志匹配特性"><a href="#4-3-3-日志匹配特性" class="headerlink" title="4.3.3 日志匹配特性"></a>4.3.3 日志匹配特性</h4></li>
<li>如果两个节点上的某个 log entry 的 log index 相同且 term 相同，那么在该 index 之前的所有 log entry 应该都是相同的。<h4 id="4-3-4-Leader-完备性"><a href="#4-3-4-Leader-完备性" class="headerlink" title="4.3.4 Leader 完备性"></a>4.3.4 Leader 完备性</h4></li>
<li>被选举人必须比自己知道的更多（比较 term 、log index）<h4 id="4-3-5-状态机安全性"><a href="#4-3-5-状态机安全性" class="headerlink" title="4.3.5 状态机安全性"></a>4.3.5 状态机安全性</h4></li>
<li>状态机安全性由日志的一致来保证。在算法中，一个日志被复制到多数节点才算 committed， 如果一个 log entry 在某个任期被提交（committed），那么这条日志一定会出现在所有更高 term 的 leader 的日志里面</li>
</ul>
</blockquote>
<h2 id="5-五、ZooKeeper"><a href="#5-五、ZooKeeper" class="headerlink" title="5 五、ZooKeeper"></a>5 五、ZooKeeper</h2><pre><code>ZooKeeper 提供了一个类似于 Linux 文件系统的数据模型，和基于 Watcher 机制的分布式事件通知。
</code></pre><h3 id="5-1-1、Zab-一致性协议"><a href="#5-1-1、Zab-一致性协议" class="headerlink" title="5.1 1、Zab 一致性协议"></a>5.1 1、Zab 一致性协议</h3><pre><code>ZooKeeper Atomic Broadcast，ZooKeeper 原子广播协议，保证分布式事务的最终一致性。

具体实现
</code></pre><ul>
<li>消息广播阶段，Leader 节点接受事务提交并将请求广播给 Follower 节点，根据反馈决定是否 Commit。</li>
<li>崩溃恢复阶段，Leader 宕机，重新进行 Leader 选举并进行数据同步。</li>
<li>Zxid: 事务编号，有一个新的 Leader 选举出现时，就会从这个 Leader 服务器上取出其本地日志中最大事务的 Zxid，并从中读取 epoch 值，然后加 1，以此作为新的周期 ID。高 32 位代表了每代 Leader 的唯一性，低 32 位则代表了每代 Leader 中事务的唯一性。</li>
</ul>
<h2 id="6-六、分布式锁"><a href="#6-六、分布式锁" class="headerlink" title="6 六、分布式锁"></a>6 六、分布式锁</h2><pre><code>分布式锁的目的是保证在分布式部署的应用集群中，多个服务在请求同一个方法或者同一个业务操作的情况下，对应业务逻辑只能被一台机器上的一个线程执行，避免出现并发问题。
</code></pre><ul>
<li><strong>互斥性</strong>: 任意时刻，只有一个客户端能持有锁。</li>
<li><strong>锁超时释放</strong>：持有锁超时，可以释放，防止不必要的资源浪费，也可以防止死锁。</li>
<li><strong>可重入性</strong>:一个线程如果获取了锁之后,可以再次对其请求加锁。</li>
<li><strong>高性能和高可用</strong>：加锁和解锁需要开销尽可能低，同时也要保证高可用，避免分布式锁失效。</li>
<li><strong>安全性</strong>：锁只能被持有的客户端删除，不能被其他客户端删除<h3 id="6-1-1、基于数据库"><a href="#6-1-1、基于数据库" class="headerlink" title="6.1 1、基于数据库"></a>6.1 1、基于数据库</h3>  基于关系型数据库实现分布式锁，是依赖数据库的唯一性来实现资源锁定，比如主键和唯一索引等。<br>  问题：单点故障，超时无法失效，不可重入，不能阻塞。<h3 id="6-2-2、基于缓存-Redis"><a href="#6-2-2、基于缓存-Redis" class="headerlink" title="6.2 2、基于缓存 Redis"></a>6.2 2、基于缓存 Redis</h3></li>
<li>SETNX + EXPIRE：不是原子操作</li>
<li>SETNX + value值是(系统时间+过期时间)：要求时间同步，没有持有者的标识</li>
<li>使用Lua脚本(包含SETNX + EXPIRE两条指令)：原子性</li>
<li>SET的扩展命令（SET EX PX NX）：误删，过期还没执行完</li>
<li>SET EX PX NX + 校验唯一随机值,再删除：设置 value 标记线程</li>
<li>Redisson框架：开启一个定时守护线程，延长过期时间</li>
<li>setnx 是「set if not exists」</li>
</ul>
<blockquote>
<p>高可用，Redlock算法，基于 N 个完全独立的 Redis 节点，一般是大于 3 的奇数个</p>
<ul>
<li>客户端记录当前系统时间，以毫秒为单位；</li>
<li>依次尝试从 5 个 Redis 实例中，使用相同的 key 获取锁，当向 Redis 请求获取锁时，客户端应该设置一个网络连接和响应超时时间，超时时间应该小于锁的失效时间，避免因为网络故障出现的问题；</li>
<li>客户端使用当前时间减去开始获取锁时间就得到了获取锁使用的时间，当且仅当从半数以上的 Redis 节点获取到锁，并且当使用的时间小于锁失效时间时，锁才算获取成功；</li>
<li>如果获取到了锁，key 的真正有效时间等于有效时间减去获取锁所使用的时间，减少超时的几率；</li>
<li>如果获取锁失败，客户端应该在所有的 Redis 实例上进行解锁，即使是上一步操作请求失败的节点，防止因为服务端响应消息丢失，但是实际数据添加成功导致的不一致。</li>
</ul>
</blockquote>
<h3 id="6-3-3、基于Zookeeper"><a href="#6-3-3、基于Zookeeper" class="headerlink" title="6.3 3、基于Zookeeper"></a>6.3 3、基于Zookeeper</h3><ul>
<li>利用 ZooKeeper 支持临时顺序节点的特性，实现分布式锁。</li>
<li>当客户端对某个方法加锁时，在 ZooKeeper 中该方法对应的指定节点目录下，生成一个唯一的临时有序节点。</li>
<li>判断是否获取锁，只需要判断持有的节点是否是有序节点中序号最小的一个，当释放锁的时候，将这个临时节点删除即可，这种方式可以避免服务宕机导致的锁无法释放而产生的死锁问题。<ul>
<li>客户端连接 ZooKeeper，并在 /lock 下创建临时有序子节点，第一个客户端对应的子节点为 /lock/lock01/00000001，第二个为 /lock/lock01/00000002；</li>
<li>其他客户端获取 /lock01 下的子节点列表，判断自己创建的子节点是否为当前列表中序号最小的子节点；</li>
<li>如果是则认为获得锁，执行业务代码，否则通过 watch 事件监听 /lock01 的子节点变更消息，获得变更通知后重复此步骤直至获得锁；</li>
<li>完成业务流程后，删除对应的子节点，释放分布式锁。</li>
</ul>
</li>
</ul>

    
    
  </div>

  

  

</article>
  
  <article class="post">
  <header class="post-header">
    <h1 class="post-title">
      
      <a class="post-link" href="/2023/09/10/Framework/MySQL/"></a>
      
    </h1>

    <div class="post-meta">
      <span class="post-time">
        2023-09-10
      </span>
      
      
      
    </div>
  </header>

  

  <div class="post-content">
    
    
    

    
    <figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"></span><br></pre></td></tr></table></figure>
<h2 id="1-架构与简介"><a href="#1-架构与简介" class="headerlink" title="1. 架构与简介"></a>1. 架构与简介</h2><h3 id="1-MySQL-架构"><a href="#1-MySQL-架构" class="headerlink" title="1 MySQL 架构"></a>1 MySQL 架构</h3><ul>
<li><em>Server 层</em>：建立连接、分析和执行 SQL；主要包括连接器、查询缓存、分析器、优化器、执行器等，所有跨存储引擎的功能都在这一层实现，比如存储过程、触发器、视图，函数等，还有一个通用的日志模块 binglog 日志模块。</li>
<li><em>存储引擎层</em>：主要负责数据的存储和读取，采用可以替换的插件式架构，支持 InnoDB、MyISAM、Memory 等多个存储引擎，其中 InnoDB 引擎有自有的日志模块 redolog 模块。<strong>现在最常用的存储引擎是 InnoDB，它从 MySQL 5.5.5 版本开始就被当做默认存储引擎了。</strong></li>
</ul>
<h3 id="2-SQL-语句执行过程"><a href="#2-SQL-语句执行过程" class="headerlink" title="2 SQL 语句执行过程"></a>2 SQL 语句执行过程</h3><blockquote>
<p>MySQL 执行一条 select 查询语句，在 MySQL 中期间发生了什么？</p>
<ul>
<li><em>连接器</em>：TCP 三次握手连接</li>
<li><em>查询缓存</em>：先去查询缓存（ Query Cache ）里查找缓存数据</li>
<li><em>解析 SQL</em>：解析器进行词法分析和语法分析</li>
<li><em>执行 SQL</em>：<ul>
<li><code>预处理器</code>：查询表和字段是否存在</li>
<li><code>优化器</code>：确定 SQL 语句执行方案，选择最高效的索引<ul>
<li>explain：select_type 查询类型； type 连接方式；key 用到的索引；rows 扫描出的行数</li>
</ul>
</li>
<li><code>执行器</code>：<ul>
<li>主键索引查询：选择符合的记录</li>
<li>全表扫描</li>
<li><strong><em>索引下推</em></strong>：<code>减少二级索引在查询时的回表操作</code>，将查询条件下推到存储引擎层面进行判断，而不是将数据加载到内存中由应用层进行过滤</li>
<li>exp： <code>where age &gt; 20 and reward = 100000</code>, 其中 age 可以用到联合索引，通过下推后，直接在存储引擎中过滤出<code>reward = 100000</code>的记录再去回表；<h3 id="3-记录存储"><a href="#3-记录存储" class="headerlink" title="3 记录存储"></a>3 记录存储</h3></li>
</ul>
</li>
</ul>
</li>
<li>数据存放：表结构（t_order.frm），表数据（t_order.ibd）</li>
<li>表空间文件结构：段（segment）、区（extent）、页（page，16KB）、行（row）</li>
<li><code>null 存储</code>：Compact 行格式中会用「NULL值列表」来标记值为 NULL 的列，NULL 值并不会存储在行格式中的真实数据部分</li>
<li>页的大小和结构： 16KB 文件头 页头 最小和最大记录 用户记录 空闲空间 页目录 文件尾</li>
<li>innodb的行格式：<img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/mysql/row_format/COMPACT.drawio.png" alt=""><pre><code>  1. 变长字段的真实数据占用的字节数会按照列的顺序**逆序存放**    **使得位置靠前的记录的真实数据和数据对应的字段长度信息可以同时在一个 CPU Cache Line 中，这样就可以提高 CPU Cache 的命中率**。
  2. trx_id   事务id；roll_pointer  记录上一个版本的指针
</code></pre></li>
</ul>
</blockquote>
<h2 id="2-索引"><a href="#2-索引" class="headerlink" title="2. 索引"></a>2. 索引</h2><h3 id="1-索引简介与-B-树"><a href="#1-索引简介与-B-树" class="headerlink" title="1 索引简介与 B+树"></a>1 索引简介与 B+树</h3><h4 id="1-1-什么是索引？"><a href="#1-1-什么是索引？" class="headerlink" title="1.1 什么是索引？"></a>1.1 什么是索引？</h4><ul>
<li>帮助存储引擎快速获取数据的一种数据结构</li>
<li>缺点：本身会占据物理空间；创建索引和维护索引要耗费时间；降低表的增删改的效率</li>
<li>使用场合：字段有唯一性限制，表数据多，更新不频繁<h4 id="1-2-B-树"><a href="#1-2-B-树" class="headerlink" title="1.2 B+树"></a>1.2 B+树</h4><blockquote>
<p>主键索引和二级索引默认使用的是 B+Tree 索引</p>
</blockquote>
</li>
<li><em>什么是 B+树？</em><ul>
<li>B 树：多叉树，左小右大，每个节点都包含索引和数据</li>
<li><em>B+树</em>:就是 B 树的升级<ul>
<li>叶子节点（最底部的节点）才会存放实际数据（索引+记录），非叶子节点只会存放索引</li>
<li>所有索引都会在叶子节点出现，叶子节点之间构成一个<code>有序链表</code></li>
<li>非叶子节点中有多少个子节点，就有多少个索引</li>
<li>B+ 树点节点内容是数据页，数据页里存放了用户的记录以及各种信息，每个数据页默认大小是 16 KB</li>
</ul>
</li>
</ul>
</li>
<li><em>B+树优点</em>：<ul>
<li>B+树的非叶子节点可以存放更多的索引，出度更大</li>
<li>范围查询效率更高</li>
</ul>
</li>
<li>单表最大值：一般三层就可以存放两千万行数据，超过可能增加层级；内存放不下索引<h3 id="2-索引分类"><a href="#2-索引分类" class="headerlink" title="2 索引分类"></a>2 索引分类</h3></li>
<li>按数据结构： B+Tree 索引、HASH 索引、Full-Text 索引</li>
<li>按物理存储： <strong>聚簇索引（主键索引）、二级索引（辅助索引）</strong> 叶子节点存放的是主键值，还要回表</li>
<li>按字段特性： <strong>主键索引、唯一索引、普通索引、前缀索引</strong></li>
<li>按字段个数： <strong>单列索引、联合索引</strong>   <ul>
<li>最左匹配原则：按照最左优先的方式进行索引的匹配</li>
<li>exp：（a，b，c）的索引会先按 a 排序，在 a 相同的情况下按 b 排序，再按 c 排序，因此<code>b 和 c 是全局无序，局部相对有序的</code>，所以 <code>where b=2 and c=3；</code> 无法利用索引</li>
<li>where a &gt; 1 and b = 2  只有 a 能利用联合索引<h3 id="3-索引优化"><a href="#3-索引优化" class="headerlink" title="3 索引优化"></a>3 索引优化</h3></li>
</ul>
</li>
</ul>
<ol>
<li><code>前缀索引</code>优化： 可以减小索引项的大小，但是不能成为覆盖索引</li>
<li><code>覆盖索引</code>优化： 直接从二级索引获取数据，避免回表</li>
<li>主键索引<code>自增</code>：插入效率高；避免造成页分裂；主键字段的长度不要太大，减小二级索引规模</li>
<li>索引设置 NOT NULL：方便优化器选择<h3 id="4-索引失效"><a href="#4-索引失效" class="headerlink" title="4 索引失效"></a>4 索引失效</h3></li>
</ol>
<ul>
<li>使用左或者左右模糊匹配，like %xx</li>
<li>在查询条件中对索引列做了计算、函数、类型转换操作</li>
<li>联合索引未遵循最左匹配原则</li>
<li>WHERE 子句中， OR 前的条件列是索引列， OR 后不是，那么索引会失效<h2 id="3-事务"><a href="#3-事务" class="headerlink" title="3 事务"></a>3 事务</h2><h3 id="1-事务的特性-ACID"><a href="#1-事务的特性-ACID" class="headerlink" title="1 事务的特性 ACID"></a>1 事务的特性 ACID</h3></li>
<li><em><strong>原子性（Atomicity）</strong></em>：一个事务中的所有操作，要么全部完成，要么全部不完成，不会结束在中间某个环节，而且事务在执行过程中发生错误，会被回滚到事务开始前的状态； <code>由 undo log（回滚日志保证）</code></li>
<li><em><strong>一致性（Consistency）</strong></em>：是指事务操作前和操作后，数据满足完整性约束，数据库保持一致性状态  <code>由持久性+原子性+隔离性 共同保证</code></li>
<li><em><strong>隔离性（Isolation）</strong></em>：防止多个事务并发执行时由于交叉执行而导致数据的不一致   <code>MVCC（多版本并发控制） 或锁机制</code></li>
<li><em><strong>持久性（Durability）</strong></em>：事务处理结束后，对数据的修改就是永久的，即便系统故障也不会丢失。     <code>redo log （重做日志）</code><h3 id="2-并行事务的问题"><a href="#2-并行事务的问题" class="headerlink" title="2 并行事务的问题"></a>2 并行事务的问题</h3></li>
<li><strong>脏读</strong>： 一个事务「读到」了另一个「<strong>未提交事务修改过的数据</strong>」</li>
<li><strong>不可重复读</strong>：在一个事务内多次读取同一个数据，前后两次读到的<strong>数据</strong>不一样</li>
<li><strong>幻读</strong>：在一个事务内多次查询某个符合查询条件的「记录数量」，前后两次查询到的<strong>记录数量</strong>不一样<h3 id="3-事务的隔离级别"><a href="#3-事务的隔离级别" class="headerlink" title="3 事务的隔离级别"></a>3 事务的隔离级别</h3></li>
<li><strong>读未提交（<em>read uncommitted</em>）</strong>，指一个事务还没提交时，它做的变更就能被其他事务看到； <strong>会脏读</strong></li>
<li><strong>读提交（<em>read committed</em>）</strong>，指一个事务提交之后，它做的变更才能被其他事务看到； <strong>会不可重复读</strong></li>
<li><strong>可重复读（<em>repeatable read</em>）</strong>，指一个事务执行过程中看到的数据，一直跟这个事务启动时看到的数据是一致的，<strong>MySQL InnoDB 引擎的默认隔离级别</strong>； <strong>会幻读</strong></li>
<li><strong>串行化（<em>serializable</em> ）</strong>；会对记录加上读写锁，在多个事务对这条记录进行读写操作时，如果发生了读写冲突的时候，后访问的事务必须等前一个事务执行完成，才能继续执行；  都不会，但是影响性能</li>
<li><em>默认的隔离级别</em>：可重复读，用以下方法解决幻读<ul>
<li>针对<strong>快照读</strong>（普通 select 语句），是<strong>通过 MVCC 方式解决了幻读</strong></li>
<li>针对<strong>当前读</strong>（select … for update 等语句），是<strong>通过 next-key lock（记录锁+间隙锁）方式解决了幻读</strong></li>
</ul>
</li>
<li>幻读完全解决了吗？ 没有<ol>
<li>对于快照读，当事务 A 更新了一条事务 B 插入的记录，那么事务 A 前后两次查询的记录条目就不一样了，就会产生幻读</li>
<li>对于当前读，如果事务开启后，并没有执行当前读，而是先快照读，然后这期间如果其他事务插入了一条记录，那么事务后续使用当前读进行查询的时候，就会发现两次查询的记录条目就不一样了，所以就发生幻读。</li>
<li>在开启事务之后，马上执行 select … for update 这类当前读的语句</li>
</ol>
</li>
</ul>
<h3 id="4-MVCC-与-ReadView"><a href="#4-MVCC-与-ReadView" class="headerlink" title="4 MVCC 与 ReadView"></a>4 MVCC 与 ReadView</h3><ul>
<li><em>MVCC 原理</em>？<ul>
<li>Multi-Version Concurrency Control 多版本并发控制</li>
<li>核心思想是为每个事务创建一个独立的数据库快照，每个事务在操作时都会基于事务 ID 来访问数据库的对应版本</li>
</ul>
</li>
<li><em>ReadView 的数据结构</em>？  四个字段和聚簇索引记录中的两个隐藏列<ul>
<li><code>m_ids</code> ：指的是在创建 Read View 时，当前数据库中「活跃事务」的<strong>事务 id 列表</strong>，注意是一个列表，<strong>“活跃事务”指的就是，启动了但还没提交的事务</strong>。</li>
<li><code>min_trx_id</code> ：指的是在创建 Read View 时，当前数据库中「活跃事务」中事务 <strong>id 最小的事务</strong>，也就是 m_ids 的最小值。</li>
<li><code>max_trx_id</code> ：这个并不是 m_ids 的最大值，而是<strong>创建 Read View 时当前数据库中应该给下一个事务的 id 值</strong>，也就是全局事务中最大的事务 id 值 + 1；</li>
<li><code>creator_trx_id</code> ：指的是<strong>创建该 Read View 的事务的事务 id</strong>。</li>
<li><code>trx_id</code>，当一个事务对某条聚簇索引记录进行改动时，就会<strong>把该事务的事务 id 记录在 trx_id 隐藏列里</strong>；</li>
<li><code>roll_pointer</code>，每次对某条聚簇索引记录进行改动时，都会把旧版本的记录写入到 undo 日志中，然后<strong>这个隐藏列是个指针，指向每一个旧版本记录</strong>，于是就可以通过它找到修改前的记录。</li>
</ul>
</li>
<li><em>可重复读实现</em>？<ul>
<li>启动事务时生成一个 Read View，然后整个事务期间都在用这个 Read View</li>
</ul>
</li>
<li><em>读提交实现</em>？<ul>
<li>在每次读取数据时，都会生成一个新的 Read View</li>
</ul>
</li>
</ul>
<h2 id="4-锁"><a href="#4-锁" class="headerlink" title="4. 锁"></a>4. 锁</h2><h3 id="1-MySQL-有哪些锁？"><a href="#1-MySQL-有哪些锁？" class="headerlink" title="1 MySQL 有哪些锁？"></a>1 MySQL 有哪些锁？</h3><h4 id="1-1-全局锁"><a href="#1-1-全局锁" class="headerlink" title="1.1 全局锁"></a>1.1 全局锁</h4><ul>
<li><em>启用</em>：flush tables with read lock    数据库处于只读状态</li>
<li><em>使用场景</em>：全库备份</li>
<li>如果数据库的引擎支持的事务支持<strong>可重复读的隔离级别</strong>，那么在备份数据库之前先开启事务，会先创建 Read View，然后整个事务执行期间都在用这个 Read View，而且由于 MVCC 的支持，备份期间业务依然可以对数据进行更新操作<h4 id="1-2-表级锁"><a href="#1-2-表级锁" class="headerlink" title="1.2 表级锁"></a>1.2 表级锁</h4></li>
<li><em>表锁</em>：颗粒度太大，性能较差</li>
<li><em>元数据锁</em>：防止其他线程变更表结构</li>
<li><em>意向锁</em>：<strong>快速判断表里是否有记录被加锁</strong><ul>
<li>当执行插入、更新、删除操作，需要先对表加上「意向独占锁」，然后对该记录加独占锁</li>
</ul>
</li>
<li><em>AUTO-INC 锁</em>：实现主键自增<ul>
<li>在插入数据时，会加一个表级别的 AUTO-INC 锁，插入语句完成后就释放<h4 id="1-3-行级锁"><a href="#1-3-行级锁" class="headerlink" title="1.3 行级锁"></a>1.3 行级锁</h4></li>
</ul>
</li>
<li><em>Record Lock</em>：记录锁，锁住一条记录；只有 S 型记录锁兼容</li>
<li><em>Gap Lock</em>：间隙锁，解决可重复读隔离级别下的幻读现象； 如（3，5）会锁住 4</li>
<li><em>Next-Key Lock</em>：Record Lock + Gap Lock 的组合，锁定一个范围，并且锁定记录本身；（3，5] 锁住 4，5</li>
<li><em>插入意向锁</em>：插入有间隙锁位置会发生<strong>阻塞</strong>，生成一个<strong>插入意向锁</strong>，表明有事务想在某个区间插入新记录，但是现在处于等待状态</li>
<li>Innodb 在扫描记录的时，都是针对索引项这个单位去加锁的， update 不带索引就是全表扫描，也就是表里的索引项都加锁，相当于锁了整张表<h4 id="1-4-死锁"><a href="#1-4-死锁" class="headerlink" title="1.4 死锁"></a>1.4 死锁</h4></li>
<li>两个事务即使生成的间隙锁的范围是一样的，也不会发生冲突，因为间隙锁目的是为了防止其他事务插入数据，因此间隙锁与间隙锁之间是相互兼容的。</li>
<li>在执行插入语句时，如果插入的记录在其他事务持有间隙锁范围内，插入语句就会被阻塞，因为插入语句在碰到间隙锁时，会生成一个插入意向锁，然后插入意向锁和间隙锁之间是互斥的关系。</li>
<li>如果两个事务分别向对方持有的间隙锁范围内插入一条记录，而插入操作为了获取到插入意向锁，都在等待对方事务的间隙锁释放，于是就造成了循环等待，满足了死锁的四个条件：<strong>互斥、占有且等待、不可强占用、循环等待</strong>，因此发生了死锁</li>
<li>事务 A 和事务 B 在执行完后 update 语句后都持有范围为<code>(20, 30）</code>的间隙锁，而接下来的插入操作为了获取到插入意向锁，都在等待对方事务的间隙锁释放，于是就造成了循环等待</li>
</ul>
<h2 id="5-日志"><a href="#5-日志" class="headerlink" title="5. 日志"></a>5. 日志</h2><h3 id="1-undo-log（回滚日志）"><a href="#1-undo-log（回滚日志）" class="headerlink" title="1 undo log（回滚日志）"></a>1 undo log（回滚日志）</h3><ul>
<li>innodb 存储引擎层生成的日志，实现了事务中的 <em><strong>原子性</strong></em> ，主要用于事务回滚和 MVCC</li>
<li>当 InnoDB 引擎对一条记录进行操作（修改、删除、新增）时，要把回滚时需要的信息都记录到 undo log 里</li>
<li>在<code>事务没提交之前</code>，MySQL 会先记录更新前的数据到 undo log 日志文件里面</li>
<li><em>ReadView + undo log 实现 MVCC</em>：undo log 为每条记录保存多份历史数据，MySQL 在执行快照读（普通 select 语句）的时候，会根据事务的 Read View 里的信息，顺着 undo log 的<code>版本链</code>找到满足其<code>可见性</code>的记录</li>
<li>持久化：buffer pool 中有 undo 页，对 undo 页的修改也都会记录到<code>redo log</code>，redo log 会每秒刷盘，提交事务时也会刷盘<h3 id="2-Buffer-Pool-缓冲池"><a href="#2-Buffer-Pool-缓冲池" class="headerlink" title="2 Buffer Pool  缓冲池"></a>2 Buffer Pool  缓冲池</h3></li>
<li><em>基于内存，提高数据库的读写性能</em></li>
<li><em>Buffer Pool 缓存什么</em>：「索引页」和「数据页」，还包括了 Undo 页，插入缓存、自适应哈希索引、锁信息等</li>
<li>修改记录先缓存 到 change buffer，找机会去写入磁盘<pre><code>  1. 唯一索引不会用 change buffer，因为对应数据页已经加载到内存了--判断唯一性
  2. 优点：减少磁盘访问次数；提高内存利用率
</code></pre></li>
<li><strong>缓页管理方式</strong><pre><code>  1. Free List （空闲页链表），管理空闲页；
  2. Flush List （脏页链表），管理脏页；
  3. LRU List，管理脏页+干净页，将最近且经常查询的数据缓存在其中，而不常查询的数据就淘汰出去；分为 young 和 old 两个区域，先插入 old，被访问进入 young，解决数据批量访问，和大量热数据淘汰的问题；
</code></pre><h3 id="3-redo-log（物理日志）"><a href="#3-redo-log（物理日志）" class="headerlink" title="3 redo log（物理日志）"></a>3 redo log（物理日志）</h3></li>
<li>作用：记录了某个数据页做了什么修改，在事务提交时，只要先将 redo log 持久化到磁盘即可；记录了事务「<strong>完成后</strong>」的数据状态，记录的是更新<strong>之后</strong>的值</li>
<li><strong><em>预写日志WAL</em></strong>：写操作并不是立刻写到磁盘上，而是先写日志，后面再等待时机写入磁盘</li>
<li><strong><em>crash-safe</em></strong>（崩溃恢复）：即使数据库发生异常重启，之前已提交的记录都不会丢失，保证了持久性</li>
<li><strong>优点</strong>：redo log 是追加操作，所以是顺序写，开销更小</li>
<li><strong>刷盘时机</strong>： 事务提交；每秒；关闭数据库； redo log buffer占用过半</li>
<li>redo log满了？阻塞，刷新脏页到磁盘，擦除 对应的 redo log 记录腾出空间</li>
</ul>
<h3 id="4-bin-log"><a href="#4-bin-log" class="headerlink" title="4 bin log"></a>4 bin log</h3><ul>
<li>undo 和 redo 都是Innodb 存储引擎生成的，binlog 是 Server 层生成的</li>
<li>使用对象：Server 层实现的日志，所有存储引擎都可以使用</li>
<li>文件格式： STATEMENT（默认格式，记录 SQL）、ROW（记录行数据）、 MIXED</li>
<li>写入方式：追加写，会覆盖以前的日志，保存的是全量的日志。</li>
<li>作用：用于<strong>主从复制，备份恢复</strong></li>
<li>binlog cache刷盘：事务提交，内存超了</li>
<li><strong><em>主从复制实现</em></strong><ol>
<li><em>主从复制流程</em><ol>
<li><strong>写入 Binlog</strong>：主库写 binlog 日志，提交事务，并更新本地存储数据。</li>
<li><strong>同步 Binlog</strong>：把 binlog 复制到所有从库上，每个从库把 binlog 写到暂存日志中。</li>
<li><strong>回放 Binlog</strong>：回放 binlog，并更新存储引擎中的数据。</li>
</ol>
</li>
<li><em>复制步骤</em><ol>
<li>主节点log dump线程：当从节点连接主节点时，主节点会创建一个log dump 线程，用于发送bin-log的内容。在读取bin-log中的操作时，此线程会对主节点上的bin-log加锁，当读取完成，甚至在发动给从节点之前，锁会被释放。</li>
<li>从节点I/O线程：当从节点上执行<code>start slave</code>命令之后，从节点会创建一个I/O线程用来连接主节点，请求主库中更新的bin-log。I/O线程接收到主节点bin log dump 进程发来的更新之后，保存在本地relay-log中。</li>
<li>从节点SQL线程：SQL线程负责读取relay log中的内容，解析成具体的操作并执行，最终保证主从数据的一致性。</li>
</ol>
</li>
<li><em>复制模型</em><ol>
<li>同步复制：性能差</li>
<li>异步复制：主库宕机数据会丢失</li>
<li>半同步复制：从库成功一个就行</li>
</ol>
</li>
<li><em>主从同步延迟</em><ol>
<li>从库只有一个sql Thread，主库写压力大，复制很可能延时；或者从库有大型 query 产生锁等待</li>
<li>解决：要求高就走主库；sleep 一下；判断一下主备延迟</li>
</ol>
</li>
</ol>
</li>
<li><strong><em>两阶段提交</em></strong>    防止<strong>redo log</strong>和<strong>binlog</strong>不一致，导致主从数据不一致；内部 XA 事务<ol>
<li><strong><em>prepare</em> 阶段</strong>：将 redo log 对应的事务状态设置为 prepare，然后将 redo log 刷新到硬盘；</li>
<li><strong><em>commit 阶段</em></strong>：将 binlog 刷新到磁盘，接着调用引擎的提交事务接口，将 redo log 状态设置为 commit（将事务设置为 commit 状态后，刷入到磁盘 redo log 文件）；</li>
<li><strong>是否能在 binlog 中查找到与 redo log 相同的 XID</strong>，如果有就提交事务，如果没有就回滚事务。</li>
<li>组提交：<strong>有多个事务提交的时候，会将多个 binlog 刷盘操作合并成一个，从而减少磁盘 I/O 的次数</strong></li>
<li>问题：磁盘 IO 次数高，锁竞争激烈</li>
</ol>
</li>
</ul>
<h2 id="6-架构与-SQL-基础"><a href="#6-架构与-SQL-基础" class="headerlink" title="6. 架构与 SQL 基础"></a>6. 架构与 SQL 基础</h2><h3 id="1-SQL-基础"><a href="#1-SQL-基础" class="headerlink" title="1 SQL 基础"></a>1 SQL 基础</h3><ol>
<li><em>数据库四大范式</em><ol>
<li>第一范式（1NF）：属性不可拆分 或 无重复的列</li>
<li>第二范式（2NF）：非主属性对多属性候选键完全函数依赖</li>
<li>第三范式（3NF）：消除传递依赖  表中不包含已在其它表中已包含的非主属性信息。</li>
<li>BC范式（BCNF）：候选键存在多个属性时，多个主属性直接要消除传递依赖关系     主属性之间不应该有互相依赖。工号和身份证号是相互依赖。</li>
<li>第四范式（4NF）：对于候选键只能存在不超过1个多值属性。要求把同一表内的多对多关系删除。</li>
</ol>
</li>
<li><em>分页查询后期性能变慢的原因</em>    深分页问题<ol>
<li><strong>limit m n</strong>：查询从 m 开始的 n 条数据；扫 m+n 行 丢弃前 m 行</li>
<li><strong>limit n offset m</strong>：从 m 开始的 n 条</li>
<li><code>为什么慢</code>？ <ol>
<li>分页偏移量的增加，需要扫描和跳过的前面的行来到达指定的偏移量，造成浪费，也就是说<code>limit 100000,10</code>，就会扫描100010行</li>
<li><code>limit 100000,10</code> 扫描更多的行数，也意味着回表判断的次数更多</li>
</ol>
</li>
<li>优化：<ol>
<li>子查询优化：把条件转移到主键索引树，然后减少回表，比如先查到第 10000 个</li>
<li>INNER JOIN 延迟关联：先通过二级索引树查询到满足条件的主键ID，再与原表通过主键ID内连接</li>
<li>基于游标的分页：使用游标或主键来定位结果集中的特定行，而不是使用偏移量。这种方法通常比OFFSET更高效</li>
<li>使用between…and…：转换成已知位置的查询</li>
<li>使用合适的索引：确保查询中使用了适当的索引，以减少排序和过滤操作的成本</li>
</ol>
</li>
</ol>
</li>
<li>SQL(聚集函数，group by， having 子句， order by, 连接(内连接、外连接(左右)))<ol>
<li><strong>group by</strong>： 根据一个或多个列对结果集进行分组</li>
<li><strong>having</strong>：筛选分组后的各组数据    where在group by前， having在group by 之后</li>
<li><strong>order by</strong>：排序  desc 降序； asc 升序</li>
<li>连接：<ol>
<li>inner join：  只取交集</li>
<li>left join：左表所有行和右表匹配的，不匹配的行返回 null</li>
<li>right join：和上面类似</li>
<li>full join：全连接，取并集</li>
</ol>
</li>
</ol>
</li>
<li>慢查询日志<ol>
<li>set global slow_query_log = on;  long_query_time</li>
<li>mysqldumpslow进行分析<h3 id="2-架构"><a href="#2-架构" class="headerlink" title="2 架构"></a>2 架构</h3></li>
</ol>
</li>
<li>MySQL集群的结构有哪些？各自优缺点？<ol>
<li>主从架构  读写分离，数据备份</li>
<li>主主互备  </li>
</ol>
</li>
<li>分库分表的场景？   数据库性能瓶颈  <strong>IO瓶颈</strong>   <strong>CPU瓶颈</strong><ol>
<li>水平分库： 按 hash 或者 range 策略分到多个库里； 应对高并发</li>
<li>水平分表：将一个表中的数据拆分到多个表中；单表数据太多，影响 SQL 效率；</li>
<li>垂直分库：按业务归属不同分库；可以抽象出单独的业务模块</li>
<li>垂直分表：按照字段的活跃性，将表中字段拆到不同的表（主表和扩展表）中。  字段多，热点数据分离出来；不可用 join</li>
<li>分配策略： hash 取模；范围分片；地理位置；时间</li>
</ol>
</li>
<li>如何不停服迁移库表？<ol>
<li><strong>不停服，增加缓冲层（MQ），数据迁移过程中增量数据写入缓存，在数据迁移完成、缓冲层数据消费完成后，打开开关开始双写数据库</strong></li>
</ol>
</li>
<li>怎么分库分表才能均匀？分库分表后某些分片热点写入怎么解决？<ol>
<li>使用哈希算法：对于分片键（通常是某个列或多个列的组合），使用哈希算法来决定数据应该存储在哪个分片上。这样可以确保数据在分片之间均匀分布，减少热点问题。</li>
<li>增加分片数量：**如果你发现某些分片写入热点问题，可以考虑增加分片的数量。这会增加分片的数量，减少每个分片的负载，提高了吞吐量。</li>
<li>负载均衡：使用负载均衡策略来确保访问请求均匀地分布到不同的分片上。负载均衡可以在应用层或数据库代理层实现。</li>
<li>随机数分片：使用随机数来分配数据到分片，这可以减少数据的热点写入问题，但可能增加查询的复杂性。</li>
<li>分片键设计：精心设计分片键是解决热点写入问题的关键。尽量避免选择容易导致热点的分片键，例如自增主键。</li>
<li>数据迁移：定期监测数据分布，如果发现某个分片过于热点，可以考虑进行数据迁移，将一些数据从热点分片移到其他分片上，以实现负载均衡。</li>
<li>垂直分片：考虑将表按照功能或业务需求进行垂直分片，将不同类型的数据存储在不同的分片上。这可以减少写入热点问题。</li>
<li>缓存：使用缓存来缓解数据库写入压力。将热点数据缓存到内存中，减少对数据库的频繁写入请求。</li>
<li>异步写入：如果一些写入操作不需要立即生效，可以考虑将它们异步化，以减轻数据库的写入负载。例如，使用消息队列将写入操作异步处理。</li>
</ol>
</li>
<li>数据库主库挂了，在存在主从延时的情况下，切从的过程中，查询的数据不一致怎么处理<ol>
<li><strong>等待同步完成</strong>：在进行主从切换前，可以等待从库追赶主库的进度，确保从库的数据已经和主库同步完全。这可以通过监测主从延时来确定。一旦主从延时减少到可以接受的水平，再进行切换。</li>
<li><strong>切换到可用从库</strong>：如果主从切换后发现某个从库数据不一致，可以尝试切换到另一个可用的从库。这需要确保备用从库与主库的数据同步是正常的。</li>
<li><strong>手动同步数据</strong>：在切换完成后，可以考虑手动同步数据以修复不一致。这可能涉及将缺失的数据从主库手动导入到从库，以确保一致性。</li>
<li><strong>数据一致性检查</strong>：在切换后，可以运行一些数据一致性检查工具或脚本来检查数据是否一致。如果发现不一致的数据，可以进行修复。</li>
<li><strong>定期备份</strong>：在数据库正常运行期间，定期进行数据库备份，包括主库和从库。在切换后，如果出现数据不一致问题，可以使用备份进行恢复。</li>
<li><strong>容错和监控</strong>：实现主从切换时，确保有足够的监控和容错机制。这样，如果出现问题，可以迅速发现并采取措施来减小数据不一致的风险。</li>
<li><strong>故障回滚</strong>：如果切换后发现数据不一致问题无法解决，可以考虑回滚到原来的主库，然后采取更谨慎的方式来进行切换，例如逐渐减小主从延时。</li>
</ol>
</li>
</ol>

    
    
  </div>

  

  

</article>
  
  <article class="post">
  <header class="post-header">
    <h1 class="post-title">
      
      <a class="post-link" href="/2023/09/09/Framework/Kafka/"></a>
      
    </h1>

    <div class="post-meta">
      <span class="post-time">
        2023-09-09
      </span>
      
      
      
    </div>
  </header>

  

  <div class="post-content">
    
    
    

    
    <figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"></span><br></pre></td></tr></table></figure>
<h2 id="Kafka-基础"><a href="#Kafka-基础" class="headerlink" title="Kafka 基础"></a>Kafka 基础</h2><h3 id="1-架构"><a href="#1-架构" class="headerlink" title="1 架构"></a>1 架构</h3><blockquote>
<p>分布式的、分区化、可复制提交的日志服务<br><img src="https://pic1.zhimg.com/80/v2-672b6f858c187b5c8182c553cd597f14_1440w.webp" alt=""></p>
<ul>
<li><em>Producer</em>：消息生产者，就是向 kafka broker 发消息的客户端。</li>
<li><em>Consumer</em> ：消息消费者，向 kafka broker 取消息的客户端。</li>
<li><em>Topic</em> ：可以理解为一个队列，一个 Topic 又分为一个或多个分区。</li>
<li><em>Consumer Group</em>：这是 kafka 用来实现一个 topic 消息的广播（发给所有的 consumer）和单播（发给任意一个 consumer）的手段。一个 topic 可以有多个 Consumer Group。</li>
<li><em>Broker</em> ：一台 kafka 服务器就是一个 broker。一个集群由多个 broker 组成。一个 broker 可以容纳多个 topic。</li>
<li><em>Partition</em>：为了实现扩展性，一个非常大的 topic 可以分布到多个 broker上，每个 partition 是一个有序的队列。partition 中的每条消息都会被分配一个有序的id（offset）。将消息发给 consumer，kafka 只保证按一个 partition 中的消息的顺序，不保证一个 topic 的整体（多个 partition 间）的顺序。</li>
<li><em>Offset</em>：kafka 的存储文件都是按照 offset.kafka 来命名，用 offset 做名字的好处是方便查找。例如你想找位于 2049 的位置，只要找到 2048.kafka 的文件即可。当然 the first offset 就是00000000000.kafka。<h3 id="2-特点"><a href="#2-特点" class="headerlink" title="2 特点"></a>2 特点</h3></li>
<li><em>高吞吐量、低延迟</em>：每秒可以处理几十万条消息，它的延迟最低只有几毫秒，每个topic可以分多个partition, consumer group 对partition进行consume操作。</li>
<li><em>可扩展性</em>：kafka集群支持热扩展</li>
<li><em>持久性、可靠性</em>：消息被持久化到本地磁盘，并且支持数据备份防止数据丢失</li>
<li><em>容错性</em>：允许集群中节点失败（若副本数量为n,则允许n-1个节点失败）</li>
<li><em>高并发</em>：支持数千个客户端同时读写<h3 id="3-怎么实现高吞吐量的？"><a href="#3-怎么实现高吞吐量的？" class="headerlink" title="3 怎么实现高吞吐量的？"></a>3 怎么实现高吞吐量的？</h3></li>
<li><em>分区</em>：多分区通过负载均衡提高了消息并发写入和消费的能力</li>
<li><em>批量发送和压缩消息</em>：<ul>
<li><code>批量发送</code>：将消息缓存在内存中的双端队列中，然后Sender线程将从各分区对应的队列中获取已准备好的消息批次，将消息进行批量发送，减少网络传输频次，提高传输效率。</li>
<li><code>端到端压缩消息</code>：将一批消息打包后进行压缩，在 Consumer 端进行解压</li>
</ul>
</li>
<li><em>顺序读写</em>：将消息messaga追加到本地磁盘文件的末尾</li>
<li><em>零拷贝ZeroCopy</em>：将数据直接从磁盘文件复制到网卡设备中，避免重新复制数据<ul>
<li>操作系统从磁盘读取数据到内核空间的 pagecache</li>
<li>应用程序读取内核空间的数据到用户空间的缓冲区</li>
<li>应用程序将数据(用户空间的缓冲区)写回内核空间到套接字缓冲区(内核空间)</li>
<li>操作系统将数据从套接字缓冲区(内核空间)复制到通过网络发送的 NIC 缓冲区</li>
</ul>
</li>
<li><em>PageCache</em>：利用了现代操作系统分页存储 Page Cache 来利用内存提高 I/O 效率<h3 id="4-高可靠性实现"><a href="#4-高可靠性实现" class="headerlink" title="4 高可靠性实现"></a>4 高可靠性实现</h3></li>
<li>副本机制</li>
<li><h3 id="5-使用场景"><a href="#5-使用场景" class="headerlink" title="5 使用场景"></a>5 使用场景</h3></li>
<li>日志收集</li>
<li>消息系统</li>
<li>用户活动跟踪<h2 id="主题与日志"><a href="#主题与日志" class="headerlink" title="主题与日志"></a>主题与日志</h2><h3 id="1-Kafka创建Topic时如何将分区放置到不同的Broker中"><a href="#1-Kafka创建Topic时如何将分区放置到不同的Broker中" class="headerlink" title="1 Kafka创建Topic时如何将分区放置到不同的Broker中"></a>1 Kafka创建Topic时如何将分区放置到不同的Broker中</h3></li>
<li>副本因子不能大于 Broker 的个数；</li>
<li>第一个分区（编号为0）的第一个副本放置位置是随机从 brokerList 选择的；</li>
<li>其他分区的第一个副本放置位置相对于第0个分区依次往后移。也就是如果我们有5个 Broker，5个分区，假设第一个分区放在第四个 Broker 上，那么第二个分区将会放在第五个 Broker 上；第三个分区将会放在第一个 Broker 上；第四个分区将会放在第二个 Broker 上，依次类推；</li>
<li>剩余的副本相对于第一个副本放置位置其实是由 nextReplicaShift 决定的，而这个数也是随机产生的<h3 id="2-Kafka-分区数可以增加或减少吗？为什么？"><a href="#2-Kafka-分区数可以增加或减少吗？为什么？" class="headerlink" title="2 Kafka 分区数可以增加或减少吗？为什么？"></a>2 Kafka 分区数可以增加或减少吗？为什么？</h3></li>
<li>可以使用 bin/kafka-topics.sh命令对 Kafka 增加 Kafka 的分区数据，但是 Kafka 不支持减少分区数。</li>
<li>Kafka 分区数据不支持减少是由很多原因的，比如减少的分区其数据放到哪里去？是删除，还是保留？删除的话，那么这些没消费的消息不就丢了。如果保留这些消息如何放到其他分区里面？追加到其他分区后面的话那么就破坏了 Kafka 单个分区的有序性。如果要保证删除分区数据插入到其他分区保证有序性，那么实现起来逻辑就会非常复杂</li>
<li>会在含有分区目录最少的文件夹中创建新的分区目录<h3 id="3-kafka分区是不是越多越好"><a href="#3-kafka分区是不是越多越好" class="headerlink" title="3 kafka分区是不是越多越好"></a>3 kafka分区是不是越多越好</h3></li>
<li>句柄开销过大：每增加一个分区，对应的也会增加一个文件描述符，而一个进程所能支配的文件描述符是有限的，这也就是通常说的文件句柄开销。当分区数量超过进程能支配的文件描述符数量时，将出现 <code>Too many open files</code>错误.</li>
<li>生产端占用内存过大：kafka 发送消息时不是立刻发送的，而是会先将每个分区的消息先进行缓存（缓存区大小由<code>batch.size</code>设置，默认16KB），缓存满了后才会发送消息。分区越多的情况下，分区占用的缓存区也将更大。</li>
<li>影响系统可用性：broker数量一定的情况下，分区数量越大则每个broker 中所拥有的分区leader副本数量也将更多。broker出现故障后需要进行leader角色切换的分区数量会很大，导致故障恢复时间较长。<h2 id="Producer"><a href="#Producer" class="headerlink" title="Producer"></a>Producer</h2><h3 id="1-消息分区选择"><a href="#1-消息分区选择" class="headerlink" title="1 消息分区选择"></a>1 消息分区选择</h3><h3 id="2-Kafka-分区的目的？"><a href="#2-Kafka-分区的目的？" class="headerlink" title="2 Kafka 分区的目的？"></a>2 Kafka 分区的目的？</h3>分区对于 Kafka 集群的好处是：实现负载均衡。分区对于消费者来说，可以提高并发度，提高效率。<h3 id="3-ack参数设置及意义"><a href="#3-ack参数设置及意义" class="headerlink" title="3 ack参数设置及意义"></a>3 ack参数设置及意义</h3>参数设置： 设置 <code>request.required.acks=-1</code> ，只有 ISR 中所有副本都成功写入消息后才认为 kafka 消息成功写入。acks 参数其他配置项意义如下：</li>
<li><code>acks = 1</code>(默认)：分区leader 副本写入成功即认为消息成功写入，只确保leader发送成功</li>
<li><code>acks = 0</code> ：不需要等待任何服务端的响应都可认为消息成功写入，安全性最低但是效率最高。</li>
<li><code>acks = -1/ all</code> ：代表producer往集群发送数据需要所有的follower都完成从leader的同步才会发送下一条，确保 leader发送成功和所有的副本都完成备份。<h3 id="4-幂等特性"><a href="#4-幂等特性" class="headerlink" title="4 幂等特性"></a>4 幂等特性</h3></li>
<li>一次或者多次请求某一个资源对于资源本身应该具有同样的结果</li>
<li><strong>唯一标识</strong>：判断某个请求是否重复，需要有一个唯一性标识，然后服务端就能根据这个唯一标识来判断是否为重复请求。</li>
<li><strong>记录已经处理过的请求</strong>：服务端需要记录已经处理过的请求，然后根据唯一标识来判断是否是重复请求，如果已经处理过，则直接拒绝或者不做任何操作返回成功。</li>
<li>只能保证生产端在单个会话内的幂等，如果生产端因为某些原因意外挂掉然后重启，此时是没办法保证幂等的，因为这时没办法获取到之前的状态信息，即无法做到跨会话级别的幂等。</li>
<li>幂等性不能跨多个主题分区，只能保证单个分区内的幂等，涉及到多个消息分区时，中间的状态并没有同步<h3 id="5-Kafka-是如何做到消息的有序性？"><a href="#5-Kafka-是如何做到消息的有序性？" class="headerlink" title="5 Kafka 是如何做到消息的有序性？"></a>5 Kafka 是如何做到消息的有序性？</h3></li>
<li>kafka 中的每个 partition 中的消息在写入时都是有序的，而且单独一个 partition 只能由一个消费者去消费，可以在里面保证消息的顺序性。但是分区之间的消息是不保证有序的。</li>
<li>设置一个topic一个partition，消费者单线程消费</li>
<li>消息发送指定key，确保相同key的消息发送到同一个partition<h3 id="6-Kafka如何保证消息不丢失"><a href="#6-Kafka如何保证消息不丢失" class="headerlink" title="6 Kafka如何保证消息不丢失"></a>6 Kafka如何保证消息不丢失</h3></li>
<li><em>生产者</em>：ACK 机制</li>
<li><em>broker</em>：多副本和副本同步机制；保证ISR副本数量大于等于二</li>
<li><em>消费者</em>：<ul>
<li>消息消费关闭自动提交，改为手动提交offset，确保消息可再次消费</li>
<li>在第一点的前提下，涉及到消息的重复消费，所以消费端应做好消息的幂等处理<h3 id="7-Kafka-Producer-的执行过程？"><a href="#7-Kafka-Producer-的执行过程？" class="headerlink" title="7 Kafka Producer 的执行过程？"></a>7 Kafka Producer 的执行过程？</h3></li>
</ul>
</li>
<li>Producer生产消息</li>
<li>从Zookeeper找到Partition的Leader</li>
<li>推送消息</li>
<li>通过ISR列表通知给Follower</li>
<li>Follower从Leader拉取消息，并发送ack</li>
<li>Leader收到所有副本的ack，更新Offset，并向Producer发送ack，表示消息写入成功。<h3 id="8-Kafka消息是采用Pull模式，还是Push模式？"><a href="#8-Kafka消息是采用Pull模式，还是Push模式？" class="headerlink" title="8 Kafka消息是采用Pull模式，还是Push模式？"></a>8 Kafka消息是采用Pull模式，还是Push模式？</h3></li>
<li>producer将消息推送到broker，consumer从broker拉取消息</li>
<li>consumer可以自主的根据消费能力和策略决定是否批量的从broker拉取数据<h3 id="9-如何保证消息不被重复消费？"><a href="#9-如何保证消息不被重复消费？" class="headerlink" title="9 如何保证消息不被重复消费？"></a>9 如何保证消息不被重复消费？</h3></li>
<li>生产者在向Kafka写数据时，每条消息会有一个offset，表示消息写入顺序的序号。当消费者消费后，<strong>每隔一段时间会把自己已消费消息的offset通过Zookeeper提交给Kafka</strong>，告知Kafka自己offset的位置。这样一来，如果消费者重启，则会从Kafka记录的offset之后的数据开始消费，从而避免重复消费。</li>
<li>在发生重复消费后，如何<strong>保证消息消费时的幂等性</strong>。如果消费者可以在消费消息时先判断一下，自己是否已经消费了该消息，如果是就不消费，那么就可以保证系统的幂等性。<ul>
<li>数据库查询</li>
<li>redis 用 set 去重</li>
<li>全局 id</li>
</ul>
</li>
</ul>
</blockquote>
<h2 id="Consumer"><a href="#Consumer" class="headerlink" title="Consumer"></a>Consumer</h2><h3 id="1-消费组"><a href="#1-消费组" class="headerlink" title="1 消费组"></a>1 消费组</h3><ul>
<li>多个消费者可以组成一个消费组，每个消费者只属于一个消费组。</li>
<li>消费组订阅主题的每个分区只会分配给该消费组中的某个消费者处理，不同的消费组之间彼此隔离无依赖。</li>
<li>同一个消息只会被消费组中的一个消费者消费，如果想要让同一个消息被多个消费者消费，那么每个消费者需要属于不同的消费组，且对应消费组中只有该一个消费者，消费组的引入可以实现消费的“独占”或“广播”效果。<h3 id="2-重平衡机制"><a href="#2-重平衡机制" class="headerlink" title="2 重平衡机制"></a>2 重平衡机制</h3></li>
<li><em>触发条件</em>：<ul>
<li>消费者数量变化： 新消费者加入、消费者下线、消费者主动退出消费组</li>
<li>消费组内订阅的主题或者主题的分区数量发生变化</li>
<li>消费组对应的 GroupCoorinator 节点发生变化</li>
</ul>
</li>
<li><em>rebalance过程</em>：<ul>
<li>寻找到消费组的 协调者(GroupCoordination)，消费者组提交组位移的 partiotion 所在的 broker</li>
<li>所有消费者向协调者发送 JoinGroup 请求</li>
<li>协调者为消费组选择新的leader</li>
<li>协调者发送 <code>JoinGroupResponse</code> 给各个消费组，其中leader消费者的 <code>JoinGroupResponse</code> 包含了消费组成员信息</li>
<li>leader消费者指定新的消费方案</li>
<li>各消费者向 协调者 发送 <code>SyncGroupRequest</code> 请求，其中 leader消费者的<code>SyncGroupRequest</code> 携带有相关的分配方案</li>
<li>协调者向各消费者下发分区分配方案</li>
</ul>
</li>
<li><em>避免非必要rebalance</em> ：设置合理的心跳发送时间；设置Consumer 消费时间最大间隔<h3 id="3-Kafka-消费者是否可以消费指定分区消息？"><a href="#3-Kafka-消费者是否可以消费指定分区消息？" class="headerlink" title="3 Kafka 消费者是否可以消费指定分区消息？"></a>3 Kafka 消费者是否可以消费指定分区消息？</h3>Kafa consumer消费消息时，向broker发出fetch请求去消费特定分区的消息，consumer指定消息在日志中的偏移量（offset），就可以消费从这个位置开始的消息，customer拥有了offset的控制权，可以向后回滚去重新消费之前的消息，这是很有意义的。<h3 id="4-讲一下-Kafka-Consumer-消费消息时的线程模型，为何如此设计？"><a href="#4-讲一下-Kafka-Consumer-消费消息时的线程模型，为何如此设计？" class="headerlink" title="4 讲一下 Kafka Consumer 消费消息时的线程模型，为何如此设计？"></a>4 讲一下 Kafka Consumer 消费消息时的线程模型，为何如此设计？</h3>Thread-Per-Consumer Model，这种多线程模型是利用Kafka的topic分多个partition的机制来实现并行：每个线程都有自己的consumer实例，负责消费若干个partition。各个线程之间是完全独立的，不涉及任何线程同步和同学通信，所以实现起来非常简单。<h2 id="副本"><a href="#副本" class="headerlink" title="副本"></a>副本</h2><h3 id="1-ISR集合-AR-OSR"><a href="#1-ISR集合-AR-OSR" class="headerlink" title="1 ISR集合,AR,OSR"></a>1 ISR集合,AR,OSR</h3></li>
<li><em>In-Sync Replicas 副本同步队列</em>，表示可用的副本集合，也就是和主副本差距不大</li>
<li>ISR 是由 leader 维护，follower从leader 同步数据有一些延迟（包括延迟时间和延迟条数）, 任意一个超过阈值都会把follower剔除出ISR, 存入OSR（Outof-Sync Replicas）列表，新加入的follower也会先存放在OSR中。AR=ISR+OSR</li>
<li>主要是解决<code>同步副本</code>与<code>异步复制</code>两种方案各自的缺陷<h3 id="2-HW-amp-LEO"><a href="#2-HW-amp-LEO" class="headerlink" title="2 HW&amp;LEO"></a>2 HW&amp;LEO</h3></li>
<li>HW（High Watermark）：消费端消费时只能拉取到小于HW的消息而HW及之后的消息对于消费者来说是不可见的，保证HW之前消息的可靠性</li>
<li>LEO（Log End Offset）：表示当前副本最新消息的下一个offset<h3 id="3-leader-epoch机制"><a href="#3-leader-epoch机制" class="headerlink" title="3 leader epoch机制"></a>3 leader epoch机制</h3>leader epoch表示一个键值对<epoch, offset>，其中epoch表示leader主副本的版本号，从0开始编码，当leader每变更一次就会+1，offset表示该epoch版本的主副本写入第一条消息的位置，比如<0,0>表示第一个主副本从位移0开始写入消息，<1,100>表示第二个主副本版本号为1并从位移100开始写入消息，主副本会将该信息保存在缓存中并定期写入到checkpoint文件中，每次发生主副本切换都会去从缓存中查询该信息<h2 id="拾遗"><a href="#拾遗" class="headerlink" title="拾遗"></a>拾遗</h2></li>
</ul>
<h3 id="1-除了kafka-还用过哪些消息队列-他和kafka-有哪些区别，优劣"><a href="#1-除了kafka-还用过哪些消息队列-他和kafka-有哪些区别，优劣" class="headerlink" title="1 除了kafka 还用过哪些消息队列 他和kafka 有哪些区别，优劣"></a>1 除了kafka 还用过哪些消息队列 他和kafka 有哪些区别，优劣</h3><h3 id="2-Kafka-高效文件存储设计特点"><a href="#2-Kafka-高效文件存储设计特点" class="headerlink" title="2 Kafka 高效文件存储设计特点"></a>2 Kafka 高效文件存储设计特点</h3><ul>
<li>Kafka把topic中一个parition大文件分成多个小文件段，通过多个小文件段，就容易定期清除或删除已经消费完文件，减少磁盘占用。</li>
<li>通过索引信息可以快速定位message和确定 response的最大大小。</li>
<li>通过index元数据全部映射到memory，可以避免segment file的IO磁盘操作。</li>
<li>通过索引文件稀疏存储，可以大幅降低 index 文件元数据占用空间大小</li>
</ul>
<h3 id="3-Kafka-数据一致性原理"><a href="#3-Kafka-数据一致性原理" class="headerlink" title="3 Kafka 数据一致性原理"></a>3 Kafka 数据一致性原理</h3><ul>
<li>一致性就是说不论是老的 Leader 还是新选举的 Leader，Consumer 都能读到一样的数据。</li>
<li>假设分区的副本为3，其中副本0是 Leader，副本1和副本2是 follower，并且在 ISR 列表里面。虽然副本0已经写入了 Message4，但是 Consumer 只能读取到 Message2。因为所有的 ISR 都同步了 Message2，只有 High Water Mark 以上的消息才支持 Consumer 读取，而 High Water Mark 取决于 ISR 列表里面偏移量最小的分区，类似于<strong>木桶原理</strong>。</li>
<li>还没有被足够多副本复制的消息被认为是“不安全”的，如果 Leader 发生崩溃，另一个副本成为新 Leader，那么这些消息很可能丢失了。如果我们允许消费者读取这些消息，可能就会破坏一致性。试想，一个消费者从当前 Leader（副本0） 读取并处理了 Message4，这个时候 Leader 挂掉了，选举了副本1为新的 Leader，这时候另一个消费者再去从新的 Leader 读取消息，发现这个消息其实并不存在，这就导致了数据不一致性问题。</li>
</ul>
<h3 id="4-数据传输的事务有几种？"><a href="#4-数据传输的事务有几种？" class="headerlink" title="4 数据传输的事务有几种？"></a>4 数据传输的事务有几种？</h3><ul>
<li>数据传输的事务定义通常有以下三种级别：</li>
<li>最多一次: 消息不会被重复发送，最多被传输一次，但也有可能一次不传输 </li>
<li>最少一次: 消息不会被漏发送，最少被传输一次，但也有可能被重复传输.</li>
<li>精确的一次（Exactly once）: 不会漏传输也不会重复传输,每个消息都传输被</li>
</ul>
<h3 id="5-kafka为什么不需要支持读写分离"><a href="#5-kafka为什么不需要支持读写分离" class="headerlink" title="5 kafka为什么不需要支持读写分离"></a>5 kafka为什么不需要支持读写分离</h3><ul>
<li>读写均衡</li>
<li>分区，压力都不大</li>
</ul>
<h3 id="6-Kafka-中-zookeeper-的作用？它是如何保证-kafka-高可用的？主节点选举机制？"><a href="#6-Kafka-中-zookeeper-的作用？它是如何保证-kafka-高可用的？主节点选举机制？" class="headerlink" title="6 Kafka 中 zookeeper 的作用？它是如何保证 kafka 高可用的？主节点选举机制？"></a>6 Kafka 中 zookeeper 的作用？它是如何保证 kafka 高可用的？主节点选举机制？</h3><ol>
<li>用于在集群中不同节点之间进行通信</li>
<li>提交偏移量</li>
<li>leader 检测、分布式同步、配置管理、识别新节点何时离开或连接、集群、节点实时状态<h3 id="7-使用-kafka-的时候，如何确定一个-topic-的-partition-数量？"><a href="#7-使用-kafka-的时候，如何确定一个-topic-的-partition-数量？" class="headerlink" title="7 使用 kafka 的时候，如何确定一个 topic 的 partition 数量？"></a>7 使用 kafka 的时候，如何确定一个 topic 的 partition 数量？</h3></li>
<li>单台broker上partition数量不超过4000, 整个集群partition数量不超过2000,000</li>
<li>更多的Partition可能导致不可用时间增长；增加端到端的延迟；使用过多的内存<h3 id="8-kafka消息积压如何处理"><a href="#8-kafka消息积压如何处理" class="headerlink" title="8 kafka消息积压如何处理"></a>8 kafka消息积压如何处理</h3></li>
</ol>
<ul>
<li>问题定位：<ul>
<li>消息生产端数据量是否存在陡升的情况</li>
<li>消息消费端消费能力是否有下降</li>
<li>消息积压是发生在所有的partition还是所有的partition都有积压情况</li>
</ul>
</li>
<li>解决：<ul>
<li>前两个可以多线程，批量消费等提高消费速度</li>
<li>后者<ul>
<li>新建一个 topic，partition 是原来的 10 倍，临时建立好原先 10 倍的 queue 数量</li>
<li>然后写一个临时的分发数据的 consumer 程序，这个程序部署上去消费积压的数据，<strong>消费之后不做耗时的处理</strong>，直接均匀轮询写入临时建立好的 10 倍数量的 queue</li>
<li>接着临时征用 10 倍的机器来部署 consumer，每一批 consumer 消费一个临时 queue 的数据。这种做法相当于是临时将 queue 资源和 consumer 资源扩大 10 倍，以正常的 10 倍速度来消费数据</li>
<li>等快速消费完积压数据之后，<strong>得恢复原先部署的架构</strong>，<strong>重新</strong>用原先的 consumer 机器来消费消息</li>
</ul>
</li>
</ul>
</li>
</ul>

    
    
  </div>

  

  

</article>
  
  <article class="post">
  <header class="post-header">
    <h1 class="post-title">
      
      <a class="post-link" href="/2023/09/05/Framework/Redis/"></a>
      
    </h1>

    <div class="post-meta">
      <span class="post-time">
        2023-09-05
      </span>
      
      
      
    </div>
  </header>

  

  <div class="post-content">
    
    
    

    
    <figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"></span><br></pre></td></tr></table></figure>
<h2 id="1-基础知识"><a href="#1-基础知识" class="headerlink" title="1 基础知识"></a>1 基础知识</h2><h3 id="1-1-简介"><a href="#1-1-简介" class="headerlink" title="1.1 简介"></a>1.1 简介</h3><ul>
<li>Redis 为什么快：基于<code>内存</code>的数据库，单线程执行命令，没有并发问题，QPS 能轻松破 10w； I/O 多路复用机制；还有就是实现的数据结构能高效的处理数据操作；</li>
<li>使用场景：<strong>缓存，消息队列、分布式锁等场景</strong>。<h3 id="1-2-线程模型"><a href="#1-2-线程模型" class="headerlink" title="1.2 线程模型"></a>1.2 线程模型</h3><h4 id="1-2-1-Redis-是单线程吗？"><a href="#1-2-1-Redis-是单线程吗？" class="headerlink" title="1.2.1 Redis 是单线程吗？"></a>1.2.1 Redis 是单线程吗？</h4></li>
<li>接收客户端请求-&gt;解析请求 -&gt;进行数据读写等操作-&gt;发送数据给客户端 是单线程完成的</li>
<li>会启动后台线程（BIO）：<ul>
<li>2.6 版本：两个线程分别处理<code>关闭文件</code>、<code>AOF 刷盘</code></li>
<li>4.0 版本：新增lazyfree 线程，异步释放内存，避免 del 大 key 卡顿主线程,应该用 <code>unlink</code> 命令<code>异步删除</code>大 key<h4 id="1-2-2-单线程模式是怎样的？"><a href="#1-2-2-单线程模式是怎样的？" class="headerlink" title="1.2.2 单线程模式是怎样的？"></a>1.2.2 单线程模式是怎样的？</h4></li>
</ul>
</li>
<li>调用 epoll_create() 创建一个 epoll 对象和调用 socket() 创建一个服务端 socket</li>
<li>调用 bind() 绑定端口和调用 listen() 监听该 socket</li>
<li>将调用 epoll_ctl() 将 listen socket 加入到 epoll，同时注册「连接事件」处理函数</li>
<li>先调用<strong>处理发送队列函数</strong>，看是发送队列里是否有任务，如果有发送任务，则通过 write 函数将客户端发送缓存区里的数据发送出去，如果这一轮数据没有发送完，就会注册写事件处理函数，等待 epoll_wait 发现可写后再处理</li>
<li>调用 epoll_wait 函数等待事件的到来：<strong>连接事件</strong>，<strong>读事件</strong>，<strong>写事件</strong><h4 id="1-2-3-单线程模式为什么快？"><a href="#1-2-3-单线程模式为什么快？" class="headerlink" title="1.2.3 单线程模式为什么快？"></a>1.2.3 单线程模式为什么快？</h4></li>
<li>大部分操作都在<code>内存</code>中完成，并且采用了<code>高效的数据结构</code>，因此 Redis <code>瓶颈</code>可能是机器的内存或者网络带宽，而并非 CPU</li>
<li>采用单线程模型可以避免了多线程之间的竞争和切换带来的开销</li>
<li>采用了<code>I/O 多路复用机制</code>处理大量的客户端 Socket 请求，IO 多路复用机制是指一个线程处理多个 IO 流，就是我们经常听到的 select/epoll 机制。简单来说，在 Redis 只运行单线程的情况下，该机制允许内核中，同时存在多个监听 Socket 和已连接 Socket。内核会一直监听这些 Socket 上的<code>连接请求或数据请求</code>。一旦有请求到达，就会交给 Redis 线程处理，这就实现了一个 Redis 线程处理多个 IO 流的效果<h4 id="1-2-4-为什么引入多线程？"><a href="#1-2-4-为什么引入多线程？" class="headerlink" title="1.2.4 为什么引入多线程？"></a>1.2.4 为什么引入多线程？</h4></li>
<li>采用了多个 I/O 线程来处理网络请求，这是因为随着网络硬件的性能提升，Redis 的性能瓶颈有时会出现在<code>网络 I/O</code> 的处理上。 ^6bcb8c</li>
<li><strong>命令的执行，Redis 仍然使用单线程来处理</strong><h2 id="2-2-数据类型和结构"><a href="#2-2-数据类型和结构" class="headerlink" title="2 2.数据类型和结构"></a>2 2.数据类型和结构</h2><h3 id="2-1-数据类型和使用场景"><a href="#2-1-数据类型和使用场景" class="headerlink" title="2.1 数据类型和使用场景"></a>2.1 数据类型和使用场景</h3><h4 id="2-1-1-String-字符串"><a href="#2-1-1-String-字符串" class="headerlink" title="2.1.1 String 字符串"></a>2.1.1 String 字符串</h4></li>
<li><em>介绍</em>：key-value 结构,最大 512M</li>
<li><em>内部实现</em>：int 和 <code>SDS 简单动态字符串</code> </li>
<li><em>使用场景</em>：缓存对象、常规计数、分布式锁、共享 session 信息等</li>
<li><em>分布式锁</em>：SETNX  「key不存在才插入」<h4 id="2-1-2-List-列表"><a href="#2-1-2-List-列表" class="headerlink" title="2.1.2 List 列表"></a>2.1.2 List 列表</h4></li>
<li><em>介绍</em>：简单的字符串列表,最大长度为 <code>2^32 - 1</code>   40亿</li>
<li><em>内部实现</em>：<ul>
<li><code>压缩列表</code>：列表元素小于 512 个，且都小于 64 字节</li>
<li><code>双向链表</code>：不满足以上</li>
<li><code>quicklist</code>：Redis3.2 版本后</li>
</ul>
</li>
<li><em>使用场景</em>：消息队列<h4 id="2-1-3-Hash"><a href="#2-1-3-Hash" class="headerlink" title="2.1.3 Hash"></a>2.1.3 Hash</h4></li>
<li><em>介绍</em>：键值对集合</li>
<li><em>内部实现</em>：<ul>
<li><code>压缩列表</code>：列表元素小于 512 个，且都小于 64 字节</li>
<li><code>哈希表</code>：不满足以上</li>
<li><code>listpack</code>：Redis7.0 版本后</li>
</ul>
</li>
<li><em>使用场景</em>：缓存对象，比如实现购物车<h4 id="2-1-4-Set"><a href="#2-1-4-Set" class="headerlink" title="2.1.4 Set"></a>2.1.4 Set</h4></li>
<li><em>介绍</em>：无序并唯一的键值集合  2^32-1</li>
<li><em>内部实现</em>：<ul>
<li><code>整数集合</code>：列表元素小于 512 个，且都是整数</li>
<li><code>哈希表</code>：不满足以上</li>
</ul>
</li>
<li><em>使用场景</em>：点赞，共同关注（交集），抽奖<h4 id="2-1-5-ZSet"><a href="#2-1-5-ZSet" class="headerlink" title="2.1.5 ZSet"></a>2.1.5 ZSet</h4></li>
<li><em>介绍</em>：有序并唯一的键值集合，多了排序属性 Score</li>
<li><em>内部实现</em>：<ul>
<li><code>压缩列表</code>：元素小于 128 个，且都小于 64 字节</li>
<li><code>跳表</code>：不满足以上</li>
<li><code>listpack</code>：Redis7.0 版本后，压缩列表废弃了</li>
</ul>
</li>
<li><em>使用场景</em>：排行榜,电话排序</li>
<li><em>复杂度</em>： zrange：O [ (LogN)+M]； ZSCORE：O(1) ；zrank：O(logn)<h4 id="2-1-6-BitMap"><a href="#2-1-6-BitMap" class="headerlink" title="2.1.6 BitMap"></a>2.1.6 BitMap</h4></li>
<li><em>介绍</em>：位图，连续的二进制数组</li>
<li><em>内部实现</em>：<ul>
<li><code>String 类型</code>：String 会保存为二进制的字节数组</li>
</ul>
</li>
<li><em>使用场景</em>：二值统计，签到打卡，用户登录<h3 id="2-2-数据结构"><a href="#2-2-数据结构" class="headerlink" title="2.2 数据结构"></a>2.2 数据结构</h3><h4 id="2-2-1-SDS-简单动态字符串"><a href="#2-2-1-SDS-简单动态字符串" class="headerlink" title="2.2.1 SDS 简单动态字符串"></a>2.2.1 SDS 简单动态字符串</h4></li>
<li><em>C 语言字符串的问题</em>：<ul>
<li>获取字符串长度的时间复杂度为 O（N）</li>
<li>字符串的结尾是以 “\0” 字符标识，字符串里面不能包含有 “\0” 字符，因此不能保存二进制数据；</li>
<li>字符串操作函数不高效且不安全，比如有缓冲区溢出的风险，有可能会造成程序运行终止；</li>
</ul>
</li>
<li><em>SDS 结构设计</em><ul>
<li><code>len</code>，记录了字符串长度；<code>alloc</code>，分配给字符数组的空间长度；<code>flags</code>，用来表示不同类型的 SDS; <code>buf[]</code>，字符数组，用来保存实际数据</li>
</ul>
</li>
<li><em>特点</em>：添加了三个元数据解决 C 语言字符串的缺陷，二进制安全，节约内存空间<h4 id="2-2-2-链表"><a href="#2-2-2-链表" class="headerlink" title="2.2.2 链表"></a>2.2.2 链表</h4></li>
<li><em>链表结构设计</em>：添加了前驱指针</li>
<li>3.0 版本前，数据量少的情况下会用压缩列表作为底层结构实现<h4 id="2-2-3-压缩列表"><a href="#2-2-3-压缩列表" class="headerlink" title="2.2.3 压缩列表"></a>2.2.3 压缩列表</h4></li>
<li><em>目的</em>：为了节约内存，由连续内存块组成的顺序型数据结构</li>
<li><em>节点结构设计</em>：<ul>
<li>prevlen，记录了「前一个节点」的长度</li>
<li>encoding，记录了当前节点实际数据的「类型和长度」</li>
<li>data，记录了当前节点的实际数据</li>
</ul>
</li>
<li><em>连锁更新</em>：有多个连续的、长度在 250～253 之间的节点，prelen 会用一个字节保存长度，如果有大于 254 字节的新节点加入，prelen 要扩展到 5 字节，引起连锁更新</li>
<li>quicklist（Redis 3.2 引入） 和 listpack（Redis 5.0 引入）解决连锁更新<h4 id="2-2-4-哈希表"><a href="#2-2-4-哈希表" class="headerlink" title="2.2.4 哈希表"></a>2.2.4 哈希表</h4></li>
<li><em>特点</em>：通过 hash 计算，以 O(1) 的复杂度快速查询数据，通过<code>「链式哈希」</code>来解决哈希冲突</li>
<li><em>结构设计</em>：哈希表是一个<code>数组</code>（dictEntry table），数组的每个元素是一个指向「哈希表节点（dictEntry）」的指针</li>
<li><em>rehash</em>： 渐进式 rehash   <code>触发条件</code>：负载因子大于 1（没有 bgsve） 和 5（强制）<ul>
<li>给「哈希表 2」 分配空间，一般会比「哈希表 1」 大 2 倍</li>
<li>在 rehash 进行期间，每次哈希表元素进行新增、删除、查找或者更新操作时，Redis 除了会执行对应的操作之外，还会顺序将「哈希表 1 」中索引位置上的所有 key-value <code>迁移</code>到「哈希表 2」 上</li>
<li>迁移完成后，「哈希表 1 」的空间会被释放，并把「哈希表 2」 设置为「哈希表 1」，然后在「哈希表 2」 新创建一个空白的哈希表，为下次 rehash 做准备<h4 id="2-2-5-整数集合"><a href="#2-2-5-整数集合" class="headerlink" title="2.2.5 整数集合"></a>2.2.5 整数集合</h4></li>
</ul>
</li>
<li><em>特点</em>：当 Set 对象只包含整数值元素，并且元素数量不大时，就会使用整数集这个数据结构作为底层实现</li>
<li><em>升级</em>：将一个新元素加入到整数集合里面，如果新元素的类型（int32_t）比整数集合现有所有元素的类型（int16_t）都要长时，整数集合需要先进行升级，也就是按<code>新元素的类型</code>（int32_t）扩展 contents 数组的空间大小，然后才能将新元素加入到整数集合里   <code>节省内存资源</code><h4 id="2-2-6-跳表"><a href="#2-2-6-跳表" class="headerlink" title="2.2.6 跳表"></a>2.2.6 跳表</h4><blockquote>
<p>Zset底层包括 跳表和哈希表 实现高效的范围查询和单点查询</p>
</blockquote>
</li>
<li><em>结构设计</em>：在链表基础上实现了一种多层有序链表<ul>
<li>多层级实现：zskiplistLevel 结构体类型的 level 数组</li>
<li>跨度：将沿途所有层的跨度累加就是节点在跳表中的排位</li>
</ul>
</li>
<li><em>节点查询过程</em><ul>
<li>当前节点的权重「小于」要查找的权重时，访问该层的下一个节点</li>
<li>当前节点的权重「等于」要查找的权重时，当前节点的 SDS 类型数据「小于」要查找的数据时，跳表就会访问该层上的下一个节点</li>
<li>都不满足，去下一层继续查找</li>
</ul>
</li>
<li><em>节点层数设置</em>：相邻两层理想比例为 2：1，复杂度为 O(logN)<ul>
<li>在创建节点时候，会生成范围为[0-1]的一个随机数，如果这个随机数小于 0.25（相当于概率 25%），那么层数就增加 1 层，然后继续生成下一个随机数，直到随机数的结果大于 0.25 结束，最终确定该节点的层数</li>
</ul>
</li>
<li><em>为什么不用平衡树</em><ul>
<li><code>内存占用</code>：平衡树每个节点两个指针，跳表只有 1.33</li>
<li><code>范围查询</code>：平衡树需要中序遍历，跳表直接遍历就行</li>
<li><code>实现难度</code>：平衡树插入删除要调整子树，跳表只要调整相邻节点</li>
</ul>
</li>
</ul>
<h4 id="2-2-7-quicklist"><a href="#2-2-7-quicklist" class="headerlink" title="2.2.7 quicklist"></a>2.2.7 quicklist</h4><ul>
<li><em>介绍</em>：3.2后 <code>List</code>对象的底层改由 quicklist 数据结构</li>
<li><em>结构设计</em>：<code>双向链表</code>，链表的元素是<code>压缩列表</code></li>
<li><em>优点</em>：控制每个链表节点中的<code>压缩列表的大小</code>或者元素个数，来规避连锁更新的问题。因为压缩列表元素越少，连锁更新带来的影响就越小，从而提供了更好的访问性能<h4 id="2-2-8-listpack"><a href="#2-2-8-listpack" class="headerlink" title="2.2.8 listpack"></a>2.2.8 listpack</h4></li>
<li><em>介绍</em>：目的是替换压缩列表，每个节点不再包含前一个节点的长度</li>
<li><em>结构设计</em>：借鉴<code>压缩列表</code>设计</li>
<li><em>优点</em>：listpack 只记录当前节点的长度，当我们向 listpack 加入一个新元素的时候，不会影响其他节点的长度字段的变化，从而避免了压缩列表的连锁更新问题</li>
</ul>
<h2 id="3-3-持久化"><a href="#3-3-持久化" class="headerlink" title="3 3.持久化"></a>3 3.持久化</h2><h3 id="3-1-AOF-日志"><a href="#3-1-AOF-日志" class="headerlink" title="3.1 AOF 日志 :"></a>3.1 AOF 日志 :</h3><ol>
<li>实现：先执行写操作命令，然后将命令追加到日志文件</li>
<li>优缺点：不会阻塞当前命令的执行；可能丢失数据</li>
<li>写回策略：<strong>Always</strong> 总是；<strong>Everysec</strong> 每秒；No 操作系统决定</li>
<li><strong>AOF 重写</strong>： <strong>后台子进程 <em>bgrewriteaof</em></strong>； 扫描数据库中所有数据，逐一把内存数据的键值对转换成一条命令，再将命令记录到重写日志； 状态一样,<code>文件体积更小</code><ol>
<li>重写过程中，主进程依然可以正常处理命令</li>
<li>在重写 AOF 期间,将这个写命令写入到 「AOF 缓冲区」和 「AOF 重写缓冲区」</li>
<li>将 AOF 重写缓冲区中的所有内容追加到新的 AOF 的文件中，使得新旧两个 AOF 文件所保存的数据库状态一致<h3 id="3-2-RDB-快照"><a href="#3-2-RDB-快照" class="headerlink" title="3.2 RDB 快照"></a>3.2 RDB 快照</h3>将某一时刻的内存数据，以二进制的方式写入磁盘; </li>
</ol>
</li>
<li>save ：主线程实现，可能阻塞</li>
<li>bgsave： 子进程</li>
<li>写时复制：如果主线程执行写操作，则被修改的数据会复制一份副本，然后 bgsave 子进程会把该副本数据写入 RDB 文件<h3 id="3-3-混合持久化"><a href="#3-3-混合持久化" class="headerlink" title="3.3 混合持久化"></a>3.3 混合持久化</h3>AOF重写时以 RDB 为开头;<strong>前半部分是 RDB 格式的全量数据，后半部分是 AOF 格式的增量数据</strong>。保证了 Redis 重启速度，又降低数据丢失风险。  <h3 id="3-4-大-key-对持久化的影响"><a href="#3-4-大-key-对持久化的影响" class="headerlink" title="3.4 大 key 对持久化的影响"></a>3.4 大 key 对持久化的影响</h3></li>
</ol>
<ul>
<li><em>大 Key 对 AOF 日志的影响</em>：使用 Always 策略的时候，如果写入是一个大 Key，主线程在执行 fsync() 函数的时候，阻塞的时间会比较久，因为当写入的数据量很大的时候，数据同步到硬盘这个过程是很耗时的</li>
<li><em>大 Key 对 AOF 重写和 RDB 的影响</em>：<ul>
<li>创建子进程的途中，由于要复制父进程的页表等数据结构，阻塞的时间跟页表的大小有关，页表越大，阻塞的时间也越长；</li>
<li>创建完子进程后，如果子进程或者父进程修改了共享数据，就会发生写时复制，这期间会拷贝物理内存，如果内存越大，自然阻塞的时间也越长；</li>
</ul>
</li>
<li><em>其他影响</em>：<ul>
<li><code>客户端超时阻塞</code>。由于 Redis 执行命令是单线程处理，然后在操作大 key 时会比较耗时，那么就会阻塞 Redis，从客户端这一视角看，就是很久很久都没有响应。</li>
<li><code>引发网络阻塞</code>。每次获取大 key 产生的网络流量较大，如果一个 key 的大小是 1 MB，每秒访问量为 1000，那么每秒会产生 1000MB 的流量，这对于普通千兆网卡的服务器来说是灾难性的。</li>
<li><code>阻塞工作线程</code>。如果使用 del 删除大 key 时，会阻塞工作线程，这样就没办法处理后续的命令。</li>
<li><code>内存分布不均</code>。集群模型在 slot 分片均匀情况下，会出现数据和查询倾斜情况，部分有大 key 的 Redis 节点占用内存多，QPS 也会比较大。</li>
</ul>
</li>
<li>删除用 unlink 进行异步删除<h2 id="4-4-集群"><a href="#4-4-集群" class="headerlink" title="4 4.集群"></a>4 4.集群</h2><h3 id="4-1-主从复制"><a href="#4-1-主从复制" class="headerlink" title="4.1 主从复制"></a>4.1 主从复制</h3><blockquote>
<p>主从之间采用<code>读写分离</code></p>
</blockquote>
</li>
</ul>
<ol>
<li><strong>第一次同步数据</strong>： 使用 <code>replicaof</code> 命令<pre><code> 1. _建立链接、协商同步_：从服务器发送 `psync `要求同步，主服务器回应 `FULLRESYNC`，同步复制的`进度`
 2. _主同步数据给从_：主服务器生成 RBD 文件发送给从服务器，期间执行的命令会写入` replication buffer` 缓冲区
 3. _发送新写操作命令给从_：将缓冲区中的命令发送给从服务器
</code></pre></li>
<li><strong>命令传播</strong>：维护 TCP 长连接</li>
<li>分摊主服务器的压力：从服务器同步给其他</li>
<li><em>增量复制</em>：同步<strong>网络断开</strong>期间的写操作; 环形缓冲区(<strong>repl_backlog_buffer</strong>) 和 <strong>replication offset</strong>标记同步进度<h3 id="4-2-哨兵机制"><a href="#4-2-哨兵机制" class="headerlink" title="4.2 哨兵机制"></a>4.2 哨兵机制</h3></li>
</ol>
<ul>
<li><em>作用</em>：主从节点故障转移；主要负责<code>监控,选主,通知</code></li>
<li><em>判断故障</em>：每隔 1 秒给所有主从节点发送 PING 命令，没有响应就主观下线；　因为可能网络延迟，不一定真的就挂了</li>
<li><em>客观下线</em>：判断主观下线后，哨兵集群进行投票，超过半数同意就判定客观下线；</li>
<li><em>主从故障转移</em>：<pre><code>  1. `Leader选举`：到半数以上的赞成票，作为 leader 实现主从切换
  2. `选出新主节点`：**优先级、复制进度、ID 号**
  3. `将从节点指向新主节点`；通知客户的主节点已更换；将旧主节点变为从节
  4. `通知客户的主节点已更换`
</code></pre></li>
<li>哨兵集群组成：通过 Redis 的发布者/订阅者机制来相互发现；10 秒一次的频率向主节点发送 INFO 命令来获取所有「从节点」的信息<h3 id="4-3-脑裂"><a href="#4-3-脑裂" class="headerlink" title="4.3 脑裂"></a>4.3 脑裂</h3></li>
<li>由于网络问题，集群节点之间失去联系。主从数据不同步；重新平衡选举，产生两个主服务。等网络恢复，旧主节点会降级为从节点，再与新主节点进行同步复制的时候，由于会从节点会清空自己的缓冲区，所以导致之前客户端写入的数据丢失了。</li>
<li><strong>主节点连接的从节点中至少有 N 个从节点，「并且」主节点进行数据复制时的 ACK 消息延迟不能超过 T 秒</strong>，否则，主节点就不会再接收客户端的写请求了。</li>
<li>等到新主节点上线时，就只有新主节点能接收和处理客户端请求，此时，新写的数据会被直接写到新主节点中。而原主节点会被哨兵降为从节点，即使它的数据被清空了，也不会有新数据丢失。<h2 id="5-过期删除和内存淘汰"><a href="#5-过期删除和内存淘汰" class="headerlink" title="5 过期删除和内存淘汰"></a>5 过期删除和内存淘汰</h2><blockquote>
<p>过期删除策略是删除已经过期的 key，当 Redis 的运行内存超过最大内存后，会用内存淘汰策略删除符合条件的 key</p>
<h3 id="5-1-过期删除策略"><a href="#5-1-过期删除策略" class="headerlink" title="5.1 过期删除策略"></a>5.1 过期删除策略</h3></blockquote>
</li>
<li>可以给 key 设置过期时间，会有个过期字典保存所有 key 的过期时间</li>
<li><em>定时删除</em>：在设置 key 的过期时间时，同时创建一个定时事件，当时间到达时，由事件处理器自动执行 key 的删除操作；<code>内存友好但是 CPU 不友好</code></li>
<li><em>惰性删除</em>：不主动删除过期键，每次从数据库访问 key 时，都检测 key 是否过期，如果过期则删除该 key。<code>CPU友好但是内存不友好</code></li>
<li><em>定期删除</em>：每隔一段时间「随机」从数据库中取出一定数量的 key 进行检查，并删除其中的过期key</li>
<li><em>Redis 的策略</em>：「惰性删除+定期删除」配和使用<h3 id="5-2-内存淘汰策略"><a href="#5-2-内存淘汰策略" class="headerlink" title="5.2 内存淘汰策略"></a>5.2 内存淘汰策略</h3></li>
<li>不进行数据淘汰的策略：直接返回错误</li>
<li>进行数据淘汰的策略<ul>
<li>在设置了过期时间的数据中进行淘汰<ul>
<li>随机； 最久未使用； 最少使用；更早过期</li>
</ul>
</li>
<li>在所有数据范围内进行淘汰<ul>
<li>随机； 最久未使用； 最少使用<h2 id="6-缓存设计"><a href="#6-缓存设计" class="headerlink" title="6 缓存设计"></a>6 缓存设计</h2><h3 id="6-1-缓存雪崩"><a href="#6-1-缓存雪崩" class="headerlink" title="6.1 缓存雪崩"></a>6.1 缓存雪崩</h3></li>
</ul>
</li>
</ul>
</li>
<li><em>现象</em>：大量缓存数据在同一时间过期（失效）或者 Redis 故障宕机，请求全部直接访问数据库，导致系统崩溃</li>
<li><em>解决过期</em>：<ul>
<li><code>均匀设置过期时间</code>：过期时间加上一个随机数    </li>
<li><code>互斥锁</code>：如果发现访问的数据不在 Redis 里，就加个互斥锁，保证同一时间内只有一个请求来构建缓存</li>
<li><code>双 key 策略</code>：</li>
<li><code>后台更新缓存</code>：让缓存“永久有效”，并将更新缓存的工作交由后台线程定时更新</li>
</ul>
</li>
<li><em>解决宕机</em>：服务熔断或请求限流机制；Redis 缓存高可靠集群<h3 id="6-2-缓存击穿"><a href="#6-2-缓存击穿" class="headerlink" title="6.2 缓存击穿"></a>6.2 缓存击穿</h3></li>
<li><em>现象</em>：某个热点数据过期，大量请求访问该数据，直接打到了数据库中</li>
<li><em>解决</em><ul>
<li><code>互斥锁</code>：同一时间只有一个业务线程更新缓存，未能获取互斥锁的请求，要么等待锁释放后重新读取缓存，要么就返回空值或者默认值</li>
<li>不给热点数据设置过期时间，由后台异步更新缓存，或者在热点数据准备要过期前，提前通知后台线程更新缓存以及重新设置过期时间<h3 id="6-3-缓存穿透"><a href="#6-3-缓存穿透" class="headerlink" title="6.3 缓存穿透"></a>6.3 缓存穿透</h3></li>
</ul>
</li>
<li><em>现象</em>： 请求的数据<strong>既不在缓存中，也不在数据库中</strong>请求全到数据库</li>
<li><em>解决</em>：<ul>
<li>限制<code>非法请求</code></li>
<li>出现缓存穿透，可以<code>缓存空值或者默认值</code></li>
<li>使用<code>布隆过滤器</code>快速判断数据是否存在</li>
</ul>
</li>
<li><em>布隆过滤器</em>  [[布隆过滤器]]<h3 id="6-4-数据库和缓存一致性"><a href="#6-4-数据库和缓存一致性" class="headerlink" title="6.4 数据库和缓存一致性"></a>6.4 数据库和缓存一致性</h3></li>
<li>先更新数据库还是缓存？<ul>
<li>先更新数据库，再更新缓存：在并发情况下同时更新一个数据可能导致数据不一致</li>
<li>先更新缓存，再更新数据库：也可能因为并发导致不一致</li>
</ul>
</li>
<li>先更新数据库还是先删除缓存？  <code>旁路缓存策略（Cache Aside）</code><ul>
<li><em>先删除缓存，再更新数据库</em>：可能会在缓存删除且数据库没更新时出现问题</li>
<li><strong><em>先更新数据库，再删除缓存</em></strong>：理论上会出现不一致（请求 B 在请求 A 没写入缓存前更新了数据并删除了缓存），但是因为缓存的写入快于数据库的写入，出现概率不高；为了确保，还可以加上<code>过期时间</code>或者选择延迟双删</li>
<li><code>延迟双删</code>：先删缓存，然后更新数据库，等一会再删除缓存</li>
</ul>
</li>
<li>怎么保证更新数据库和删除缓存成功？<ul>
<li><code>重试机制</code>：用<code>消息队列</code>进行重试</li>
<li><code>订阅 binlog</code>：Canal，订阅日志拿到要操作的数据再执行缓存删除</li>
<li>都是<code>异步</code>操作缓存<h2 id="7-其他"><a href="#7-其他" class="headerlink" title="7 其他"></a>7 其他</h2><h3 id="7-1-redis分布式锁"><a href="#7-1-redis分布式锁" class="headerlink" title="7.1 redis分布式锁"></a>7.1 redis分布式锁</h3></li>
</ul>
</li>
</ul>
<ol>
<li>SET 命令有个 NX 参数可以实现「key不存在才插入」</li>
<li>缺点：主从复制模式中的数据是异步复制的，这样导致分布式锁的不可靠性</li>
<li>分布式锁算法 Redlock（红锁）：客户端和多个独立的 Redis 节点依次请求申请加锁，在加锁超时时间内获得半数以上的节点的锁，就获得分布式锁，否则加锁失败。  </li>
<li>使用 redis 做分布式锁怎么做？如何保证set key 和设置过期时间的原子性？除了 lua 脚本有没有其他方法？</li>
<li>Redis 分布式锁 如果watch dog续期线程阻塞了 导致锁释放，锁不安全了怎么办，或者续期次数到达限制 任务还没执行完怎么办（数据库乐观锁保证只有一条数据成功）<h3 id="7-2-实现一个延迟队列"><a href="#7-2-实现一个延迟队列" class="headerlink" title="7.2 实现一个延迟队列"></a>7.2 实现一个延迟队列</h3></li>
<li>使用有序集合（ZSet）的方式来实现 score 记录延迟的时间</li>
<li>如果想重复消费？</li>
</ol>

    
    
  </div>

  

  

</article>
  
  <article class="post">
  <header class="post-header">
    <h1 class="post-title">
      
      <a class="post-link" href="/2023/08/27/Golang/1%20%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B/05-sync.pool/"></a>
      
    </h1>

    <div class="post-meta">
      <span class="post-time">
        2023-08-27
      </span>
      
      
      
    </div>
  </header>

  

  <div class="post-content">
    
    
    

    
    <p>本文主要介绍了Go语言(golang)中的<code>sync.pool</code>包。给出了 sync.pool 的基本用法，以及各大框架中的使用案例。并从源码层面对其底层结构和具体实现原理进行分析。</p>
<blockquote>
<p>以下分析基于 Go 1.17.1</p>
</blockquote>
<h2 id="1-概述"><a href="#1-概述" class="headerlink" title="1 概述"></a>1 概述</h2><h3 id="1-1-大致理念"><a href="#1-1-大致理念" class="headerlink" title="1.1 大致理念"></a>1.1 大致理念</h3><p><code>sync.Pool</code> 是 sync 包下的一个组件，可以作为保存临时取还对象的一个“池子”，可以缓存暂时不用的对象，下次需要时直接使用（无需重新分配）。</p>
<blockquote>
<p>因为频繁的内存分配和回收会对性能产生影响，通过复用临时对象就可以避免改问题。</p>
</blockquote>
<p>下面是 2018 年的时候，《Go 夜读》上关于 <code>sync.Pool</code> 的分享，关于适用场景：</p>
<blockquote>
<p>当多个 goroutine 都需要创建同⼀个对象的时候，如果 goroutine 数过多，导致对象的创建数⽬剧增，进⽽导致 GC 压⼒增大。形成 “并发⼤－占⽤内存⼤－GC 缓慢－处理并发能⼒降低－并发更⼤”这样的恶性循环。 在这个时候，需要有⼀个对象池，每个 goroutine 不再⾃⼰单独创建对象，⽽是从对象池中获取出⼀个对象（如果池中已经有的话）。</p>
</blockquote>
<p>因此关键思想就是对象的复用，避免重复创建、销毁，下面我们来看看如何使用。</p>
<p>所以，sync.pool 的作用一句话描述就是，<strong>复用临时对象，以避免频繁的内存分配和回收，从而减少 GC 压力</strong>。</p>
<h3 id="1-2-基本使用"><a href="#1-2-基本使用" class="headerlink" title="1.2 基本使用"></a>1.2 基本使用</h3><p>首先，<code>sync.Pool</code> 是协程安全的，这对于使用者来说是极其方便的。使用前，设置好对象的 <code>New</code> 函数，用于在 <code>Pool</code> 里没有缓存的对象时，创建一个。之后，在程序的任何地方、任何时候仅通过 <code>Get()</code>、<code>Put()</code> 方法就可以取、还对象了。</p>
<p>以下为基本使用 demo：</p>
<blockquote>
<p>完整代码见 <a href="#">Github</a><br><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line"> <span class="keyword">package</span> main  </span><br><span class="line"> ​  </span><br><span class="line"> <span class="keyword">import</span> (  </span><br><span class="line">   <span class="string">&quot;fmt&quot;</span>  </span><br><span class="line">   <span class="string">&quot;sync&quot;</span>  </span><br><span class="line"> )  </span><br><span class="line"> ​  </span><br><span class="line"> <span class="keyword">type</span> Gopher <span class="keyword">struct</span> &#123;  </span><br><span class="line">   Name   <span class="type">string</span>  </span><br><span class="line">   Remark [<span class="number">1024</span>]<span class="type">byte</span>  </span><br><span class="line"> &#125;  </span><br><span class="line"> ​  </span><br><span class="line"> <span class="function"><span class="keyword">func</span> <span class="params">(s *Gopher)</span></span> Reset() &#123;  </span><br><span class="line">   s.Name = <span class="string">&quot;&quot;</span>  </span><br><span class="line">   s.Remark = [<span class="number">1024</span>]<span class="type">byte</span>&#123;&#125;  </span><br><span class="line"> &#125;  </span><br><span class="line"> ​  </span><br><span class="line"> <span class="keyword">var</span> gopherPool = sync.Pool&#123;  </span><br><span class="line">   New: <span class="function"><span class="keyword">func</span><span class="params">()</span></span> <span class="keyword">interface</span>&#123;&#125; &#123;  </span><br><span class="line">     <span class="keyword">return</span> <span class="built_in">new</span>(Gopher)  </span><br><span class="line">   &#125;,  </span><br><span class="line"> &#125;  </span><br><span class="line"> ​  </span><br><span class="line"> <span class="function"><span class="keyword">func</span> <span class="title">main</span><span class="params">()</span></span> &#123;  </span><br><span class="line">   g := gopherPool.Get().(*Gopher)  </span><br><span class="line">   fmt.Println(<span class="string">&quot;首次从 pool 里获取：&quot;</span>, g.Name)  </span><br><span class="line"> ​  </span><br><span class="line">   g.Name = <span class="string">&quot;first&quot;</span>  </span><br><span class="line">   fmt.Printf(<span class="string">&quot;设置 p.Name = %s\n&quot;</span>, g.Name)  </span><br><span class="line">   gopherPool.Put(g)  </span><br><span class="line"> ​  </span><br><span class="line">   fmt.Println(<span class="string">&quot;Pool 里已有一个对象：&amp;&#123;first&#125;，调用 Get: &quot;</span>, gopherPool.Get().(*Gopher).Name)  </span><br><span class="line">   fmt.Println(<span class="string">&quot;Pool 没有对象了，调用 Get: &quot;</span>, gopherPool.Get().(*Gopher).Name)  </span><br><span class="line"> &#125;</span><br></pre></td></tr></table></figure><br>运行结果：<br> 首次从 pool 里获取：<br> 设置 p.Name = first<br> Pool 里已有一个对象：&amp;{first}，调用 Get:  first<br> Pool 没有对象了，调用 Get:<br>首先，需要初始化 <code>Pool</code>，唯一需要的就是设置好 <code>New</code> 函数。当调用 Get 方法时，如果池子里缓存了对象，就直接返回缓存的对象。如果没有存货，则调用 New 函数创建一个新的对象。</p>
</blockquote>
<p>另外，我们发现 Get 方法取出来的对象和上次 Put 进去的对象实际上是同一个，Pool 没有做任何“清空”的处理。但我们不应当对此有任何假设，因为在实际的并发使用场景中，无法保证这种顺序，<strong>最好的做法是在 Put 前，将对象清空</strong>。</p>
<p><strong>Benchmark</strong><br><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"> <span class="keyword">var</span> defaultGopher, _ = json.Marshal(Gopher&#123;Name: <span class="string">&quot;17x&quot;</span>&#125;)  </span><br><span class="line"> ​  </span><br><span class="line"> <span class="function"><span class="keyword">func</span> <span class="title">BenchmarkUnmarshal</span><span class="params">(b *testing.B)</span></span> &#123;  </span><br><span class="line">   <span class="keyword">var</span> g *Gopher  </span><br><span class="line">   <span class="keyword">for</span> n := <span class="number">0</span>; n &lt; b.N; n++ &#123;  </span><br><span class="line">     g = <span class="built_in">new</span>(Gopher)  </span><br><span class="line">     json.Unmarshal(defaultGopher, g)  </span><br><span class="line">   &#125;  </span><br><span class="line"> &#125;  </span><br><span class="line"> ​  </span><br><span class="line"> <span class="function"><span class="keyword">func</span> <span class="title">BenchmarkUnmarshalWithPool</span><span class="params">(b *testing.B)</span></span> &#123;  </span><br><span class="line">   <span class="keyword">var</span> g *Gopher  </span><br><span class="line">   <span class="keyword">for</span> n := <span class="number">0</span>; n &lt; b.N; n++ &#123;  </span><br><span class="line">     g = gopherPool.Get().(*Gopher)  </span><br><span class="line">     json.Unmarshal(defaultGopher, g)  </span><br><span class="line">     g.Reset() <span class="comment">// 重置后在放进去  </span></span><br><span class="line">     gopherPool.Put(g)  </span><br><span class="line">   &#125;  </span><br><span class="line"> &#125;  </span><br></pre></td></tr></table></figure><br> ​<br>运行结果：</p>
<p> BenchmarkUnmarshal-6                9518            124806 ns/op            1280 B/op          6 allocs/op<br> BenchmarkUnmarshalWithPool-6       10000            124350 ns/op             128 B/op          5 allocs/op<br> <code>3287449 357 ns/op</code> 表示单位时间内（默认是1s）被测函数运行了 3287449 次，每次运行耗时 357ns，<br> <code>B/op</code> 是每个操作分配的字节数<br> <code>allocs/op</code> 表示每个操作(单次迭代)发生了多少不同的内存分配。</p>
<p>功能比较简单，其中 json 反序列化占用了大量时间，因此两种方式最终的执行时间几乎没什么变化。但是内存占用差了一个数量级，使用了 <code>sync.Pool</code> 后，内存占用仅为未使用的 128/1280=1/10，对 GC 的影响就很大了。</p>
<h3 id="1-3-使用案例"><a href="#1-3-使用案例" class="headerlink" title="1.3 使用案例"></a>1.3 使用案例</h3><h4 id="1-3-1-fmt-包"><a href="#1-3-1-fmt-包" class="headerlink" title="1.3.1 fmt 包"></a>1.3.1 fmt 包</h4><p>这部分主要看 <code>fmt.Printf</code> 如何使用：<br><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"> <span class="function"><span class="keyword">func</span> <span class="title">Printf</span><span class="params">(format <span class="type">string</span>, a ...<span class="keyword">interface</span>&#123;&#125;)</span></span> (n <span class="type">int</span>, err <span class="type">error</span>) &#123;  </span><br><span class="line">   <span class="keyword">return</span> Fprintf(os.Stdout, format, a...)  </span><br><span class="line"> &#125;</span><br></pre></td></tr></table></figure><br>继续看 <code>Fprintf</code>：<br><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"> <span class="function"><span class="keyword">func</span> <span class="title">Fprintf</span><span class="params">(w io.Writer, format <span class="type">string</span>, a ...<span class="keyword">interface</span>&#123;&#125;)</span></span> (n <span class="type">int</span>, err <span class="type">error</span>) &#123;  </span><br><span class="line">   p := newPrinter()  </span><br><span class="line">   p.doPrintf(format, a)  </span><br><span class="line">   n, err = w.Write(p.buf)  </span><br><span class="line">   p.free()  </span><br><span class="line">   <span class="keyword">return</span>  </span><br><span class="line"> &#125;</span><br></pre></td></tr></table></figure><br><code>Fprintf</code> 函数的参数是一个 <code>io.Writer</code>，<code>Printf</code> 传的是 <code>os.Stdout</code>，相当于直接输出到标准输出。这里的 <code>newPrinter</code> 用的就是 Pool：<br><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"> <span class="keyword">var</span> ppFree = sync.Pool&#123;  </span><br><span class="line">   New: <span class="function"><span class="keyword">func</span><span class="params">()</span></span> <span class="keyword">interface</span>&#123;&#125; &#123; <span class="keyword">return</span> <span class="built_in">new</span>(pp) &#125;,  </span><br><span class="line"> &#125;  </span><br><span class="line"> ​  </span><br><span class="line"> <span class="function"><span class="keyword">func</span> <span class="title">newPrinter</span><span class="params">()</span></span> *pp &#123;  </span><br><span class="line">   p := ppFree.Get().(*pp)  </span><br><span class="line">   p.panicking = <span class="literal">false</span>  </span><br><span class="line">   p.erroring = <span class="literal">false</span>  </span><br><span class="line">   p.wrapErrs = <span class="literal">false</span>  </span><br><span class="line">   p.fmt.init(&amp;p.buf)  </span><br><span class="line">   <span class="keyword">return</span> p  </span><br><span class="line"> &#125;</span><br></pre></td></tr></table></figure><br>回到 <code>Fprintf</code> 函数，拿到 pp 指针后，会做一些 format 的操作，并且将 p.buf 里面的内容写入 w。最后，调用 free 函数，将 pp 指针归还到 Pool 中：<br><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"> <span class="function"><span class="keyword">func</span> <span class="params">(p *pp)</span></span> free() &#123;  </span><br><span class="line">   <span class="keyword">if</span> <span class="built_in">cap</span>(p.buf) &gt; <span class="number">64</span>&lt;&lt;<span class="number">10</span> &#123;  </span><br><span class="line">     <span class="keyword">return</span>  </span><br><span class="line">   &#125;  </span><br><span class="line"> ​  </span><br><span class="line">   p.buf = p.buf[:<span class="number">0</span>]  </span><br><span class="line">   p.arg = <span class="literal">nil</span>  </span><br><span class="line">   p.value = reflect.Value&#123;&#125;  </span><br><span class="line">   p.wrappedErr = <span class="literal">nil</span>  </span><br><span class="line">   ppFree.Put(p)  </span><br><span class="line"> &#125;</span><br></pre></td></tr></table></figure><br>归还到 Pool 前还进行了<strong>字段清零</strong>，这样，通过 Get 拿到缓存的对象时，就可以安全地使用了。</p>
<h4 id="1-3-2-gin-框架"><a href="#1-3-2-gin-框架" class="headerlink" title="1.3.2 gin 框架"></a>1.3.2 gin 框架</h4><p>gin 框架会给每个请求分配一个 Context 用以进行追踪，这就是典型的 sync.pool 使用场景：<br><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">New</span><span class="params">()</span></span> *Engine &#123;  </span><br><span class="line">	engine := &amp;Engine&#123;  </span><br><span class="line">		  </span><br><span class="line">	&#125;  </span><br><span class="line">	engine.pool.New = <span class="function"><span class="keyword">func</span><span class="params">()</span></span> <span class="keyword">interface</span>&#123;&#125; &#123;  </span><br><span class="line">		<span class="keyword">return</span> engine.allocateContext()  </span><br><span class="line">	&#125;  </span><br><span class="line">	<span class="keyword">return</span> engine  </span><br><span class="line">&#125;  </span><br><span class="line">  </span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(engine *Engine)</span></span> allocateContext() *Context &#123;  </span><br><span class="line">	<span class="keyword">return</span> &amp;Context&#123;engine: engine&#125;  </span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(engine *Engine)</span></span> ServeHTTP(w http.ResponseWriter, req *http.Request) &#123;  </span><br><span class="line">	c := engine.pool.Get().(*Context)  </span><br><span class="line">	c.writermem.reset(w)  </span><br><span class="line">	c.Request = req  </span><br><span class="line">	c.reset()  </span><br><span class="line">  </span><br><span class="line">	engine.handleHTTPRequest(c)  </span><br><span class="line">  </span><br><span class="line">	engine.pool.Put(c)  </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><br>从 pool 中获取 Context 对象，用完后又还回去，注意 还回去之前这里也调用了 reset() 方法进行<strong>字段清空</strong>。</p>
<h3 id="1-4-正确姿势"><a href="#1-4-正确姿势" class="headerlink" title="1.4 正确姿势"></a>1.4 正确姿势</h3><p>根据以上几个案例，可以看出正确使用姿势就是：</p>
<ul>
<li><p>1）设置 New 方法</p>
</li>
<li><p>2）使用时直接 Get</p>
</li>
<li><p>3）使用完成后先进行<strong>字段清空</strong>,然后在 Put 回去。</p>
</li>
</ul>
<blockquote>
<p>一定要进行 Reset，不然会出现意想不到的问题。分享一个<a target="_blank" rel="noopener" href="https://github.com/lixd/daily-notes/blob/master/Golang/FAQ/mongodb%E9%87%87%E5%9D%91.md">类似的坑</a></p>
</blockquote>
<h2 id="2-源码分析"><a href="#2-源码分析" class="headerlink" title="2 源码分析"></a>2 源码分析</h2><blockquote>
<p>一下分析基于 Go 1.17.1</p>
</blockquote>
<h3 id="2-1-Pool-结构体"><a href="#2-1-Pool-结构体" class="headerlink" title="2.1 Pool 结构体"></a>2.1 Pool 结构体</h3><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">type</span> Pool <span class="keyword">struct</span> &#123;  </span><br><span class="line">	noCopy noCopy  </span><br><span class="line">	local     unsafe.Pointer <span class="comment">// local fixed-size per-P pool, actual type is [P]poolLocal  </span></span><br><span class="line">	localSize <span class="type">uintptr</span>        <span class="comment">// size of the local array  </span></span><br><span class="line">	victim     unsafe.Pointer <span class="comment">// local from previous cycle  </span></span><br><span class="line">	victimSize <span class="type">uintptr</span>        <span class="comment">// size of victims array  </span></span><br><span class="line">	New <span class="function"><span class="keyword">func</span><span class="params">()</span></span> <span class="keyword">interface</span>&#123;&#125;  </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>字段详解：</p>
<ul>
<li><code>noCopy</code>对象，实现了<code>sync.Locker</code>接口，使得内嵌了 noCopy 的对象在进行 go vet 静态检查的时候，可以检查出是否被复制。<ul>
<li>具体见 <a target="_blank" rel="noopener" href="https://github.com/golang/go/issues/8005">Go issues 8005</a></li>
<li>说明 Pool 对象也是不允许复制的。</li>
</ul>
</li>
<li><code>local</code> 字段存储指向 <code>[P]poolLocal</code> 数组（严格来说，它是一个切片）的指针。<code>localSize</code> 则表示 local 数组的大小。<ul>
<li>访问时，根据 P 的 id 去访问对应下标的 <code>local[pid]</code></li>
<li>通过这样的设计，多个 goroutine 使用同一个 Pool 时，减少了竞争，提升了性能。</li>
<li>有点类似于降低锁粒度，分段锁的思想。</li>
</ul>
</li>
<li><code>victim</code> 和 <code>victimSize</code> 则会在在一轮 GC 到来时，分别“接管” local 和 localSize。<ul>
<li>victim cache 是一种提高缓存性能的硬件技术;</li>
<li><code>victim</code> 的机制用于减少 GC 后冷启动导致的性能抖动，让分配对象更平滑;</li>
</ul>
</li>
<li><code>New</code>就是我们指定的新建对象的方法。</li>
</ul>
<blockquote>
<p><a target="_blank" rel="noopener" href="https://en.wikipedia.org/wiki/Victim_cache">Victim Cache</a> 是一种提高缓存性能的硬件技术，主要用于提升缓存命令率。<br>所谓受害者缓存（Victim Cache），是一个与直接匹配或低相联缓存并用的、容量很小的全相联缓存。当一个数据块被逐出缓存时，并不直接丢弃，而是暂先进入受害者缓存。如果受害者缓存已满，就替换掉其中一项。当进行缓存标签匹配时，在与索引指向标签匹配的同时，并行查看受害者缓存，如果在受害者缓存发现匹配，就将其此数据块与缓存中的不匹配数据块做交换，同时返回给处理器。</p>
</blockquote>
<h4 id="2-1-1-local"><a href="#2-1-1-local" class="headerlink" title="2.1.1 local"></a>2.1.1 local</h4><p>local 具体结构如下：<br><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">type</span> poolLocal <span class="keyword">struct</span> &#123;  </span><br><span class="line">	poolLocalInternal  </span><br><span class="line">    <span class="comment">// 将 poolLocal 补齐至128字节(即两个cache line)的倍数，防止 false sharing,  </span></span><br><span class="line">    <span class="comment">// 伪共享，仅占位用，防止在 cache line 上分配多个 poolLocalInternal  </span></span><br><span class="line">	pad [<span class="number">128</span> - unsafe.Sizeof(poolLocalInternal&#123;&#125;)%<span class="number">128</span>]<span class="type">byte</span>  </span><br><span class="line">&#125;  </span><br><span class="line"><span class="keyword">type</span> poolLocalInternal <span class="keyword">struct</span> &#123;  </span><br><span class="line">	private <span class="keyword">interface</span>&#123;&#125; <span class="comment">// Can be used only by the respective P.  </span></span><br><span class="line">	shared  poolChain   <span class="comment">// Local P can pushHead/popHead; any P can popTail.  </span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><br><code>poolLocalInternal</code>对象 中包含一个 <code>private</code> 和 <code>shared</code>。其中 private 只有当前 p 能用，shared 则是其他 p 都可以用。</p>
<h4 id="2-1-2-cpu-cache-amp-false-sharing"><a href="#2-1-2-cpu-cache-amp-false-sharing" class="headerlink" title="2.1.2 cpu cache &amp; false sharing"></a>2.1.2 cpu cache &amp; false sharing</h4><p><strong>cpu cache</strong><br>现代 cpu 中，cache 都划分成以 cache line (cache block) 为单位，在 x86_64 体系下一般都是 64 字节，cache line 是操作的最小单元。 程序即使只想读内存中的 1 个字节数据，也要同时把附近 63 节字加载到 cache 中，如果读取超个 64 字节，那么就要加载到多个 cache line 中。<br>这样，访问后续 63 字节数据时就可以直接从 cache line 中读取，性能有很大提升。</p>
<p><strong><a target="_blank" rel="noopener" href="https://en.wikipedia.org/wiki/False_sharing">false sharing</a></strong></p>
<blockquote>
<p>伪共享的非标准定义为：缓存系统中是以缓存行（cache line）为单位存储的，当多线程修改互相独立的变量时，如果这些变量共享同一个缓存行，就会令整个 cache line 失效，无意中影响彼此的性能，这就是伪共享。</p>
</blockquote>
<p>简单来说，如果没有 pad 字段，那么当需要访问 0 号索引的 poolLocal 时，CPU 同时会把 0 号和 1 号索引同时加载到 cpu cache。在只修改 0 号索引的情况下，会让 1 号索引的 poolLocal 失效。这样，当其他线程想要读取 1 号索引时，发生 cache miss，还得重新再加载，对性能有损。增加一个 <code>pad</code>，补齐缓存行，让相关的字段能独立地加载到缓存行就不会出现 <code>false sharding</code> 了。</p>
<h4 id="2-1-3-poolChain"><a href="#2-1-3-poolChain" class="headerlink" title="2.1.3 poolChain"></a>2.1.3 poolChain</h4><p><code>poolChain</code> 是一个双端队列的实现<br><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">type</span> poolChain <span class="keyword">struct</span> &#123;  </span><br><span class="line">  </span><br><span class="line">   head *poolChainElt  </span><br><span class="line">  </span><br><span class="line">   tail *poolChainElt  </span><br><span class="line">&#125;  </span><br><span class="line">  </span><br><span class="line"><span class="keyword">type</span> poolChainElt <span class="keyword">struct</span> &#123;  </span><br><span class="line">	poolDequeue  </span><br><span class="line">  </span><br><span class="line">	next, prev *poolChainElt  </span><br><span class="line">&#125;  </span><br><span class="line">  </span><br><span class="line"><span class="keyword">type</span> poolDequeue <span class="keyword">struct</span> &#123;  </span><br><span class="line">  </span><br><span class="line">	headTail <span class="type">uint64</span>  </span><br><span class="line">  </span><br><span class="line">	vals []eface  </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><br><code>poolDequeue</code> 被实现为单生产者、多消费者的固定大小的无锁（atomic 实现） Ring 式队列（底层存储使用数组，使用两个指针标记 head、tail）。生产者可以从 head 插入、head 删除，而消费者仅可从 tail 删除。 <code>headTail</code> 指向队列的头和尾，通过位运算将 head 和 tail 存入 headTail 变量中。</p>
<p>我们用一幅图来完整地描述 Pool 结构体：</p>
<p>![[pool-structure.png]]</p>
<blockquote>
<p>图源：<a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/133638023">码农桃花源</a></p>
<h3 id="2-2-大致流程"><a href="#2-2-大致流程" class="headerlink" title="2.2 大致流程"></a>2.2 大致流程</h3></blockquote>
<p>分析完 Pool 结构体之后，先提前说明一下大致的流程，后续分析时便于理解。</p>
<p><strong>存储</strong></p>
<p>为每个 P 开辟了一个 Local 用于数据，降低竞争。</p>
<p>Local 中包含 private 和 shared。</p>
<ul>
<li><p>private ：只有当前 P 能使用</p>
</li>
<li><p>shared：所有 P 共享，当 private 没有时优先去当前 P 的 local.shared 中取，如果还没有就去其他 P 中 local.shared 中窃取一个来用。</p>
</li>
</ul>
<p><strong>Get</strong></p>
<p>优先从当前P 的 local.private 中取，没有则从当前 P 的 local.shared 中取，还没有则去其他 P 中 local.shared 中窃取一个。</p>
<p><strong>Put</strong></p>
<p>优先存放到当前 P 的 local.private，local.private 已经有值了就往 shared 中放。</p>
<h3 id="2-3-Get"><a href="#2-3-Get" class="headerlink" title="2.3 Get"></a>2.3 Get</h3><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(p *Pool)</span></span> Get() <span class="keyword">interface</span>&#123;&#125; &#123;  </span><br><span class="line">	<span class="comment">// ...  </span></span><br><span class="line">	l, pid := p.pin()  </span><br><span class="line">	x := l.private  </span><br><span class="line">	l.private = <span class="literal">nil</span>  </span><br><span class="line">	<span class="keyword">if</span> x == <span class="literal">nil</span> &#123;  </span><br><span class="line">		x, _ = l.shared.popHead()  </span><br><span class="line">		<span class="keyword">if</span> x == <span class="literal">nil</span> &#123;  </span><br><span class="line">			x = p.getSlow(pid)  </span><br><span class="line">		&#125;  </span><br><span class="line">	&#125;  </span><br><span class="line">	runtime_procUnpin()  </span><br><span class="line">	<span class="comment">// ...  </span></span><br><span class="line">	<span class="keyword">if</span> x == <span class="literal">nil</span> &amp;&amp; p.New != <span class="literal">nil</span> &#123;  </span><br><span class="line">		x = p.New()  </span><br><span class="line">	&#125;  </span><br><span class="line">	<span class="keyword">return</span> x  </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>流程如下：</p>
<ol>
<li><p>首先，调用 <code>p.pin()</code> 函数将当前的 goroutine 和 P 绑定，禁止被抢占，返回当前 P 对应的 poolLocal，以及 pid。</p>
</li>
<li><p>然后直接取 l.private，赋值给 x，并置 l.private 为 nil。</p>
</li>
<li><p>判断 x 是否为空，若为空，则尝试从 l.shared 的头部 pop 一个对象出来，同时赋值给 x。</p>
</li>
<li><p>如果 x 仍然为空，则调用 getSlow 尝试从其他 P 的 shared 双端队列尾部“偷”一个对象出来。</p>
</li>
<li><p>Pool 的相关操作做完了，调用 <code>runtime_procUnpin()</code> 解除禁止抢占。</p>
</li>
<li><p>最后如果还是没有取到缓存的对象，那就直接调用预先设置好的 New 函数，创建一个出来。</p>
</li>
</ol>
<h4 id="2-3-1-pin"><a href="#2-3-1-pin" class="headerlink" title="2.3.1 pin"></a>2.3.1 pin</h4><p>首先，调用 <code>p.pin()</code> 函数将当前的 goroutine 和 P 绑定，禁止被抢占，返回当前 P 对应的 poolLocal，以及 pid。<br><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(p *Pool)</span></span> pin() (*poolLocal, <span class="type">int</span>) &#123;  </span><br><span class="line">   <span class="comment">// pin 具体逻辑由 runtime_procPin 实现  </span></span><br><span class="line">   pid :=  runtime_procPin()  </span><br><span class="line">   <span class="comment">// 原子操作取出 p.localSize 和 p.local  </span></span><br><span class="line">   s := runtime_LoadAcquintptr(&amp;p.localSize) <span class="comment">// load-acquire  </span></span><br><span class="line">   l := p.local                              <span class="comment">// load-consume  </span></span><br><span class="line">   <span class="comment">// 因为是把 pid 做下标从 pool.local 中取得 p 对应的 local 的，  </span></span><br><span class="line">   <span class="comment">// 所以如果 pid 小于 pool.local size 的时候才有可能取到对应的 local  </span></span><br><span class="line">   <span class="keyword">if</span> <span class="type">uintptr</span>(pid) &lt; s &#123;  </span><br><span class="line">      <span class="keyword">return</span> indexLocal(l, pid), pid  </span><br><span class="line">   &#125;  </span><br><span class="line">   <span class="comment">// 正常情况下会一直满足该条件，  </span></span><br><span class="line">   <span class="comment">// 只有刚开始  pool.local 还没创建或者动态调整了 P 的数量这两种情况  </span></span><br><span class="line">   <span class="comment">// 会进入到下面的逻辑 去创建 pool.local  </span></span><br><span class="line">   <span class="keyword">return</span> p.pinSlow()  </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<h4 id="2-3-2-pinSlow"><a href="#2-3-2-pinSlow" class="headerlink" title="2.3.2 pinSlow"></a>2.3.2 pinSlow</h4><p>pinSlow 主要是完成 pool.local 的创建。<br><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(p *Pool)</span></span> pinSlow() (*poolLocal, <span class="type">int</span>) &#123;  </span><br><span class="line">    <span class="comment">// 这里先取消绑定，然后加锁，最后有绑定上  </span></span><br><span class="line">	runtime_procUnpin()  </span><br><span class="line">	allPoolsMu.Lock()  </span><br><span class="line">	<span class="keyword">defer</span> allPoolsMu.Unlock()  </span><br><span class="line">	pid := runtime_procPin()  </span><br><span class="line">	<span class="comment">// doubleCheck 因为在执行上述命令过程中 pinSlow 可能已经被其他的线程调用，因此这时候需要再次对 pid 进行检查  </span></span><br><span class="line">	s := p.localSize  </span><br><span class="line">	l := p.local  </span><br><span class="line">	<span class="keyword">if</span> <span class="type">uintptr</span>(pid) &lt; s &#123;  </span><br><span class="line">		<span class="keyword">return</span> indexLocal(l, pid), pid  </span><br><span class="line">	&#125;  </span><br><span class="line">	<span class="keyword">if</span> p.local == <span class="literal">nil</span> &#123;  </span><br><span class="line">		allPools = <span class="built_in">append</span>(allPools, p)  </span><br><span class="line">	&#125;  </span><br><span class="line">	<span class="comment">// 根据当前 P 的数量创建 pool.local并更新pool.localSize  </span></span><br><span class="line">	size := runtime.GOMAXPROCS(<span class="number">0</span>)  </span><br><span class="line">	local := <span class="built_in">make</span>([]poolLocal, size)  </span><br><span class="line">	atomic.StorePointer(&amp;p.local, unsafe.Pointer(&amp;local[<span class="number">0</span>])) <span class="comment">// store-release  </span></span><br><span class="line">	runtime_StoreReluintptr(&amp;p.localSize, <span class="type">uintptr</span>(size))     <span class="comment">// store-release  </span></span><br><span class="line">    <span class="comment">// 最后根据 pid 返回当前 P 对应的 local  </span></span><br><span class="line">	<span class="keyword">return</span> &amp;local[pid], pid  </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><br><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">#### popHead</span><br><span class="line"></span><br><span class="line">然后回到 Get 方法</span><br><span class="line">```go</span><br><span class="line">x := l.private  </span><br><span class="line">	l.private = nil  </span><br><span class="line">	if x == nil &#123;  </span><br><span class="line">		x, _ = l.shared.popHead()  </span><br><span class="line">		if x == nil &#123;  </span><br><span class="line">			x = p.getSlow(pid)  </span><br><span class="line">		&#125;  </span><br><span class="line">	&#125;</span><br></pre></td></tr></table></figure></p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">优先从 local.private 中取，如果没有就调用`poolChain.popHead()`去 local.shared 中取一个。</span><br><span class="line">```go</span><br><span class="line">func (c *poolChain) popHead() (interface&#123;&#125;, bool) &#123;  </span><br><span class="line">	d := c.head  </span><br><span class="line">	for d != nil &#123;  </span><br><span class="line">		if val, ok := d.popHead(); ok &#123;  </span><br><span class="line">			return val, ok  </span><br><span class="line">		&#125;  </span><br><span class="line">		d = loadPoolChainElt(&amp;d.prev)  </span><br><span class="line">	&#125;  </span><br><span class="line">	return nil, false  </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">`popHead` 函数只会被 producer 调用。首先拿到头节点：c.head，如果头节点不为空的话，尝试调用头节点的 `poolDequeue.popHead` 方法。</span><br><span class="line">```go</span><br><span class="line">func (d *poolDequeue) popHead() (interface&#123;&#125;, bool) &#123;  </span><br><span class="line">	var slot *eface  </span><br><span class="line">	for &#123;  </span><br><span class="line">		ptrs := atomic.LoadUint64(&amp;d.headTail)  </span><br><span class="line">		head, tail := d.unpack(ptrs)  </span><br><span class="line">        // 收尾相连则说明队列是空的  </span><br><span class="line">		if tail == head &#123;  </span><br><span class="line">			return nil, false  </span><br><span class="line">		&#125;  </span><br><span class="line">  </span><br><span class="line">		// head 位置是队头的前一个位置，所以此处要先退一位。  </span><br><span class="line">        // 在读出 slot 的 value 之前就把 head 值减 1，取消对这个 slot 的控制  </span><br><span class="line">		head--  </span><br><span class="line">		ptrs2 := d.pack(head, tail)  </span><br><span class="line">        // 通过 CAS 操作更新头部的位置 这样当前头部第一个元素就算是被移除了  </span><br><span class="line">		if atomic.CompareAndSwapUint64(&amp;d.headTail, ptrs, ptrs2) &#123;  </span><br><span class="line">			slot = &amp;d.vals[head&amp;uint32(len(d.vals)-1)]  </span><br><span class="line">			break  </span><br><span class="line">		&#125;  </span><br><span class="line">	&#125;  </span><br><span class="line">    // 类型转换与 nil 判断  </span><br><span class="line">	val := *(*interface&#123;&#125;)(unsafe.Pointer(slot))  </span><br><span class="line">	if val == dequeueNil(nil) &#123;  </span><br><span class="line">		val = nil  </span><br><span class="line">	&#125;  </span><br><span class="line">    // 然后把这个 slot 置空，因为现在这个 slot 已经是队列的 head 了，置空便于前一个 head 被回收。  </span><br><span class="line">	*slot = eface&#123;&#125;  </span><br><span class="line">	return val, true  </span><br><span class="line">&#125;```</span><br></pre></td></tr></table></figure>
<p>此函数会删掉并且返回 <code>queue</code> 的头节点。但如果 <code>queue</code> 为空的话，返回 false。这里的 <code>queue</code> 存储的实际上就是 Pool 里缓存的对象。</p>
<p>整个函数的核心是一个无限循环，这是 Go 中常用的无锁化编程形式。</p>
<p>首先调用 unpack 函数分离出 head 和 tail 指针，如果 head 和 tail 相等，即首尾相等，那么这个队列就是空的，直接就返回 nil，false。</p>
<p>否则，将 head 指针后移一位，即 head 值减 1，然后调用 pack 打包 head 和 tail 指针。使用 CAS 更新 headTail 的值，并且把 vals 相应索引处的元素赋值给 slot。</p>
<blockquote>
<p>因为 <code>vals</code> 长度实际是只能是 2 的 n 次幂，因此 <code>len(d.vals)-1</code> 实际上得到的值的低 n 位是全 1，它再与 head 进行与运算，实际就是取 head 低 n 位的值作为下标。</p>
</blockquote>
<p>得到相应 slot 的元素后，经过类型转换并判断是否是 <code>dequeueNil</code>，如果是，说明没取到缓存的对象，返回 nil。</p>
<p>type dequeueNil *struct{}</p>
<p>最后，返回 val 之前，将 slot “归零”，移除和上一个 head 的关联，便于回收上一个 Head。</p>
<p>*slot = eface{}</p>
<p>结束后回到 <code>poolChain.popHead()</code>，如果调用 <code>poolDequeue.popHead()</code> 拿到了缓存的对象，就直接返回。否则，将 <code>d</code> 重新指向 <code>d.prev</code>，继续尝试获取缓存的对象。</p>
<h4 id="2-3-3-getSlow"><a href="#2-3-3-getSlow" class="headerlink" title="2.3.3 getSlow"></a>2.3.3 getSlow</h4><p>如果在 shared 里没有获取到缓存对象，则继续调用 <code>Pool.getSlow()</code>，尝试从其他 P 的 poolLocal 偷取：<br><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(p *Pool)</span></span> getSlow(pid <span class="type">int</span>) <span class="keyword">interface</span>&#123;&#125; &#123;  </span><br><span class="line">	size := runtime_LoadAcquintptr(&amp;p.localSize) <span class="comment">// load-acquire  </span></span><br><span class="line">	locals := p.local                            <span class="comment">// load-consume  </span></span><br><span class="line">    <span class="comment">// 尝试从其他 p 中窃取一个对象  </span></span><br><span class="line">	<span class="keyword">for</span> i := <span class="number">0</span>; i &lt; <span class="type">int</span>(size); i++ &#123;  </span><br><span class="line">        <span class="comment">// (pid+i+1)%int(size) 保证每次都可以从 当前pid+1 这个位置开始尝试窃取。  </span></span><br><span class="line">		l := indexLocal(locals, (pid+i+<span class="number">1</span>)%<span class="type">int</span>(size))  </span><br><span class="line">        <span class="comment">// 如果能取到就直接返回  </span></span><br><span class="line">		<span class="keyword">if</span> x, _ := l.shared.popTail(); x != <span class="literal">nil</span> &#123;  </span><br><span class="line">			<span class="keyword">return</span> x  </span><br><span class="line">		&#125;  </span><br><span class="line">	&#125;  </span><br><span class="line">  </span><br><span class="line">    <span class="comment">// 尝试从其他 P 的 poolLocal 窃取失败后，再尝试从victim cache中取对象  </span></span><br><span class="line">    <span class="comment">// 这样可以使 victim 中的对象更容易被回收。  </span></span><br><span class="line">	size = atomic.LoadUintptr(&amp;p.victimSize)  </span><br><span class="line">	<span class="keyword">if</span> <span class="type">uintptr</span>(pid) &gt;= size &#123;  </span><br><span class="line">		<span class="keyword">return</span> <span class="literal">nil</span>  </span><br><span class="line">	&#125;  </span><br><span class="line">	locals = p.victim  </span><br><span class="line">	l := indexLocal(locals, pid)  </span><br><span class="line">	<span class="keyword">if</span> x := l.private; x != <span class="literal">nil</span> &#123;  </span><br><span class="line">		l.private = <span class="literal">nil</span>  </span><br><span class="line">		<span class="keyword">return</span> x  </span><br><span class="line">	&#125;  </span><br><span class="line">	<span class="keyword">for</span> i := <span class="number">0</span>; i &lt; <span class="type">int</span>(size); i++ &#123;  </span><br><span class="line">		l := indexLocal(locals, (pid+i)%<span class="type">int</span>(size))  </span><br><span class="line">		<span class="keyword">if</span> x, _ := l.shared.popTail(); x != <span class="literal">nil</span> &#123;  </span><br><span class="line">			<span class="keyword">return</span> x  </span><br><span class="line">		&#125;  </span><br><span class="line">	&#125;  </span><br><span class="line">  </span><br><span class="line">    <span class="comment">// 清空 victim cache。下次就不用再从这里找了  </span></span><br><span class="line">	atomic.StoreUintptr(&amp;p.victimSize, <span class="number">0</span>)  </span><br><span class="line">  </span><br><span class="line">	<span class="keyword">return</span> <span class="literal">nil</span>  </span><br><span class="line">&#125;<span class="string">``</span><span class="string">`</span></span><br></pre></td></tr></table></figure></p>
<p>从索引为 pid+1 的 poolLocal 处开始，尝试调用 <code>shared.popTail()</code> 获取缓存对象。如果没有拿到，则从 victim 里找，和 poolLocal 的逻辑类似。</p>
<p>最后，实在没找到，就把 victimSize 置 0，防止后来的“人”再到 victim 里找。</p>
<p>在 Get 函数的最后，经过这一番操作还是没找到缓存的对象，就调用 New 函数创建一个新的对象。</p>
<h4 id="2-3-4-popTail"><a href="#2-3-4-popTail" class="headerlink" title="2.3.4 popTail"></a>2.3.4 popTail</h4><p>最后，还剩一个 popTail 函数：<br><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(c *poolChain)</span></span> popTail() (<span class="keyword">interface</span>&#123;&#125;, <span class="type">bool</span>) &#123;  </span><br><span class="line">    <span class="comment">// tail 指针为空直接返回 这里的 tail 是一个双端队列  </span></span><br><span class="line">	d := loadPoolChainElt(&amp;c.tail)  </span><br><span class="line">	<span class="keyword">if</span> d == <span class="literal">nil</span> &#123;  </span><br><span class="line">		<span class="keyword">return</span> <span class="literal">nil</span>, <span class="literal">false</span>  </span><br><span class="line">	&#125;  </span><br><span class="line">  </span><br><span class="line">	<span class="keyword">for</span> &#123;  </span><br><span class="line">		<span class="comment">// It&#x27;s important that we load the next pointer  </span></span><br><span class="line">		<span class="comment">// *before* popping the tail. In general, d may be  </span></span><br><span class="line">		<span class="comment">// transiently empty, but if next is non-nil before  </span></span><br><span class="line">		<span class="comment">// the pop and the pop fails, then d is permanently  </span></span><br><span class="line">		<span class="comment">// empty, which is the only condition under which it&#x27;s  </span></span><br><span class="line">		<span class="comment">// safe to drop d from the chain.  </span></span><br><span class="line">        <span class="comment">// 在 for 循环的一开始，就把 d.next 加载到了 d2。因为 d 可能会短暂为空，但如果 d2 在 pop 或者 pop fails 之前就不为空的话，说明 d 就会永久为空了。在这种情况下，可以安全地将 d 这个结点“甩掉”。  </span></span><br><span class="line">		d2 := loadPoolChainElt(&amp;d.next)  </span><br><span class="line">  </span><br><span class="line">		<span class="keyword">if</span> val, ok := d.popTail(); ok &#123;  </span><br><span class="line">			<span class="keyword">return</span> val, ok  </span><br><span class="line">		&#125;  </span><br><span class="line">  </span><br><span class="line">		<span class="keyword">if</span> d2 == <span class="literal">nil</span> &#123;  </span><br><span class="line">			<span class="comment">// This is the only dequeue. It&#x27;s empty right  </span></span><br><span class="line">			<span class="comment">// now, but could be pushed to in the future.  </span></span><br><span class="line">			<span class="keyword">return</span> <span class="literal">nil</span>, <span class="literal">false</span>  </span><br><span class="line">		&#125;  </span><br><span class="line">  </span><br><span class="line">		<span class="comment">// 同样的通过 CAS 来更新 tail 的值为 d2  </span></span><br><span class="line">		<span class="keyword">if</span> atomic.CompareAndSwapPointer((*unsafe.Pointer)(unsafe.Pointer(&amp;c.tail)), unsafe.Pointer(d), unsafe.Pointer(d2)) &#123;  </span><br><span class="line">			storePoolChainElt(&amp;d2.prev, <span class="literal">nil</span>)  </span><br><span class="line">		&#125;  </span><br><span class="line">        <span class="comment">// 最后将d2赋值给d便于进行下一轮循环。  </span></span><br><span class="line">		d = d2  </span><br><span class="line">	&#125;  </span><br><span class="line">&#125;  </span><br></pre></td></tr></table></figure></p>
<p>在 for 循环的一开始，就把 d.next 加载到了 d2。因为 d 可能会短暂为空，但如果 d2 在 pop 或者 pop fails 之前就不为空的话，说明 d 就会永久为空了。在这种情况下，可以安全地将 d 这个结点“甩掉”。</p>
<p>最后，将 c.tail 更新为 d2，可以防止下次 popTail 的时候查看一个空的 dequeue；而将 d2.prev 设置为 nil，可以防止下次 popHead 时查看一个空的 dequeue。</p>
<p>我们再看一下核心的 <code>poolDequeue.popTail</code>：<br><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(d *poolDequeue)</span></span> popTail() (<span class="keyword">interface</span>&#123;&#125;, <span class="type">bool</span>) &#123;  </span><br><span class="line">	<span class="keyword">var</span> slot *eface  </span><br><span class="line">	<span class="keyword">for</span> &#123;  </span><br><span class="line">		ptrs := atomic.LoadUint64(&amp;d.headTail)  </span><br><span class="line">		head, tail := d.unpack(ptrs)  </span><br><span class="line">        <span class="comment">// 同样的 head=tail 说明队列为空  </span></span><br><span class="line">		<span class="keyword">if</span> tail == head &#123;  </span><br><span class="line">			<span class="keyword">return</span> <span class="literal">nil</span>, <span class="literal">false</span>  </span><br><span class="line">		&#125;  </span><br><span class="line">  </span><br><span class="line">		<span class="comment">// 同样是 CAS 更新 headTail 以移除 tail 元素  </span></span><br><span class="line">		ptrs2 := d.pack(head, tail+<span class="number">1</span>)  </span><br><span class="line">		<span class="keyword">if</span> atomic.CompareAndSwapUint64(&amp;d.headTail, ptrs, ptrs2) &#123;  </span><br><span class="line">			<span class="comment">// Success.  </span></span><br><span class="line">			slot = &amp;d.vals[tail&amp;<span class="type">uint32</span>(<span class="built_in">len</span>(d.vals)<span class="number">-1</span>)]  </span><br><span class="line">			<span class="keyword">break</span>  </span><br><span class="line">		&#125;  </span><br><span class="line">	&#125;  </span><br><span class="line">  </span><br><span class="line">	<span class="comment">// 类型转换和 nil 判断  </span></span><br><span class="line">	val := *(*<span class="keyword">interface</span>&#123;&#125;)(unsafe.Pointer(slot))  </span><br><span class="line">	<span class="keyword">if</span> val == dequeueNil(<span class="literal">nil</span>) &#123;  </span><br><span class="line">		val = <span class="literal">nil</span>  </span><br><span class="line">	&#125;  </span><br><span class="line">  </span><br><span class="line">    <span class="comment">// 最后也是将这个 slot 置空  </span></span><br><span class="line">    <span class="comment">// 先清空 val 再清空 typ 操作顺序和 pushHead 正好相反  </span></span><br><span class="line">	slot.val = <span class="literal">nil</span>  </span><br><span class="line">	atomic.StorePointer(&amp;slot.typ, <span class="literal">nil</span>)  </span><br><span class="line">  </span><br><span class="line">  </span><br><span class="line">	<span class="keyword">return</span> val, <span class="literal">true</span>  </span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(d *poolDequeue)</span></span> popTail() (<span class="keyword">interface</span>&#123;&#125;, <span class="type">bool</span>) &#123;  </span><br><span class="line">	<span class="keyword">var</span> slot *eface  </span><br><span class="line">	<span class="keyword">for</span> &#123;  </span><br><span class="line">		ptrs := atomic.LoadUint64(&amp;d.headTail)  </span><br><span class="line">		head, tail := d.unpack(ptrs)  </span><br><span class="line">        <span class="comment">// 同样的 head=tail 说明队列为空  </span></span><br><span class="line">		<span class="keyword">if</span> tail == head &#123;  </span><br><span class="line">			<span class="keyword">return</span> <span class="literal">nil</span>, <span class="literal">false</span>  </span><br><span class="line">		&#125;  </span><br><span class="line">  </span><br><span class="line">		<span class="comment">// 同样是 CAS 更新 headTail 以移除 tail 元素  </span></span><br><span class="line">		ptrs2 := d.pack(head, tail+<span class="number">1</span>)  </span><br><span class="line">		<span class="keyword">if</span> atomic.CompareAndSwapUint64(&amp;d.headTail, ptrs, ptrs2) &#123;  </span><br><span class="line">			<span class="comment">// Success.  </span></span><br><span class="line">			slot = &amp;d.vals[tail&amp;<span class="type">uint32</span>(<span class="built_in">len</span>(d.vals)<span class="number">-1</span>)]  </span><br><span class="line">			<span class="keyword">break</span>  </span><br><span class="line">		&#125;  </span><br><span class="line">	&#125;  </span><br><span class="line">  </span><br><span class="line">	<span class="comment">// 类型转换和 nil 判断  </span></span><br><span class="line">	val := *(*<span class="keyword">interface</span>&#123;&#125;)(unsafe.Pointer(slot))  </span><br><span class="line">	<span class="keyword">if</span> val == dequeueNil(<span class="literal">nil</span>) &#123;  </span><br><span class="line">		val = <span class="literal">nil</span>  </span><br><span class="line">	&#125;  </span><br><span class="line">  </span><br><span class="line">    <span class="comment">// 最后也是将这个 slot 置空  </span></span><br><span class="line">    <span class="comment">// 先清空 val 再清空 typ 操作顺序和 pushHead 正好相反  </span></span><br><span class="line">	slot.val = <span class="literal">nil</span>  </span><br><span class="line">	atomic.StorePointer(&amp;slot.typ, <span class="literal">nil</span>)  </span><br><span class="line">	<span class="keyword">return</span> val, <span class="literal">true</span>  </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<p>整体逻辑和 popHead 差不多。</p>
<h4 id="2-3-5-小结"><a href="#2-3-5-小结" class="headerlink" title="2.3.5 小结"></a>2.3.5 小结</h4><p>首先从 当前 p 对应的 local.private 上取，没有就从 local.shared 里取，还没有就去其他 p 的 local.shared 里取，都没有就 new 一个返回。</p>
<h3 id="2-4-Put"><a href="#2-4-Put" class="headerlink" title="2.4 Put"></a>2.4 Put</h3><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(p *Pool)</span></span> Put(x <span class="keyword">interface</span>&#123;&#125;) &#123;  </span><br><span class="line">	<span class="keyword">if</span> x == <span class="literal">nil</span> &#123;  </span><br><span class="line">		<span class="keyword">return</span>  </span><br><span class="line">	&#125;  </span><br><span class="line">	<span class="comment">// ...  </span></span><br><span class="line">	l, _ := p.pin()  </span><br><span class="line">	<span class="keyword">if</span> l.private == <span class="literal">nil</span> &#123;  </span><br><span class="line">		l.private = x  </span><br><span class="line">		x = <span class="literal">nil</span>  </span><br><span class="line">	&#125;  </span><br><span class="line">	<span class="keyword">if</span> x != <span class="literal">nil</span> &#123;  </span><br><span class="line">		l.shared.pushHead(x)  </span><br><span class="line">	&#125;  </span><br><span class="line">	runtime_procUnpin()  </span><br><span class="line">	<span class="comment">// ...  </span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>流程也比较简单：</p>
<ol>
<li>先绑定 g 和 P，然后尝试将 x 赋值给 private 字段。</li>
<li>如果失败，就调用 <code>pushHead</code> 方法尝试将其放入 shared 字段所维护的双端队列中。<h4 id="2-4-1-pushHead"><a href="#2-4-1-pushHead" class="headerlink" title="2.4.1 pushHead"></a>2.4.1 pushHead</h4></li>
</ol>
<p>p.pin() 和之前是一样的，就不分析了，主要看一下 pushHead()<br><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(c *poolChain)</span></span> pushHead(val <span class="keyword">interface</span>&#123;&#125;) &#123;  </span><br><span class="line">	d := c.head  </span><br><span class="line">	<span class="keyword">if</span> d == <span class="literal">nil</span> &#123;  </span><br><span class="line">		<span class="comment">// 第一次写入，队列为空则进行初始化 默认长度为8  </span></span><br><span class="line">		<span class="keyword">const</span> initSize = <span class="number">8</span> <span class="comment">// Must be a power of 2  </span></span><br><span class="line">		d = <span class="built_in">new</span>(poolChainElt)  </span><br><span class="line">		d.vals = <span class="built_in">make</span>([]eface, initSize)  </span><br><span class="line">		c.head = d  </span><br><span class="line">		storePoolChainElt(&amp;c.tail, d)  </span><br><span class="line">	&#125;  </span><br><span class="line">	<span class="comment">// 存储元素 存储成功直接返回  </span></span><br><span class="line">	<span class="keyword">if</span> d.pushHead(val) &#123;  </span><br><span class="line">		<span class="keyword">return</span>  </span><br><span class="line">	&#125;  </span><br><span class="line">  </span><br><span class="line">	<span class="comment">// The current dequeue is full. Allocate a new one of twice  </span></span><br><span class="line">	<span class="comment">// the size.  </span></span><br><span class="line">    <span class="comment">// 存储失败说明队列满了 进行扩容  </span></span><br><span class="line">	newSize := <span class="built_in">len</span>(d.vals) * <span class="number">2</span>  </span><br><span class="line">	<span class="keyword">if</span> newSize &gt;= dequeueLimit &#123; <span class="comment">// 限制一下，不能无限扩容  </span></span><br><span class="line">		newSize = dequeueLimit  </span><br><span class="line">	&#125;  </span><br><span class="line">	<span class="comment">// 扩容逻辑也比较简单，就是首尾相连，构成链表  </span></span><br><span class="line">	d2 := &amp;poolChainElt&#123;prev: d&#125;  </span><br><span class="line">	d2.vals = <span class="built_in">make</span>([]eface, newSize)  </span><br><span class="line">	c.head = d2  </span><br><span class="line">	storePoolChainElt(&amp;d.next, d2)  </span><br><span class="line">	d2.pushHead(val)  </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><br>如果 <code>c.head</code> 为空，就要创建一个 poolChainElt，作为首结点，当然也是尾节点。它管理的双端队列的长度，初始为 8，放满之后，再创建一个 poolChainElt 节点时，双端队列的长度就要翻倍。当然，有一个最大长度限制（2^30）：</p>
<p>const dequeueBits = 32  </p>
<p>const dequeueLimit = (1 &lt;&lt; dequeueBits) / 4</p>
<p>调用 <code>poolDequeue.pushHead</code> 尝试将对象放到 poolDeque 里去：<br><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(d *poolDequeue)</span></span> pushHead(val <span class="keyword">interface</span>&#123;&#125;) <span class="type">bool</span> &#123;  </span><br><span class="line">	ptrs := atomic.LoadUint64(&amp;d.headTail)  </span><br><span class="line">	head, tail := d.unpack(ptrs)  </span><br><span class="line">    <span class="comment">// 首先判断队列是否已满： 也就是将尾部指针加上 d.vals 的长度，再取低 31 位，看它是否和 head 相等  </span></span><br><span class="line">	<span class="keyword">if</span> (tail+<span class="type">uint32</span>(<span class="built_in">len</span>(d.vals)))&amp;(<span class="number">1</span>&lt;&lt;dequeueBits<span class="number">-1</span>) == head &#123;  </span><br><span class="line">		<span class="keyword">return</span> <span class="literal">false</span>  </span><br><span class="line">	&#125;  </span><br><span class="line">	slot := &amp;d.vals[head&amp;<span class="type">uint32</span>(<span class="built_in">len</span>(d.vals)<span class="number">-1</span>)]  </span><br><span class="line">  </span><br><span class="line">	<span class="comment">// Check if the head slot has been released by popTail.  </span></span><br><span class="line">	typ := atomic.LoadPointer(&amp;slot.typ)  </span><br><span class="line">	<span class="keyword">if</span> typ != <span class="literal">nil</span> &#123;  </span><br><span class="line">		<span class="comment">// Another goroutine is still cleaning up the tail, so  </span></span><br><span class="line">		<span class="comment">// the queue is actually still full.  </span></span><br><span class="line">		<span class="keyword">return</span> <span class="literal">false</span>  </span><br><span class="line">	&#125;  </span><br><span class="line">  </span><br><span class="line">	<span class="comment">// slot占位，将val存入vals中  </span></span><br><span class="line">	<span class="keyword">if</span> val == <span class="literal">nil</span> &#123;  </span><br><span class="line">		val = dequeueNil(<span class="literal">nil</span>)  </span><br><span class="line">	&#125;  </span><br><span class="line">	*(*<span class="keyword">interface</span>&#123;&#125;)(unsafe.Pointer(slot)) = val  </span><br><span class="line">  </span><br><span class="line">	<span class="comment">// head 增加 1  </span></span><br><span class="line">	atomic.AddUint64(&amp;d.headTail, <span class="number">1</span>&lt;&lt;dequeueBits)  </span><br><span class="line">	<span class="keyword">return</span> <span class="literal">true</span>  </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><br>首先判断队列是否已满：</p>
<pre><code>if (tail+uint32(len(d.vals)))&amp;(1&lt;&lt;dequeueBits-1) == head &#123;  
    return false  
&#125;
</code></pre><p>队列没满，通过 head 指针找到即将填充的 slot 位置：取 head 指针的低 31 位。</p>
<pre><code>slot := &amp;d.vals[head&amp;uint32(len(d.vals)-1)]  

// Check if the head slot has been released by popTail.  
typ := atomic.LoadPointer(&amp;slot.typ)  
if typ != nil &#123;  
    // Another goroutine is still cleaning up the tail, so  
    // the queue is actually still full.  
    return false  
&#125;
</code></pre><p>这里还判断了当前 slot 是否正在被 popTail 释放，popTail 相关语句如下：</p>
<pre><code>// 最后也是将这个 slot 置空  
// 先清空 val 再清空 typ 操作顺序和 pushHead 正好相反  
slot.val = nil  
atomic.StorePointer(&amp;slot.typ, nil)
</code></pre><p>所以如果 slot.typ==nil 就说明这个 slot 正在被 popTail 释放，说明队列其实还是满的，直接返回 false，走后续的扩容逻辑。</p>
<p>最后，将 val 赋值到 slot，并将 head 指针值加 1。</p>
<p>// slot占位，将val存入vals中<br><em>(</em>interface{})(unsafe.Pointer(slot)) = val</p>
<blockquote>
<p>这里的实现比较巧妙，slot 是 eface 类型，即空接口，将 slot 转为 interface{} 类型，这样 val 能以 interface{} 赋值给 slot 让 slot.typ 和 slot.val 指向其内存块，于是 slot.typ 和 slot.val 均不为空。</p>
</blockquote>
<h4 id="2-4-2-pack-unpack"><a href="#2-4-2-pack-unpack" class="headerlink" title="2.4.2 pack/unpack"></a>2.4.2 pack/unpack</h4><p>最后我们再来看一下 pack 和 unpack 函数，它们实际上是一组绑定、解绑 head 和 tail 指针的两个函数。<br><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(d *poolDequeue)</span></span> pack(head, tail <span class="type">uint32</span>) <span class="type">uint64</span> &#123;  </span><br><span class="line">	<span class="keyword">const</span> mask = <span class="number">1</span>&lt;&lt;dequeueBits - <span class="number">1</span>  </span><br><span class="line">	<span class="keyword">return</span> (<span class="type">uint64</span>(head) &lt;&lt; dequeueBits) |  </span><br><span class="line">		<span class="type">uint64</span>(tail&amp;mask)  </span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="string">`mask`</span> 的低 <span class="number">31</span> 位为全 <span class="number">1</span>，其他位为 <span class="number">0</span>，它和 tail 相与，就是只看 tail 的低 <span class="number">31</span> 位。而 head 向左移 <span class="number">32</span> 位之后，低 <span class="number">32</span> 位为全 <span class="number">0</span>。最后把两部分“或”起来，head 和 tail 就“绑定”在一起了。</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(d *poolDequeue)</span></span> unpack(ptrs <span class="type">uint64</span>) (head, tail <span class="type">uint32</span>) &#123;  </span><br><span class="line">	<span class="keyword">const</span> mask = <span class="number">1</span>&lt;&lt;dequeueBits - <span class="number">1</span>  </span><br><span class="line">	head = <span class="type">uint32</span>((ptrs &gt;&gt; dequeueBits) &amp; mask)  </span><br><span class="line">	tail = <span class="type">uint32</span>(ptrs &amp; mask)  </span><br><span class="line">	<span class="keyword">return</span>  </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><br>unpack 则是相反的逻辑，取出 head 指针的方法就是将 ptrs 右移 32 位，再与 mask 相与，同样只看 head 的低 31 位。而 tail 实际上更简单，直接将 ptrs 与 mask 相与就可以了。</p>
<h4 id="2-4-3-小结"><a href="#2-4-3-小结" class="headerlink" title="2.4.3 小结"></a>2.4.3 小结</h4><p>Put 和 Get 类似，首先尝试将放到当前 p 的 local.private 上，已经有了就放到 local.shared。</p>
<h3 id="2-5-GC"><a href="#2-5-GC" class="headerlink" title="2.5 GC"></a>2.5 GC</h3><p>对于 Pool 而言，并不能无限扩展，否则对象占用内存太多了，会引起内存溢出。<br>sync.pool 选择了在 GC 时进行清理。<br>在 pool.go 文件的 init 函数里，注册了 GC 发生时，如何清理 Pool 的函数：<br><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// sync/pool.go  </span></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">init</span><span class="params">()</span></span> &#123;  </span><br><span class="line">	runtime_registerPoolCleanup(poolCleanup)  </span><br><span class="line">&#125;</span><br><span class="line">编译器在编译时将其注册到运行时：</span><br><span class="line"><span class="comment">// src/runtime/mgc.go  </span></span><br><span class="line"><span class="comment">// Hooks for other packages  </span></span><br><span class="line"><span class="keyword">var</span> poolcleanup <span class="function"><span class="keyword">func</span><span class="params">()</span></span>  </span><br><span class="line"><span class="comment">// 利用编译器标志将 sync 包中的清理注册到运行时  </span></span><br><span class="line"><span class="comment">//go:linkname sync_runtime_registerPoolCleanup sync.runtime_registerPoolCleanup  </span></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">sync_runtime_registerPoolCleanup</span><span class="params">(f <span class="keyword">func</span>()</span></span>) &#123;  </span><br><span class="line">  poolcleanup = f  </span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">具体的 poolCleanup() 函数如下：</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">poolCleanup</span><span class="params">()</span></span> &#123;  </span><br><span class="line">	<span class="keyword">for</span> _, p := <span class="keyword">range</span> oldPools &#123;  </span><br><span class="line">		p.victim = <span class="literal">nil</span>  </span><br><span class="line">		p.victimSize = <span class="number">0</span>  </span><br><span class="line">	&#125;  </span><br><span class="line">  </span><br><span class="line">  </span><br><span class="line">	<span class="keyword">for</span> _, p := <span class="keyword">range</span> allPools &#123;  </span><br><span class="line">		p.victim = p.local  </span><br><span class="line">		p.victimSize = p.localSize  </span><br><span class="line">		p.local = <span class="literal">nil</span>  </span><br><span class="line">		p.localSize = <span class="number">0</span>  </span><br><span class="line">	&#125;  </span><br><span class="line">	oldPools, allPools = allPools, <span class="literal">nil</span>  </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<p>整体看起来，比较简洁。主要是将 local 和 victim 作交换，这样也就不致于让 GC 把所有的 Pool 都清空了，有 victim 在“兜底”。</p>
<ol>
<li>初始状态下，oldPools 和 allPools 均为 nil。</li>
<li>第 1 次调用 Get，由于 p.local 为 nil，将会在 pinSlow 中创建 p.local，然后将 p 放入 allPools，此时 allPools 长度为 1，oldPools 为 nil。</li>
<li>对象使用完毕，第 1 次调用 Put 放回对象。</li>
<li>第 1 次GC STW 阶段，allPools 中所有 p.local 将值赋值给 victim 并置为 nil。allPools 赋值给 oldPools，最后 allPools 为 nil，oldPools 长度为 1。</li>
<li>第 2 次调用 Get，由于 p.local 为 nil，此时会从 p.victim 里面尝试取对象。</li>
<li>对象使用完毕，第 2 次调用 Put 放回对象，但由于 p.local 为 nil，重新创建 p.local，并将对象放回，此时 allPools 长度为 1，oldPools 长度为 1。</li>
<li>第 2 次 GC STW 阶段，oldPools 中所有 p.victim 置 nil，前一次的 cache 在本次 GC 时被回收，allPools 所有 p.local 将值赋值给 victim 并置为nil，最后 allPools 为 nil，oldPools 长度为 1。<br>简单来说就是清理时，先清理 oldPools 的 local.victim,然后把 allPools 中的 local 赋值给 victim，最后再把 allPools 赋值给 oldPools，把 allPools 置空。<blockquote>
<p>GC 时只会清理 oldPools，allPools 只会先把数据转移到 victim，然后把 allPools 变成 oldPools，如果从 oldPools 中读取出来的数据进行 Put 也会直接放到 allPools 中，相当于要两次 GC 都没有被访问到并且Put回来才会被移除。</p>
</blockquote>
</li>
</ol>
<h2 id="3-小结"><a href="#3-小结" class="headerlink" title="3 小结"></a>3 小结</h2><ul>
<li><p>1）关键思想是对象的复用，避免重复创建、销毁。将暂时不用的对象缓存起来，待下次需要的时候直接使用，不用再次经过内存分配，复用对象的内存，减轻 GC 的压力。</p>
</li>
<li><p>2）<code>sync.Pool</code> 是协程安全的，使用起来非常方便。设置好 New 函数后，调用 Get 获取，调用 Put 归还对象。</p>
</li>
<li><p>3）不要对 Get 得到的对象有任何假设，更好的做法是归还对象时，将对象“清空”。</p>
</li>
<li><p>4）Pool 里对象的生命周期受 GC 影响，不适合于做连接池，因为连接池需要自己管理对象的生命周期。</p>
</li>
</ul>
<p>一些设计思想或者相关知识点：</p>
<ul>
<li><p>lock free：无锁编程是很多编程语言里逃离不了的话题。<code>sync.Pool</code>的无锁是在<code>poolDequeue</code>和<code>poolChain</code>层面实现的。</p>
</li>
<li><p>原子操作代替锁：<code>poolDequeue</code>对一些关键变量采用了CAS操作，比如<code>poolDequeue.headTail</code>，既可完整保证并发又能降低相比锁而言的开销。</p>
</li>
<li><p>cacheline false sharing 问题</p>
</li>
<li><p>noCopy 禁止复制</p>
</li>
<li><p>分段锁，降低锁粒度</p>
</li>
<li><p>victim cache</p>
</li>
<li><p>常见优化手段：复用</p>
</li>
</ul>
<h2 id="4-参考"><a href="#4-参考" class="headerlink" title="4 参考"></a>4 参考</h2><p><code>https://golang.org/src/sync/pool.go</code></p>
<p><code>https://en.wikipedia.org/wiki/False_sharing</code></p>
<p><code>https://en.wikipedia.org/wiki/Victim_cache</code></p>
<p><code>https://zhuanlan.zhihu.com/p/110140126</code></p>
<p><code>https://medium.com/swlh/go-the-idea-behind-sync-pool-32da5089df72</code></p>
<p><code>https://zhuanlan.zhihu.com/p/133638023</code></p>
<p><code>https://www.jianshu.com/p/dc4b5562aad2</code></p>
<p><code>https://colobu.com/2019/10/08/how-is-sync-Pool-improved-in-Go-1-13/</code></p>
<p>[Github]  <a target="_blank" rel="noopener" href="https://github.com/lixd/i-go/blob/master/a-tutorials/lib/sync_pool/main.go">https://github.com/lixd/i-go/blob/master/a-tutorials/lib/sync_pool/main.go</a> </p>
<p>[pool-structure]  <a target="_blank" rel="noopener" href="https://github.com/lixd/blog/raw/master/images/golang/lib/sync-pool/pool-structure.png">https://github.com/lixd/blog/raw/master/images/golang/lib/sync-pool/pool-structure.png</a></p>

    
    
  </div>

  

  

</article>
  
  <article class="post">
  <header class="post-header">
    <h1 class="post-title">
      
      <a class="post-link" href="/2023/08/22/Basic/RPC/"></a>
      
    </h1>

    <div class="post-meta">
      <span class="post-time">
        2023-08-22
      </span>
      
      
      
    </div>
  </header>

  

  <div class="post-content">
    
    
    

    
    <pre><code>RPC（Remote Procedure Call）远程过程调用，是一种通过网络从远程计算机程序上请求服务，而不需要了解底层网络技术的协议
</code></pre><h2 id="RPC机制和实现过程"><a href="#RPC机制和实现过程" class="headerlink" title="RPC机制和实现过程"></a>RPC机制和实现过程</h2><ul>
<li>RPC 是远程过程调用的方式之一，涉及调用方和被调用方两个进程的交互。因为 RPC 提供类似于本地方法调用的形式，所以对于调用方来说，调用 RPC 方法和调用本地方法并没有明显区别。<br>　　1. 定义 IDL 文件，生成 stub 桩文件，实现函数映射<br>　　2. 调用者（客户端Client）以本地调用的方式发起调用；<br>　　3. 序列化：Client stub（客户端存根）收到调用后，负责将被调用的方法名、参数等打包编码成特定格式的能进行网络传输的消息体；<br>　　4. Client stub将消息体通过网络发送给服务端；<br>　　5. Server stub（服务端存根）收到通过网络接收到消息后按照相应格式进行拆包解码，获取方法名和参数；<br>　　6. Server stub根据方法名和参数进行本地调用；<br>　　7. 被调用者（Server）本地调用执行后将结果返回给server stub；<br>　　8. Server stub将返回值打包编码成消息，并通过网络发送给客户端；<br>　　9. Client stub收到消息后，进行拆包解码，返回给Client；<br>　　10. Client得到本次RPC调用的最终结果。</li>
<li><strong>消息协议</strong>：以何种方式打包编码和拆包解码，有基于纯文本的 XML 和 JSON、二进制编码的Protobuf和Hessian等，或者自定义私有协议</li>
<li><strong>传输控制</strong>：主要有HTTP传输和TCP传输，鉴于TCP传输的可靠性，RPC的传输一般使用TCP作为传输协议</li>
<li><strong>RPC和HTTP区别</strong>  <ul>
<li>RPC 和 HTTP都是微服务间通信较为常用的方案之一，其实RPC 和 HTTP 并不完全是同一个层次的概念，它们之间还是有所区别的。  <ul>
<li>RPC 是远程过程调用，其调用协议通常包括序列化协议和传输协议。序列化协议有基于纯文本的 XML 和 JSON、二进制编码的Protobuf和Hessian。传输协议是指其底层网络传输所使用的协议，比如 TCP、HTTP。  </li>
<li>可以看出HTTP是RPC的传输协议的一个可选方案，比如说 gRPC 的网络传输协议就是 HTTP。HTTP 既可以和 RPC 一样作为服务间通信的解决方案，也可以作为 RPC 中通信层的传输协议（此时与之对比的是 TCP 协议）。</li>
</ul>
</li>
</ul>
</li>
</ul>

    
    
  </div>

  

  

</article>
  
  <article class="post">
  <header class="post-header">
    <h1 class="post-title">
      
      <a class="post-link" href="/2022/09/12/Golang/2%20%E5%86%85%E5%AD%98%E7%AE%A1%E7%90%86/%E5%9E%83%E5%9C%BE%E5%9B%9E%E6%94%B6/">[Go] 垃圾回收</a>
      
    </h1>

    <div class="post-meta">
      <span class="post-time">
        2022-09-12
      </span>
      
      
      <span class="post-category">
        
        <a href="/categories/Golang/">Golang</a>
        
        <a href="/categories/Golang/%E5%86%85%E5%AD%98%E7%AE%A1%E7%90%86/">内存管理</a>
        
      </span>
      
      
    </div>
  </header>

  

  <div class="post-content">
    
    
    
    
    

    
    <blockquote>
<p>垃圾回收（Garbage Collection，简称 GC）是一种内存管理策略，由垃圾收集器以类似守护协程的方式在后台运作，按照既定的策略为用户回收那些不再被使用的对象，释放对应的内存空间.</p>
</blockquote>
    <div class="read-more">
      <a href="/2022/09/12/Golang/2%20%E5%86%85%E5%AD%98%E7%AE%A1%E7%90%86/%E5%9E%83%E5%9C%BE%E5%9B%9E%E6%94%B6/" class="read-more-link">Read more..</a>
    </div>
    
    
  </div>

  

  

</article>
  
  <article class="post">
  <header class="post-header">
    <h1 class="post-title">
      
      <a class="post-link" href="/2022/09/08/Golang/2%20%E5%86%85%E5%AD%98%E7%AE%A1%E7%90%86/%E5%86%85%E5%AD%98%E5%88%86%E9%85%8D/">[Go] 内存分配</a>
      
    </h1>

    <div class="post-meta">
      <span class="post-time">
        2022-09-08
      </span>
      
      
      <span class="post-category">
        
        <a href="/categories/Golang/">Golang</a>
        
        <a href="/categories/Golang/%E5%86%85%E5%AD%98%E7%AE%A1%E7%90%86/">内存管理</a>
        
      </span>
      
      
    </div>
  </header>

  

  <div class="post-content">
    
    
    
    
    

    
    <blockquote>
<p>Golang的内存管理是基于TCMalloc的核心思想来构建的，内存管理本质上是一个<strong>内存池和多级对象管理</strong></p>
</blockquote>
    <div class="read-more">
      <a href="/2022/09/08/Golang/2%20%E5%86%85%E5%AD%98%E7%AE%A1%E7%90%86/%E5%86%85%E5%AD%98%E5%88%86%E9%85%8D/" class="read-more-link">Read more..</a>
    </div>
    
    
  </div>

  

  

</article>
  
    
  <nav class="pagination">  
      
      <a class="prev" href="/page/2/">  
        <i class="iconfont icon-left"></i>  
        <span class="prev-text">Prev</span>  
      </a>  
      
      
      <a class="next" href="/page/4/">  
        <span class="next-text">Next</span>  
        <i class="iconfont icon-right"></i>  
      </a>  
      
  </nav>  
  

  
</section>
        </div>
      </div>
    </main>
    <footer id="footer" class="footer">
      <!-- Social Links -->

<div class="social-links">
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  

  
  <a href="/atom.xml" class="iconfont icon-rss" title="rss"></a>
  
</div>



<div class="copyright">
  <span class="power-by">
    Powered by <a class="hexo-link" target="_blank" rel="noopener" href="https://hexo.io/">Hexo</a>
  </span>
  <span class="division">|</span>
  <span class="theme-info">
    Theme -
    <a class="theme-link" target="_blank" rel="noopener" href="https://github.com/ahonn/hexo-theme-even">Even</a>
  </span>
  <span class="division">|</span>
  <span class="hosting-info">
    footer.hosting
  </span>

  <span class="copyright-year">
    <span>
      
      &copy;
      
      2019 - 2025      
    </span>

    <span class="heart">
      <i class="iconfont icon-heart"></i>
    </span>

    <span class="author">draco</span>
  </span>

</div>
    </footer>
    <div class="back-to-top" id="back-to-top"> <i class="iconfont icon-up"></i> </div>
  </div>
  







<script type="text/javascript" src="/lib/jquery/jquery.min.js"></script>



<script type="text/javascript" src="/lib/slideout/slideout.js"></script>



<script type="text/javascript" src="/lib/fancybox/jquery.fancybox.pack.js"></script>



  <script type="text/javascript" src="/js/src/even.js?v=3.0.0"></script>
</body>

</html>