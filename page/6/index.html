<!DOCTYPE html>
<html lang="en">

<head>
  <!-- Website mata -->
<meta charset="UTF-8" />
<meta http-equiv="X-UA-Compatible" content="IE=edge" />
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1" />

<!-- Disable transformation -->
<meta http-equiv="Cache-Control" content="no-transform" />
<meta http-equiv="Cache-Control" content="no-siteapp" />

<meta name="theme-color" content="#f8f5ec" />
<meta name="msapplication-navbutton-color" content="#f8f5ec">
<meta name="apple-mobile-web-app-capable" content="yes">
<meta name="apple-mobile-web-app-status-bar-style" content="#f8f5ec">

<!-- Website description -->


<!-- Website keywords -->




<!-- Website rss -->

<link rel="alternate" href="/atom.xml" title="Draco's Blog" type="application/atom+xml">


<!-- Website favicon -->

<link rel="shortcut icon" type="image/x-icon" href="/favicon.ico?v=3.0.0" />


<!-- Canonical, good for google search engine -->
<link rel="canonical" href="https://stardustorz.github.io/page/6/" />

<!-- Fancybox styling -->

<link rel="stylesheet" type="text/css" href="/lib/fancybox/jquery.fancybox.css" />


<!-- MathJax (LaTeX) support -->


<!-- Theme styling -->
<link rel="stylesheet" type="text/css" href="/css/style.css?v=3.0.0" />

<!-- Analytics and push -->



  



<!-- LeanCloud Counter -->


<script>
  window.config = {"leancloud":{"app_id":null,"app_key":null,"server_url":null,"cdn":null},"toc":true,"fancybox":true,"latex":false};
</script>
  
  <title>Draco&#39;s Blog</title>

<meta name="generator" content="Hexo 6.3.0"></head>

<body>
  <div class="scrollPercentage"></div>
  <div id="mobile-navbar" class="mobile-navbar">
  <div class="mobile-header-logo">
    <a href="/." class="logo">Draco&#39;s Blog</a>
  </div>
  <div class="mobile-navbar-icon">
    <span></span>
    <span></span>
    <span></span>
  </div>
</div>

<nav id="mobile-menu" class="mobile-menu slideout-menu">
  <ul class="mobile-menu-list">
    
    <a href="/">
      <li class="mobile-menu-item">
        
        
        Home              </li>
    </a>
    
    <a href="/archives/">
      <li class="mobile-menu-item">
        
        
        Archives              </li>
    </a>
    
    <a href="/tags/">
      <li class="mobile-menu-item">
        
        
        Tags              </li>
    </a>
    
    <a href="/categories/">
      <li class="mobile-menu-item">
        
        
        Categories              </li>
    </a>
    
    <a href="/links/">
      <li class="mobile-menu-item">
        
        
        Links              </li>
    </a>
    
    <a href="/about/">
      <li class="mobile-menu-item">
        
        
        About              </li>
    </a>
    
  </ul>
</nav>
  <div class="container" id="mobile-panel">
    <header id="header" class="header">
      <div class="logo-wrapper">  
  <a href="/." class="logo">Draco's Blog</a>  
</div>  
  
<nav class="site-navbar">  
    
    <ul id="menu" class="menu">  
        
        <li class="menu-item">  
          <a class="menu-item-link" href="/">  
              
              
              Home  
              
          </a>  
        </li>  
        
        <li class="menu-item">  
          <a class="menu-item-link" href="/archives/">  
              
              
              Archives  
              
          </a>  
        </li>  
        
        <li class="menu-item">  
          <a class="menu-item-link" href="/tags/">  
              
              
              Tags  
              
          </a>  
        </li>  
        
        <li class="menu-item">  
          <a class="menu-item-link" href="/categories/">  
              
              
              Categories  
              
          </a>  
        </li>  
        
        <li class="menu-item">  
          <a class="menu-item-link" href="/links/">  
              
              
              Links  
              
          </a>  
        </li>  
        
        <li class="menu-item">  
          <a class="menu-item-link" href="/about/">  
              
              
              About  
              
          </a>  
        </li>  
        
    </ul>  
    
</nav>  

    </header>
    <main id="main" class="main">
      <div class="content-wrapper">
        <div id="content" class="content">
          <section id="posts" class="posts">
  
  
  
  <article class="post">
  <header class="post-header">
    <h1 class="post-title">
      
      <a class="post-link" href="/2025/01/19/Golang/4%20%E5%85%B6%E4%BB%96/%E5%86%85%E5%AD%98%E5%AF%B9%E9%BD%90/">[Go] Memory Align</a>
      
    </h1>

    <div class="post-meta">
      <span class="post-time">
        2025-01-19
      </span>
      
      
      
    </div>
  </header>

  

  <div class="post-content">
    
    
    
    
    

    
    <blockquote>
<p>内存对齐主要就是为了迎合内存设计, 可以提升内存访问效率</p>
</blockquote>
    <div class="read-more">
      <a href="/2025/01/19/Golang/4%20%E5%85%B6%E4%BB%96/%E5%86%85%E5%AD%98%E5%AF%B9%E9%BD%90/" class="read-more-link">Read more..</a>
    </div>
    
    
  </div>

  

  

</article>
  
  <article class="post">
  <header class="post-header">
    <h1 class="post-title">
      
      <a class="post-link" href="/2025/01/19/Golang/3%20%E4%BB%A3%E7%A0%81%E8%A7%84%E8%8C%83/Golang%20%E5%B7%A5%E7%A8%8B%E5%AE%9E%E8%B7%B5/">[Go] Best Practice</a>
      
    </h1>

    <div class="post-meta">
      <span class="post-time">
        2025-01-19
      </span>
      
      
      
    </div>
  </header>

  

  <div class="post-content">
    
    
    
    
    

    
    <blockquote>
<p>如何写优雅的 Go 语言代码</p>
</blockquote>
    <div class="read-more">
      <a href="/2025/01/19/Golang/3%20%E4%BB%A3%E7%A0%81%E8%A7%84%E8%8C%83/Golang%20%E5%B7%A5%E7%A8%8B%E5%AE%9E%E8%B7%B5/" class="read-more-link">Read more..</a>
    </div>
    
    
  </div>

  

  

</article>
  
  <article class="post">
  <header class="post-header">
    <h1 class="post-title">
      
      <a class="post-link" href="/2025/01/19/Golang/3%20%E4%BB%A3%E7%A0%81%E8%A7%84%E8%8C%83/Golang%20%E4%BB%A3%E7%A0%81%E8%A7%84%E8%8C%83/">[Go] Code Style</a>
      
    </h1>

    <div class="post-meta">
      <span class="post-time">
        2025-01-19
      </span>
      
      
      
    </div>
  </header>

  

  <div class="post-content">
    
    
    
    
    

    
    <blockquote>
<p>主要记录了一些容易犯错的地方，具体规范参考如下:</p>
</blockquote>
    <div class="read-more">
      <a href="/2025/01/19/Golang/3%20%E4%BB%A3%E7%A0%81%E8%A7%84%E8%8C%83/Golang%20%E4%BB%A3%E7%A0%81%E8%A7%84%E8%8C%83/" class="read-more-link">Read more..</a>
    </div>
    
    
  </div>

  

  

</article>
  
  <article class="post">
  <header class="post-header">
    <h1 class="post-title">
      
      <a class="post-link" href="/2025/01/16/Golang/4%20%E5%85%B6%E4%BB%96/Concatenate%20Strings/">[Go] Concatenate Strings</a>
      
    </h1>

    <div class="post-meta">
      <span class="post-time">
        2025-01-16
      </span>
      
      
      
    </div>
  </header>

  

  <div class="post-content">
    
    
    
    
    

    
    <blockquote>
<p>How to Efficiently Concatenate Strings in Go</p>
</blockquote>
    <div class="read-more">
      <a href="/2025/01/16/Golang/4%20%E5%85%B6%E4%BB%96/Concatenate%20Strings/" class="read-more-link">Read more..</a>
    </div>
    
    
  </div>

  

  

</article>
  
  <article class="post">
  <header class="post-header">
    <h1 class="post-title">
      
      <a class="post-link" href="/2025/01/16/Golang/4%20%E5%85%B6%E4%BB%96/%E6%9E%84%E5%BB%BADocker%E9%95%9C%E5%83%8F/">[Go] Build Docker Image</a>
      
    </h1>

    <div class="post-meta">
      <span class="post-time">
        2025-01-16
      </span>
      
      
      
    </div>
  </header>

  

  <div class="post-content">
    
    
    
    
    

    
    <blockquote>
<p>Golang应用通过Dockerfile构建Docker镜像</p>
</blockquote>
    <div class="read-more">
      <a href="/2025/01/16/Golang/4%20%E5%85%B6%E4%BB%96/%E6%9E%84%E5%BB%BADocker%E9%95%9C%E5%83%8F/" class="read-more-link">Read more..</a>
    </div>
    
    
  </div>

  

  

</article>
  
  <article class="post">
  <header class="post-header">
    <h1 class="post-title">
      
      <a class="post-link" href="/2025/01/15/Golang/4%20%E5%85%B6%E4%BB%96/http.Client%E8%AF%B7%E6%B1%82%E7%A8%8B%E5%BA%8F%E9%81%87%E5%88%B0%20Connection%20Reset%20by%20Peer%20%E6%88%96%20EOF%20%E9%97%AE%E9%A2%98/">[Go] Connection Reset by Peer or EOF</a>
      
    </h1>

    <div class="post-meta">
      <span class="post-time">
        2025-01-15
      </span>
      
      
      
    </div>
  </header>

  

  <div class="post-content">
    
    
    
    
    

    
    <blockquote>
<p>Golang http.Client请求程序遇到Connection Reset by peer 或 EOF 问题</p>
</blockquote>
    <div class="read-more">
      <a href="/2025/01/15/Golang/4%20%E5%85%B6%E4%BB%96/http.Client%E8%AF%B7%E6%B1%82%E7%A8%8B%E5%BA%8F%E9%81%87%E5%88%B0%20Connection%20Reset%20by%20Peer%20%E6%88%96%20EOF%20%E9%97%AE%E9%A2%98/" class="read-more-link">Read more..</a>
    </div>
    
    
  </div>

  

  

</article>
  
  <article class="post">
  <header class="post-header">
    <h1 class="post-title">
      
      <a class="post-link" href="/2025/01/13/Golang/4%20%E5%85%B6%E4%BB%96/WorkerPool/">[Go] WorkerPool</a>
      
    </h1>

    <div class="post-meta">
      <span class="post-time">
        2025-01-13
      </span>
      
      
      
    </div>
  </header>

  

  <div class="post-content">
    
    
    
    
    

    
    <blockquote>
<p>Golang实现一个工作池处理并发任务</p>
</blockquote>
    <div class="read-more">
      <a href="/2025/01/13/Golang/4%20%E5%85%B6%E4%BB%96/WorkerPool/" class="read-more-link">Read more..</a>
    </div>
    
    
  </div>

  

  

</article>
  
  <article class="post">
  <header class="post-header">
    <h1 class="post-title">
      
      <a class="post-link" href="/2025/01/13/Golang/4%20%E5%85%B6%E4%BB%96/Channel%E5%AE%9E%E7%8E%B0%E4%BA%92%E6%96%A5%E9%94%81/">[Go] Channel实现互斥锁</a>
      
    </h1>

    <div class="post-meta">
      <span class="post-time">
        2025-01-13
      </span>
      
      
      
    </div>
  </header>

  

  <div class="post-content">
    
    
    
    
    

    
    <blockquote>
<p>使用长度为1的有缓冲channel实现互斥锁</p>
</blockquote>
    <div class="read-more">
      <a href="/2025/01/13/Golang/4%20%E5%85%B6%E4%BB%96/Channel%E5%AE%9E%E7%8E%B0%E4%BA%92%E6%96%A5%E9%94%81/" class="read-more-link">Read more..</a>
    </div>
    
    
  </div>

  

  

</article>
  
  <article class="post">
  <header class="post-header">
    <h1 class="post-title">
      
      <a class="post-link" href="/2023/09/10/Framework/MySQL/">[Framework] MySQL</a>
      
    </h1>

    <div class="post-meta">
      <span class="post-time">
        2023-09-10
      </span>
      
      
      
    </div>
  </header>

  

  <div class="post-content">
    
    
    

    
    <span id="more"></span>
<h2 id="1-架构与简介"><a href="#1-架构与简介" class="headerlink" title="1 架构与简介"></a>1 架构与简介</h2><h3 id="1-1-MySQL-架构"><a href="#1-1-MySQL-架构" class="headerlink" title="1.1 MySQL 架构"></a>1.1 MySQL 架构</h3><ul>
<li><em>Server 层</em>：建立连接、分析和执行 SQL；主要包括连接器、查询缓存、分析器、优化器、执行器等，所有跨存储引擎的功能都在这一层实现，比如存储过程、触发器、视图，函数等，还有一个通用的日志模块 binglog 日志模块。</li>
<li><em>存储引擎层</em>：主要负责数据的存储和读取，采用可以替换的插件式架构，支持 InnoDB、MyISAM、Memory 等多个存储引擎，其中 InnoDB 引擎有自有的日志模块 redolog 模块。<strong>现在最常用的存储引擎是 InnoDB，它从 MySQL 5.5.5 版本开始就被当做默认存储引擎了。</strong></li>
</ul>
<h3 id="1-2-SQL-语句执行过程"><a href="#1-2-SQL-语句执行过程" class="headerlink" title="1.2 SQL 语句执行过程"></a>1.2 SQL 语句执行过程</h3><blockquote>
<p>MySQL 执行一条 select 查询语句，在 MySQL 中期间发生了什么？</p>
<ul>
<li><em>连接器</em>：TCP 三次握手连接</li>
<li><em>查询缓存</em>：先去查询缓存（ Query Cache ）里查找缓存数据</li>
<li><em>解析 SQL</em>：解析器进行词法分析和语法分析</li>
<li><em>执行 SQL</em>：<ul>
<li><code>预处理器</code>：查询表和字段是否存在</li>
<li><code>优化器</code>：确定 SQL 语句执行方案，选择最高效的索引<ul>
<li>explain：select_type 查询类型； type 连接方式；key 用到的索引；rows 扫描出的行数</li>
</ul>
</li>
<li><code>执行器</code>：<ul>
<li>主键索引查询：选择符合的记录</li>
<li>全表扫描</li>
<li><strong><em>索引下推</em></strong>：<code>减少二级索引在查询时的回表操作</code>，将查询条件下推到存储引擎层面进行判断，而不是将数据加载到内存中由应用层进行过滤</li>
<li>exp： <code>where age &gt; 20 and reward = 100000</code>, 其中 age 可以用到联合索引，通过下推后，直接在存储引擎中过滤出<code>reward = 100000</code>的记录再去回表；<h3 id="1-3-记录存储"><a href="#1-3-记录存储" class="headerlink" title="1.3 记录存储"></a>1.3 记录存储</h3></li>
</ul>
</li>
</ul>
</li>
<li>数据存放：表结构（t_order.frm），表数据（t_order.ibd）</li>
<li>表空间文件结构：段（segment）、区（extent）、页（page，16KB）、行（row）</li>
<li><code>null 存储</code>：Compact 行格式中会用「NULL值列表」来标记值为 NULL 的列，NULL 值并不会存储在行格式中的真实数据部分</li>
<li>页的大小和结构： 16KB 文件头 页头 最小和最大记录 用户记录 空闲空间 页目录 文件尾</li>
<li>innodb的行格式：<img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/mysql/row_format/COMPACT.drawio.png" alt=""><pre><code>  1. 变长字段的真实数据占用的字节数会按照列的顺序**逆序存放**    **使得位置靠前的记录的真实数据和数据对应的字段长度信息可以同时在一个 CPU Cache Line 中，这样就可以提高 CPU Cache 的命中率**。
  2. trx_id   事务id；roll_pointer  记录上一个版本的指针
</code></pre></li>
</ul>
</blockquote>
<h2 id="2-索引"><a href="#2-索引" class="headerlink" title="2 索引"></a>2 索引</h2><h3 id="2-1-索引简介与-B-树"><a href="#2-1-索引简介与-B-树" class="headerlink" title="2.1 索引简介与 B+树"></a>2.1 索引简介与 B+树</h3><h4 id="2-1-1-什么是索引？"><a href="#2-1-1-什么是索引？" class="headerlink" title="2.1.1 什么是索引？"></a>2.1.1 什么是索引？</h4><ul>
<li>帮助存储引擎快速获取数据的一种数据结构</li>
<li>缺点：本身会占据物理空间；创建索引和维护索引要耗费时间；降低表的增删改的效率</li>
<li>使用场合：字段有唯一性限制，表数据多，更新不频繁<h4 id="2-1-2-B-树"><a href="#2-1-2-B-树" class="headerlink" title="2.1.2 B+树"></a>2.1.2 B+树</h4><blockquote>
<p>主键索引和二级索引默认使用的是 B+Tree 索引</p>
</blockquote>
</li>
<li><em>什么是 B+树？</em><ul>
<li>B 树：多叉树，左小右大，每个节点都包含索引和数据</li>
<li><em>B+树</em>:就是 B 树的升级<ul>
<li>叶子节点（最底部的节点）才会存放实际数据（索引+记录），非叶子节点只会存放索引</li>
<li>所有索引都会在叶子节点出现，叶子节点之间构成一个<code>有序链表</code></li>
<li>非叶子节点中有多少个子节点，就有多少个索引</li>
<li>B+ 树点节点内容是数据页，数据页里存放了用户的记录以及各种信息，每个数据页默认大小是 16 KB</li>
</ul>
</li>
</ul>
</li>
<li><em>B+树优点</em>：<ul>
<li>B+树的非叶子节点可以存放更多的索引，出度更大</li>
<li>范围查询效率更高</li>
</ul>
</li>
<li>单表最大值：一般三层就可以存放两千万行数据，超过可能增加层级；内存放不下索引<h3 id="2-2-索引分类"><a href="#2-2-索引分类" class="headerlink" title="2.2 索引分类"></a>2.2 索引分类</h3></li>
<li>按数据结构： B+Tree 索引、HASH 索引、Full-Text 索引</li>
<li>按物理存储： <strong>聚簇索引（主键索引）、二级索引（辅助索引）</strong> 叶子节点存放的是主键值，还要回表</li>
<li>按字段特性： <strong>主键索引、唯一索引、普通索引、前缀索引</strong></li>
<li>按字段个数： <strong>单列索引、联合索引</strong>   <ul>
<li>最左匹配原则：按照最左优先的方式进行索引的匹配</li>
<li>exp：（a，b，c）的索引会先按 a 排序，在 a 相同的情况下按 b 排序，再按 c 排序，因此<code>b 和 c 是全局无序，局部相对有序的</code>，所以 <code>where b=2 and c=3；</code> 无法利用索引</li>
<li>where a &gt; 1 and b = 2  只有 a 能利用联合索引<h3 id="2-3-索引优化"><a href="#2-3-索引优化" class="headerlink" title="2.3 索引优化"></a>2.3 索引优化</h3></li>
</ul>
</li>
</ul>
<ol>
<li><code>前缀索引</code>优化： 可以减小索引项的大小，但是不能成为覆盖索引</li>
<li><code>覆盖索引</code>优化： 直接从二级索引获取数据，避免回表</li>
<li>主键索引<code>自增</code>：插入效率高；避免造成页分裂；主键字段的长度不要太大，减小二级索引规模</li>
<li>索引设置 NOT NULL：方便优化器选择<h3 id="2-4-索引失效"><a href="#2-4-索引失效" class="headerlink" title="2.4 索引失效"></a>2.4 索引失效</h3></li>
</ol>
<ul>
<li>使用左或者左右模糊匹配，like %xx</li>
<li>在查询条件中对索引列做了计算、函数、类型转换操作</li>
<li>联合索引未遵循最左匹配原则</li>
<li>WHERE 子句中， OR 前的条件列是索引列， OR 后不是，那么索引会失效<h2 id="3-事务"><a href="#3-事务" class="headerlink" title="3 事务"></a>3 事务</h2><h3 id="3-1-事务的特性-ACID"><a href="#3-1-事务的特性-ACID" class="headerlink" title="3.1 事务的特性 ACID"></a>3.1 事务的特性 ACID</h3></li>
<li><em><strong>原子性（Atomicity）</strong></em>：一个事务中的所有操作，要么全部完成，要么全部不完成，不会结束在中间某个环节，而且事务在执行过程中发生错误，会被回滚到事务开始前的状态； <code>由 undo log（回滚日志保证）</code></li>
<li><em><strong>一致性（Consistency）</strong></em>：是指事务操作前和操作后，数据满足完整性约束，数据库保持一致性状态  <code>由持久性+原子性+隔离性 共同保证</code></li>
<li><em><strong>隔离性（Isolation）</strong></em>：防止多个事务并发执行时由于交叉执行而导致数据的不一致   <code>MVCC（多版本并发控制） 或锁机制</code></li>
<li><em><strong>持久性（Durability）</strong></em>：事务处理结束后，对数据的修改就是永久的，即便系统故障也不会丢失。     <code>redo log （重做日志）</code><h3 id="3-2-并行事务的问题"><a href="#3-2-并行事务的问题" class="headerlink" title="3.2 并行事务的问题"></a>3.2 并行事务的问题</h3></li>
<li><strong>脏读</strong>： 一个事务「读到」了另一个「<strong>未提交事务修改过的数据</strong>」</li>
<li><strong>不可重复读</strong>：在一个事务内多次读取同一个数据，前后两次读到的<strong>数据</strong>不一样</li>
<li><strong>幻读</strong>：在一个事务内多次查询某个符合查询条件的「记录数量」，前后两次查询到的<strong>记录数量</strong>不一样<h3 id="3-3-事务的隔离级别"><a href="#3-3-事务的隔离级别" class="headerlink" title="3.3 事务的隔离级别"></a>3.3 事务的隔离级别</h3></li>
<li><strong>读未提交（<em>read uncommitted</em>）</strong>，指一个事务还没提交时，它做的变更就能被其他事务看到； <strong>会脏读</strong></li>
<li><strong>读提交（<em>read committed</em>）</strong>，指一个事务提交之后，它做的变更才能被其他事务看到； <strong>会不可重复读</strong></li>
<li><strong>可重复读（<em>repeatable read</em>）</strong>，指一个事务执行过程中看到的数据，一直跟这个事务启动时看到的数据是一致的，<strong>MySQL InnoDB 引擎的默认隔离级别</strong>； <strong>会幻读</strong></li>
<li><strong>串行化（<em>serializable</em> ）</strong>；会对记录加上读写锁，在多个事务对这条记录进行读写操作时，如果发生了读写冲突的时候，后访问的事务必须等前一个事务执行完成，才能继续执行；  都不会，但是影响性能</li>
<li><em>默认的隔离级别</em>：可重复读，用以下方法解决幻读<ul>
<li>针对<strong>快照读</strong>（普通 select 语句），是<strong>通过 MVCC 方式解决了幻读</strong></li>
<li>针对<strong>当前读</strong>（select … for update 等语句），是<strong>通过 next-key lock（记录锁+间隙锁）方式解决了幻读</strong></li>
</ul>
</li>
<li>幻读完全解决了吗？ 没有<ol>
<li>对于快照读，当事务 A 更新了一条事务 B 插入的记录，那么事务 A 前后两次查询的记录条目就不一样了，就会产生幻读</li>
<li>对于当前读，如果事务开启后，并没有执行当前读，而是先快照读，然后这期间如果其他事务插入了一条记录，那么事务后续使用当前读进行查询的时候，就会发现两次查询的记录条目就不一样了，所以就发生幻读。</li>
<li>在开启事务之后，马上执行 select … for update 这类当前读的语句</li>
</ol>
</li>
</ul>
<h3 id="3-4-MVCC-与-ReadView"><a href="#3-4-MVCC-与-ReadView" class="headerlink" title="3.4 MVCC 与 ReadView"></a>3.4 MVCC 与 ReadView</h3><ul>
<li><em>MVCC 原理</em>？<ul>
<li>Multi-Version Concurrency Control 多版本并发控制</li>
<li>核心思想是为每个事务创建一个独立的数据库快照，每个事务在操作时都会基于事务 ID 来访问数据库的对应版本</li>
</ul>
</li>
<li><em>ReadView 的数据结构</em>？  四个字段和聚簇索引记录中的两个隐藏列<ul>
<li><code>m_ids</code> ：指的是在创建 Read View 时，当前数据库中「活跃事务」的<strong>事务 id 列表</strong>，注意是一个列表，<strong>“活跃事务”指的就是，启动了但还没提交的事务</strong>。</li>
<li><code>min_trx_id</code> ：指的是在创建 Read View 时，当前数据库中「活跃事务」中事务 <strong>id 最小的事务</strong>，也就是 m_ids 的最小值。</li>
<li><code>max_trx_id</code> ：这个并不是 m_ids 的最大值，而是<strong>创建 Read View 时当前数据库中应该给下一个事务的 id 值</strong>，也就是全局事务中最大的事务 id 值 + 1；</li>
<li><code>creator_trx_id</code> ：指的是<strong>创建该 Read View 的事务的事务 id</strong>。</li>
<li><code>trx_id</code>，当一个事务对某条聚簇索引记录进行改动时，就会<strong>把该事务的事务 id 记录在 trx_id 隐藏列里</strong>；</li>
<li><code>roll_pointer</code>，每次对某条聚簇索引记录进行改动时，都会把旧版本的记录写入到 undo 日志中，然后<strong>这个隐藏列是个指针，指向每一个旧版本记录</strong>，于是就可以通过它找到修改前的记录。</li>
</ul>
</li>
<li><em>可重复读实现</em>？<ul>
<li>启动事务时生成一个 Read View，然后整个事务期间都在用这个 Read View</li>
</ul>
</li>
<li><em>读提交实现</em>？<ul>
<li>在每次读取数据时，都会生成一个新的 Read View</li>
</ul>
</li>
</ul>
<h2 id="4-锁"><a href="#4-锁" class="headerlink" title="4 锁"></a>4 锁</h2><h3 id="4-1-MySQL-有哪些锁？"><a href="#4-1-MySQL-有哪些锁？" class="headerlink" title="4.1 MySQL 有哪些锁？"></a>4.1 MySQL 有哪些锁？</h3><h4 id="4-1-1-全局锁"><a href="#4-1-1-全局锁" class="headerlink" title="4.1.1 全局锁"></a>4.1.1 全局锁</h4><ul>
<li><em>启用</em>：flush tables with read lock    数据库处于只读状态</li>
<li><em>使用场景</em>：全库备份</li>
<li>如果数据库的引擎支持的事务支持<strong>可重复读的隔离级别</strong>，那么在备份数据库之前先开启事务，会先创建 Read View，然后整个事务执行期间都在用这个 Read View，而且由于 MVCC 的支持，备份期间业务依然可以对数据进行更新操作<h4 id="4-1-2-表级锁"><a href="#4-1-2-表级锁" class="headerlink" title="4.1.2 表级锁"></a>4.1.2 表级锁</h4></li>
<li><em>表锁</em>：颗粒度太大，性能较差</li>
<li><em>元数据锁</em>：防止其他线程变更表结构</li>
<li><em>意向锁</em>：<strong>快速判断表里是否有记录被加锁</strong><ul>
<li>当执行插入、更新、删除操作，需要先对表加上「意向独占锁」，然后对该记录加独占锁</li>
</ul>
</li>
<li><em>AUTO-INC 锁</em>：实现主键自增<ul>
<li>在插入数据时，会加一个表级别的 AUTO-INC 锁，插入语句完成后就释放<h4 id="4-1-3-行级锁"><a href="#4-1-3-行级锁" class="headerlink" title="4.1.3 行级锁"></a>4.1.3 行级锁</h4></li>
</ul>
</li>
<li><em>Record Lock</em>：记录锁，锁住一条记录；只有 S 型记录锁兼容</li>
<li><em>Gap Lock</em>：间隙锁，解决可重复读隔离级别下的幻读现象； 如（3，5）会锁住 4</li>
<li><em>Next-Key Lock</em>：Record Lock + Gap Lock 的组合，锁定一个范围，并且锁定记录本身；（3，5] 锁住 4，5</li>
<li><em>插入意向锁</em>：插入有间隙锁位置会发生<strong>阻塞</strong>，生成一个<strong>插入意向锁</strong>，表明有事务想在某个区间插入新记录，但是现在处于等待状态</li>
<li>Innodb 在扫描记录的时，都是针对索引项这个单位去加锁的， update 不带索引就是全表扫描，也就是表里的索引项都加锁，相当于锁了整张表<h4 id="4-1-4-死锁"><a href="#4-1-4-死锁" class="headerlink" title="4.1.4 死锁"></a>4.1.4 死锁</h4></li>
<li>两个事务即使生成的间隙锁的范围是一样的，也不会发生冲突，因为间隙锁目的是为了防止其他事务插入数据，因此间隙锁与间隙锁之间是相互兼容的。</li>
<li>在执行插入语句时，如果插入的记录在其他事务持有间隙锁范围内，插入语句就会被阻塞，因为插入语句在碰到间隙锁时，会生成一个插入意向锁，然后插入意向锁和间隙锁之间是互斥的关系。</li>
<li>如果两个事务分别向对方持有的间隙锁范围内插入一条记录，而插入操作为了获取到插入意向锁，都在等待对方事务的间隙锁释放，于是就造成了循环等待，满足了死锁的四个条件：<strong>互斥、占有且等待、不可强占用、循环等待</strong>，因此发生了死锁</li>
<li>事务 A 和事务 B 在执行完后 update 语句后都持有范围为<code>(20, 30）</code>的间隙锁，而接下来的插入操作为了获取到插入意向锁，都在等待对方事务的间隙锁释放，于是就造成了循环等待</li>
</ul>
<h2 id="5-日志"><a href="#5-日志" class="headerlink" title="5 日志"></a>5 日志</h2><h3 id="5-1-undo-log（回滚日志）"><a href="#5-1-undo-log（回滚日志）" class="headerlink" title="5.1 undo log（回滚日志）"></a>5.1 undo log（回滚日志）</h3><ul>
<li>innodb 存储引擎层生成的日志，实现了事务中的 <em><strong>原子性</strong></em> ，主要用于事务回滚和 MVCC</li>
<li>当 InnoDB 引擎对一条记录进行操作（修改、删除、新增）时，要把回滚时需要的信息都记录到 undo log 里</li>
<li>在<code>事务没提交之前</code>，MySQL 会先记录更新前的数据到 undo log 日志文件里面</li>
<li><em>ReadView + undo log 实现 MVCC</em>：undo log 为每条记录保存多份历史数据，MySQL 在执行快照读（普通 select 语句）的时候，会根据事务的 Read View 里的信息，顺着 undo log 的<code>版本链</code>找到满足其<code>可见性</code>的记录</li>
<li>持久化：buffer pool 中有 undo 页，对 undo 页的修改也都会记录到<code>redo log</code>，redo log 会每秒刷盘，提交事务时也会刷盘<h3 id="5-2-Buffer-Pool-缓冲池"><a href="#5-2-Buffer-Pool-缓冲池" class="headerlink" title="5.2 Buffer Pool  缓冲池"></a>5.2 Buffer Pool  缓冲池</h3></li>
<li><em>基于内存，提高数据库的读写性能</em></li>
<li><em>Buffer Pool 缓存什么</em>：「索引页」和「数据页」，还包括了 Undo 页，插入缓存、自适应哈希索引、锁信息等</li>
<li>修改记录先缓存 到 change buffer，找机会去写入磁盘<pre><code>  1. 唯一索引不会用 change buffer，因为对应数据页已经加载到内存了--判断唯一性
  2. 优点：减少磁盘访问次数；提高内存利用率
</code></pre></li>
<li><strong>缓页管理方式</strong><pre><code>  1. Free List （空闲页链表），管理空闲页；
  2. Flush List （脏页链表），管理脏页；
  3. LRU List，管理脏页+干净页，将最近且经常查询的数据缓存在其中，而不常查询的数据就淘汰出去；分为 young 和 old 两个区域，先插入 old，被访问进入 young，解决数据批量访问，和大量热数据淘汰的问题；
</code></pre><h3 id="5-3-redo-log（物理日志）"><a href="#5-3-redo-log（物理日志）" class="headerlink" title="5.3 redo log（物理日志）"></a>5.3 redo log（物理日志）</h3></li>
<li>作用：记录了某个数据页做了什么修改，在事务提交时，只要先将 redo log 持久化到磁盘即可；记录了事务「<strong>完成后</strong>」的数据状态，记录的是更新<strong>之后</strong>的值</li>
<li><strong><em>预写日志WAL</em></strong>：写操作并不是立刻写到磁盘上，而是先写日志，后面再等待时机写入磁盘</li>
<li><strong><em>crash-safe</em></strong>（崩溃恢复）：即使数据库发生异常重启，之前已提交的记录都不会丢失，保证了持久性</li>
<li><strong>优点</strong>：redo log 是追加操作，所以是顺序写，开销更小</li>
<li><strong>刷盘时机</strong>： 事务提交；每秒；关闭数据库； redo log buffer占用过半</li>
<li>redo log满了？阻塞，刷新脏页到磁盘，擦除 对应的 redo log 记录腾出空间</li>
</ul>
<h3 id="5-4-bin-log"><a href="#5-4-bin-log" class="headerlink" title="5.4 bin log"></a>5.4 bin log</h3><ul>
<li>undo 和 redo 都是Innodb 存储引擎生成的，binlog 是 Server 层生成的</li>
<li>使用对象：Server 层实现的日志，所有存储引擎都可以使用</li>
<li>文件格式： STATEMENT（默认格式，记录 SQL）、ROW（记录行数据）、 MIXED</li>
<li>写入方式：追加写，会覆盖以前的日志，保存的是全量的日志。</li>
<li>作用：用于<strong>主从复制，备份恢复</strong></li>
<li>binlog cache刷盘：事务提交，内存超了</li>
<li><strong><em>主从复制实现</em></strong><ol>
<li><em>主从复制流程</em><ol>
<li><strong>写入 Binlog</strong>：主库写 binlog 日志，提交事务，并更新本地存储数据。</li>
<li><strong>同步 Binlog</strong>：把 binlog 复制到所有从库上，每个从库把 binlog 写到暂存日志中。</li>
<li><strong>回放 Binlog</strong>：回放 binlog，并更新存储引擎中的数据。</li>
</ol>
</li>
<li><em>复制步骤</em><ol>
<li>主节点log dump线程：当从节点连接主节点时，主节点会创建一个log dump 线程，用于发送bin-log的内容。在读取bin-log中的操作时，此线程会对主节点上的bin-log加锁，当读取完成，甚至在发动给从节点之前，锁会被释放。</li>
<li>从节点I/O线程：当从节点上执行<code>start slave</code>命令之后，从节点会创建一个I/O线程用来连接主节点，请求主库中更新的bin-log。I/O线程接收到主节点bin log dump 进程发来的更新之后，保存在本地relay-log中。</li>
<li>从节点SQL线程：SQL线程负责读取relay log中的内容，解析成具体的操作并执行，最终保证主从数据的一致性。</li>
</ol>
</li>
<li><em>复制模型</em><ol>
<li>同步复制：性能差</li>
<li>异步复制：主库宕机数据会丢失</li>
<li>半同步复制：从库成功一个就行</li>
</ol>
</li>
<li><em>主从同步延迟</em><ol>
<li>从库只有一个sql Thread，主库写压力大，复制很可能延时；或者从库有大型 query 产生锁等待</li>
<li>解决：要求高就走主库；sleep 一下；判断一下主备延迟</li>
</ol>
</li>
</ol>
</li>
<li><strong><em>两阶段提交</em></strong>    防止<strong>redo log</strong>和<strong>binlog</strong>不一致，导致主从数据不一致；内部 XA 事务<ol>
<li><strong><em>prepare</em> 阶段</strong>：将 redo log 对应的事务状态设置为 prepare，然后将 redo log 刷新到硬盘；</li>
<li><strong><em>commit 阶段</em></strong>：将 binlog 刷新到磁盘，接着调用引擎的提交事务接口，将 redo log 状态设置为 commit（将事务设置为 commit 状态后，刷入到磁盘 redo log 文件）；</li>
<li><strong>是否能在 binlog 中查找到与 redo log 相同的 XID</strong>，如果有就提交事务，如果没有就回滚事务。</li>
<li>组提交：<strong>有多个事务提交的时候，会将多个 binlog 刷盘操作合并成一个，从而减少磁盘 I/O 的次数</strong></li>
<li>问题：磁盘 IO 次数高，锁竞争激烈</li>
</ol>
</li>
</ul>
<h2 id="6-架构与-SQL-基础"><a href="#6-架构与-SQL-基础" class="headerlink" title="6 架构与 SQL 基础"></a>6 架构与 SQL 基础</h2><h3 id="6-1-SQL-基础"><a href="#6-1-SQL-基础" class="headerlink" title="6.1 SQL 基础"></a>6.1 SQL 基础</h3><ol>
<li><em>数据库四大范式</em><ol>
<li>第一范式（1NF）：属性不可拆分 或 无重复的列</li>
<li>第二范式（2NF）：非主属性对多属性候选键完全函数依赖</li>
<li>第三范式（3NF）：消除传递依赖  表中不包含已在其它表中已包含的非主属性信息。</li>
<li>BC范式（BCNF）：候选键存在多个属性时，多个主属性直接要消除传递依赖关系     主属性之间不应该有互相依赖。工号和身份证号是相互依赖。</li>
<li>第四范式（4NF）：对于候选键只能存在不超过1个多值属性。要求把同一表内的多对多关系删除。</li>
</ol>
</li>
<li><em>分页查询后期性能变慢的原因</em>    深分页问题<ol>
<li><strong>limit m n</strong>：查询从 m 开始的 n 条数据；扫 m+n 行 丢弃前 m 行</li>
<li><strong>limit n offset m</strong>：从 m 开始的 n 条</li>
<li><code>为什么慢</code>？ <ol>
<li>分页偏移量的增加，需要扫描和跳过的前面的行来到达指定的偏移量，造成浪费，也就是说<code>limit 100000,10</code>，就会扫描100010行</li>
<li><code>limit 100000,10</code> 扫描更多的行数，也意味着回表判断的次数更多</li>
</ol>
</li>
<li>优化：<ol>
<li>子查询优化：把条件转移到主键索引树，然后减少回表，比如先查到第 10000 个</li>
<li>INNER JOIN 延迟关联：先通过二级索引树查询到满足条件的主键ID，再与原表通过主键ID内连接</li>
<li>基于游标的分页：使用游标或主键来定位结果集中的特定行，而不是使用偏移量。这种方法通常比OFFSET更高效</li>
<li>使用between…and…：转换成已知位置的查询</li>
<li>使用合适的索引：确保查询中使用了适当的索引，以减少排序和过滤操作的成本</li>
</ol>
</li>
</ol>
</li>
<li>SQL(聚集函数，group by， having 子句， order by, 连接(内连接、外连接(左右)))<ol>
<li><strong>group by</strong>： 根据一个或多个列对结果集进行分组</li>
<li><strong>having</strong>：筛选分组后的各组数据    where在group by前， having在group by 之后</li>
<li><strong>order by</strong>：排序  desc 降序； asc 升序</li>
<li>连接：<ol>
<li>inner join：  只取交集</li>
<li>left join：左表所有行和右表匹配的，不匹配的行返回 null</li>
<li>right join：和上面类似</li>
<li>full join：全连接，取并集</li>
</ol>
</li>
</ol>
</li>
<li>慢查询日志<ol>
<li>set global slow_query_log = on;  long_query_time</li>
<li>mysqldumpslow进行分析<h3 id="6-2-架构"><a href="#6-2-架构" class="headerlink" title="6.2 架构"></a>6.2 架构</h3></li>
</ol>
</li>
<li>MySQL集群的结构有哪些？各自优缺点？<ol>
<li>主从架构  读写分离，数据备份</li>
<li>主主互备  </li>
</ol>
</li>
<li>分库分表的场景？   数据库性能瓶颈  <strong>IO瓶颈</strong>   <strong>CPU瓶颈</strong><ol>
<li>水平分库： 按 hash 或者 range 策略分到多个库里； 应对高并发</li>
<li>水平分表：将一个表中的数据拆分到多个表中；单表数据太多，影响 SQL 效率；</li>
<li>垂直分库：按业务归属不同分库；可以抽象出单独的业务模块</li>
<li>垂直分表：按照字段的活跃性，将表中字段拆到不同的表（主表和扩展表）中。  字段多，热点数据分离出来；不可用 join</li>
<li>分配策略： hash 取模；范围分片；地理位置；时间</li>
</ol>
</li>
<li>如何不停服迁移库表？<ol>
<li><strong>不停服，增加缓冲层（MQ），数据迁移过程中增量数据写入缓存，在数据迁移完成、缓冲层数据消费完成后，打开开关开始双写数据库</strong></li>
</ol>
</li>
<li>怎么分库分表才能均匀？分库分表后某些分片热点写入怎么解决？<ol>
<li>使用哈希算法：对于分片键（通常是某个列或多个列的组合），使用哈希算法来决定数据应该存储在哪个分片上。这样可以确保数据在分片之间均匀分布，减少热点问题。</li>
<li>增加分片数量：**如果你发现某些分片写入热点问题，可以考虑增加分片的数量。这会增加分片的数量，减少每个分片的负载，提高了吞吐量。</li>
<li>负载均衡：使用负载均衡策略来确保访问请求均匀地分布到不同的分片上。负载均衡可以在应用层或数据库代理层实现。</li>
<li>随机数分片：使用随机数来分配数据到分片，这可以减少数据的热点写入问题，但可能增加查询的复杂性。</li>
<li>分片键设计：精心设计分片键是解决热点写入问题的关键。尽量避免选择容易导致热点的分片键，例如自增主键。</li>
<li>数据迁移：定期监测数据分布，如果发现某个分片过于热点，可以考虑进行数据迁移，将一些数据从热点分片移到其他分片上，以实现负载均衡。</li>
<li>垂直分片：考虑将表按照功能或业务需求进行垂直分片，将不同类型的数据存储在不同的分片上。这可以减少写入热点问题。</li>
<li>缓存：使用缓存来缓解数据库写入压力。将热点数据缓存到内存中，减少对数据库的频繁写入请求。</li>
<li>异步写入：如果一些写入操作不需要立即生效，可以考虑将它们异步化，以减轻数据库的写入负载。例如，使用消息队列将写入操作异步处理。</li>
</ol>
</li>
<li>数据库主库挂了，在存在主从延时的情况下，切从的过程中，查询的数据不一致怎么处理<ol>
<li><strong>等待同步完成</strong>：在进行主从切换前，可以等待从库追赶主库的进度，确保从库的数据已经和主库同步完全。这可以通过监测主从延时来确定。一旦主从延时减少到可以接受的水平，再进行切换。</li>
<li><strong>切换到可用从库</strong>：如果主从切换后发现某个从库数据不一致，可以尝试切换到另一个可用的从库。这需要确保备用从库与主库的数据同步是正常的。</li>
<li><strong>手动同步数据</strong>：在切换完成后，可以考虑手动同步数据以修复不一致。这可能涉及将缺失的数据从主库手动导入到从库，以确保一致性。</li>
<li><strong>数据一致性检查</strong>：在切换后，可以运行一些数据一致性检查工具或脚本来检查数据是否一致。如果发现不一致的数据，可以进行修复。</li>
<li><strong>定期备份</strong>：在数据库正常运行期间，定期进行数据库备份，包括主库和从库。在切换后，如果出现数据不一致问题，可以使用备份进行恢复。</li>
<li><strong>容错和监控</strong>：实现主从切换时，确保有足够的监控和容错机制。这样，如果出现问题，可以迅速发现并采取措施来减小数据不一致的风险。</li>
<li><strong>故障回滚</strong>：如果切换后发现数据不一致问题无法解决，可以考虑回滚到原来的主库，然后采取更谨慎的方式来进行切换，例如逐渐减小主从延时。</li>
</ol>
</li>
</ol>

    
    
  </div>

  

  

</article>
  
  <article class="post">
  <header class="post-header">
    <h1 class="post-title">
      
      <a class="post-link" href="/2023/09/09/Framework/Kafka/">[Framework] Kafka</a>
      
    </h1>

    <div class="post-meta">
      <span class="post-time">
        2023-09-09
      </span>
      
      
      
    </div>
  </header>

  

  <div class="post-content">
    
    
    

    
    <span id="more"></span>
<h2 id="1-Kafka-基础"><a href="#1-Kafka-基础" class="headerlink" title="1 Kafka 基础"></a>1 Kafka 基础</h2><h3 id="1-1-架构"><a href="#1-1-架构" class="headerlink" title="1.1 架构"></a>1.1 架构</h3><blockquote>
<p>分布式的、分区化、可复制提交的日志服务<br><img src="https://pic1.zhimg.com/80/v2-672b6f858c187b5c8182c553cd597f14_1440w.webp" alt=""></p>
<ul>
<li><em>Producer</em>：消息生产者，就是向 kafka broker 发消息的客户端。</li>
<li><em>Consumer</em> ：消息消费者，向 kafka broker 取消息的客户端。</li>
<li><em>Topic</em> ：可以理解为一个队列，一个 Topic 又分为一个或多个分区。</li>
<li><em>Consumer Group</em>：这是 kafka 用来实现一个 topic 消息的广播（发给所有的 consumer）和单播（发给任意一个 consumer）的手段。一个 topic 可以有多个 Consumer Group。</li>
<li><em>Broker</em> ：一台 kafka 服务器就是一个 broker。一个集群由多个 broker 组成。一个 broker 可以容纳多个 topic。</li>
<li><em>Partition</em>：为了实现扩展性，一个非常大的 topic 可以分布到多个 broker上，每个 partition 是一个有序的队列。partition 中的每条消息都会被分配一个有序的id（offset）。将消息发给 consumer，kafka 只保证按一个 partition 中的消息的顺序，不保证一个 topic 的整体（多个 partition 间）的顺序。</li>
<li><em>Offset</em>：kafka 的存储文件都是按照 offset.kafka 来命名，用 offset 做名字的好处是方便查找。例如你想找位于 2049 的位置，只要找到 2048.kafka 的文件即可。当然 the first offset 就是00000000000.kafka。<h3 id="1-2-特点"><a href="#1-2-特点" class="headerlink" title="1.2 特点"></a>1.2 特点</h3></li>
<li><em>高吞吐量、低延迟</em>：每秒可以处理几十万条消息，它的延迟最低只有几毫秒，每个topic可以分多个partition, consumer group 对partition进行consume操作。</li>
<li><em>可扩展性</em>：kafka集群支持热扩展</li>
<li><em>持久性、可靠性</em>：消息被持久化到本地磁盘，并且支持数据备份防止数据丢失</li>
<li><em>容错性</em>：允许集群中节点失败（若副本数量为n,则允许n-1个节点失败）</li>
<li><em>高并发</em>：支持数千个客户端同时读写<h3 id="1-3-怎么实现高吞吐量的？"><a href="#1-3-怎么实现高吞吐量的？" class="headerlink" title="1.3 怎么实现高吞吐量的？"></a>1.3 怎么实现高吞吐量的？</h3></li>
<li><em>分区</em>：多分区通过负载均衡提高了消息并发写入和消费的能力</li>
<li><em>批量发送和压缩消息</em>：<ul>
<li><code>批量发送</code>：将消息缓存在内存中的双端队列中，然后Sender线程将从各分区对应的队列中获取已准备好的消息批次，将消息进行批量发送，减少网络传输频次，提高传输效率。</li>
<li><code>端到端压缩消息</code>：将一批消息打包后进行压缩，在 Consumer 端进行解压</li>
</ul>
</li>
<li><em>顺序读写</em>：将消息messaga追加到本地磁盘文件的末尾</li>
<li><em>零拷贝ZeroCopy</em>：将数据直接从磁盘文件复制到网卡设备中，避免重新复制数据<ul>
<li>操作系统从磁盘读取数据到内核空间的 pagecache</li>
<li>应用程序读取内核空间的数据到用户空间的缓冲区</li>
<li>应用程序将数据(用户空间的缓冲区)写回内核空间到套接字缓冲区(内核空间)</li>
<li>操作系统将数据从套接字缓冲区(内核空间)复制到通过网络发送的 NIC 缓冲区</li>
</ul>
</li>
<li><em>PageCache</em>：利用了现代操作系统分页存储 Page Cache 来利用内存提高 I/O 效率<h3 id="1-4-高可靠性实现"><a href="#1-4-高可靠性实现" class="headerlink" title="1.4 高可靠性实现"></a>1.4 高可靠性实现</h3></li>
<li>副本机制</li>
<li><h3 id="1-5-使用场景"><a href="#1-5-使用场景" class="headerlink" title="1.5 使用场景"></a>1.5 使用场景</h3></li>
<li>日志收集</li>
<li>消息系统</li>
<li>用户活动跟踪<h2 id="2-主题与日志"><a href="#2-主题与日志" class="headerlink" title="2 主题与日志"></a>2 主题与日志</h2><h3 id="2-1-Kafka创建Topic时如何将分区放置到不同的Broker中"><a href="#2-1-Kafka创建Topic时如何将分区放置到不同的Broker中" class="headerlink" title="2.1 Kafka创建Topic时如何将分区放置到不同的Broker中"></a>2.1 Kafka创建Topic时如何将分区放置到不同的Broker中</h3></li>
<li>副本因子不能大于 Broker 的个数；</li>
<li>第一个分区（编号为0）的第一个副本放置位置是随机从 brokerList 选择的；</li>
<li>其他分区的第一个副本放置位置相对于第0个分区依次往后移。也就是如果我们有5个 Broker，5个分区，假设第一个分区放在第四个 Broker 上，那么第二个分区将会放在第五个 Broker 上；第三个分区将会放在第一个 Broker 上；第四个分区将会放在第二个 Broker 上，依次类推；</li>
<li>剩余的副本相对于第一个副本放置位置其实是由 nextReplicaShift 决定的，而这个数也是随机产生的<h3 id="2-2-Kafka-分区数可以增加或减少吗？为什么？"><a href="#2-2-Kafka-分区数可以增加或减少吗？为什么？" class="headerlink" title="2.2 Kafka 分区数可以增加或减少吗？为什么？"></a>2.2 Kafka 分区数可以增加或减少吗？为什么？</h3></li>
<li>可以使用 bin/kafka-topics.sh命令对 Kafka 增加 Kafka 的分区数据，但是 Kafka 不支持减少分区数。</li>
<li>Kafka 分区数据不支持减少是由很多原因的，比如减少的分区其数据放到哪里去？是删除，还是保留？删除的话，那么这些没消费的消息不就丢了。如果保留这些消息如何放到其他分区里面？追加到其他分区后面的话那么就破坏了 Kafka 单个分区的有序性。如果要保证删除分区数据插入到其他分区保证有序性，那么实现起来逻辑就会非常复杂</li>
<li>会在含有分区目录最少的文件夹中创建新的分区目录<h3 id="2-3-kafka分区是不是越多越好"><a href="#2-3-kafka分区是不是越多越好" class="headerlink" title="2.3 kafka分区是不是越多越好"></a>2.3 kafka分区是不是越多越好</h3></li>
<li>句柄开销过大：每增加一个分区，对应的也会增加一个文件描述符，而一个进程所能支配的文件描述符是有限的，这也就是通常说的文件句柄开销。当分区数量超过进程能支配的文件描述符数量时，将出现 <code>Too many open files</code>错误.</li>
<li>生产端占用内存过大：kafka 发送消息时不是立刻发送的，而是会先将每个分区的消息先进行缓存（缓存区大小由<code>batch.size</code>设置，默认16KB），缓存满了后才会发送消息。分区越多的情况下，分区占用的缓存区也将更大。</li>
<li>影响系统可用性：broker数量一定的情况下，分区数量越大则每个broker 中所拥有的分区leader副本数量也将更多。broker出现故障后需要进行leader角色切换的分区数量会很大，导致故障恢复时间较长。<h2 id="3-Producer"><a href="#3-Producer" class="headerlink" title="3 Producer"></a>3 Producer</h2><h3 id="3-1-消息分区选择"><a href="#3-1-消息分区选择" class="headerlink" title="3.1 消息分区选择"></a>3.1 消息分区选择</h3><h3 id="3-2-Kafka-分区的目的？"><a href="#3-2-Kafka-分区的目的？" class="headerlink" title="3.2 Kafka 分区的目的？"></a>3.2 Kafka 分区的目的？</h3>分区对于 Kafka 集群的好处是：实现负载均衡。分区对于消费者来说，可以提高并发度，提高效率。<h3 id="3-3-ack参数设置及意义"><a href="#3-3-ack参数设置及意义" class="headerlink" title="3.3 ack参数设置及意义"></a>3.3 ack参数设置及意义</h3>参数设置： 设置 <code>request.required.acks=-1</code> ，只有 ISR 中所有副本都成功写入消息后才认为 kafka 消息成功写入。acks 参数其他配置项意义如下：</li>
<li><code>acks = 1</code>(默认)：分区leader 副本写入成功即认为消息成功写入，只确保leader发送成功</li>
<li><code>acks = 0</code> ：不需要等待任何服务端的响应都可认为消息成功写入，安全性最低但是效率最高。</li>
<li><code>acks = -1/ all</code> ：代表producer往集群发送数据需要所有的follower都完成从leader的同步才会发送下一条，确保 leader发送成功和所有的副本都完成备份。<h3 id="3-4-幂等特性"><a href="#3-4-幂等特性" class="headerlink" title="3.4 幂等特性"></a>3.4 幂等特性</h3></li>
<li>一次或者多次请求某一个资源对于资源本身应该具有同样的结果</li>
<li><strong>唯一标识</strong>：判断某个请求是否重复，需要有一个唯一性标识，然后服务端就能根据这个唯一标识来判断是否为重复请求。</li>
<li><strong>记录已经处理过的请求</strong>：服务端需要记录已经处理过的请求，然后根据唯一标识来判断是否是重复请求，如果已经处理过，则直接拒绝或者不做任何操作返回成功。</li>
<li>只能保证生产端在单个会话内的幂等，如果生产端因为某些原因意外挂掉然后重启，此时是没办法保证幂等的，因为这时没办法获取到之前的状态信息，即无法做到跨会话级别的幂等。</li>
<li>幂等性不能跨多个主题分区，只能保证单个分区内的幂等，涉及到多个消息分区时，中间的状态并没有同步<h3 id="3-5-Kafka-是如何做到消息的有序性？"><a href="#3-5-Kafka-是如何做到消息的有序性？" class="headerlink" title="3.5 Kafka 是如何做到消息的有序性？"></a>3.5 Kafka 是如何做到消息的有序性？</h3></li>
<li>kafka 中的每个 partition 中的消息在写入时都是有序的，而且单独一个 partition 只能由一个消费者去消费，可以在里面保证消息的顺序性。但是分区之间的消息是不保证有序的。</li>
<li>设置一个topic一个partition，消费者单线程消费</li>
<li>消息发送指定key，确保相同key的消息发送到同一个partition<h3 id="3-6-Kafka如何保证消息不丢失"><a href="#3-6-Kafka如何保证消息不丢失" class="headerlink" title="3.6 Kafka如何保证消息不丢失"></a>3.6 Kafka如何保证消息不丢失</h3></li>
<li><em>生产者</em>：ACK 机制</li>
<li><em>broker</em>：多副本和副本同步机制；保证ISR副本数量大于等于二</li>
<li><em>消费者</em>：<ul>
<li>消息消费关闭自动提交，改为手动提交offset，确保消息可再次消费</li>
<li>在第一点的前提下，涉及到消息的重复消费，所以消费端应做好消息的幂等处理<h3 id="3-7-Kafka-Producer-的执行过程？"><a href="#3-7-Kafka-Producer-的执行过程？" class="headerlink" title="3.7 Kafka Producer 的执行过程？"></a>3.7 Kafka Producer 的执行过程？</h3></li>
</ul>
</li>
<li>Producer生产消息</li>
<li>从Zookeeper找到Partition的Leader</li>
<li>推送消息</li>
<li>通过ISR列表通知给Follower</li>
<li>Follower从Leader拉取消息，并发送ack</li>
<li>Leader收到所有副本的ack，更新Offset，并向Producer发送ack，表示消息写入成功。<h3 id="3-8-Kafka消息是采用Pull模式，还是Push模式？"><a href="#3-8-Kafka消息是采用Pull模式，还是Push模式？" class="headerlink" title="3.8 Kafka消息是采用Pull模式，还是Push模式？"></a>3.8 Kafka消息是采用Pull模式，还是Push模式？</h3></li>
<li>producer将消息推送到broker，consumer从broker拉取消息</li>
<li>consumer可以自主的根据消费能力和策略决定是否批量的从broker拉取数据<h3 id="3-9-如何保证消息不被重复消费？"><a href="#3-9-如何保证消息不被重复消费？" class="headerlink" title="3.9 如何保证消息不被重复消费？"></a>3.9 如何保证消息不被重复消费？</h3></li>
<li>生产者在向Kafka写数据时，每条消息会有一个offset，表示消息写入顺序的序号。当消费者消费后，<strong>每隔一段时间会把自己已消费消息的offset通过Zookeeper提交给Kafka</strong>，告知Kafka自己offset的位置。这样一来，如果消费者重启，则会从Kafka记录的offset之后的数据开始消费，从而避免重复消费。</li>
<li>在发生重复消费后，如何<strong>保证消息消费时的幂等性</strong>。如果消费者可以在消费消息时先判断一下，自己是否已经消费了该消息，如果是就不消费，那么就可以保证系统的幂等性。<ul>
<li>数据库查询</li>
<li>redis 用 set 去重</li>
<li>全局 id</li>
</ul>
</li>
</ul>
</blockquote>
<h2 id="4-Consumer"><a href="#4-Consumer" class="headerlink" title="4 Consumer"></a>4 Consumer</h2><h3 id="4-1-消费组"><a href="#4-1-消费组" class="headerlink" title="4.1 消费组"></a>4.1 消费组</h3><ul>
<li>多个消费者可以组成一个消费组，每个消费者只属于一个消费组。</li>
<li>消费组订阅主题的每个分区只会分配给该消费组中的某个消费者处理，不同的消费组之间彼此隔离无依赖。</li>
<li>同一个消息只会被消费组中的一个消费者消费，如果想要让同一个消息被多个消费者消费，那么每个消费者需要属于不同的消费组，且对应消费组中只有该一个消费者，消费组的引入可以实现消费的“独占”或“广播”效果。<h3 id="4-2-重平衡机制"><a href="#4-2-重平衡机制" class="headerlink" title="4.2 重平衡机制"></a>4.2 重平衡机制</h3></li>
<li><em>触发条件</em>：<ul>
<li>消费者数量变化： 新消费者加入、消费者下线、消费者主动退出消费组</li>
<li>消费组内订阅的主题或者主题的分区数量发生变化</li>
<li>消费组对应的 GroupCoorinator 节点发生变化</li>
</ul>
</li>
<li><em>rebalance过程</em>：<ul>
<li>寻找到消费组的 协调者(GroupCoordination)，消费者组提交组位移的 partiotion 所在的 broker</li>
<li>所有消费者向协调者发送 JoinGroup 请求</li>
<li>协调者为消费组选择新的leader</li>
<li>协调者发送 <code>JoinGroupResponse</code> 给各个消费组，其中leader消费者的 <code>JoinGroupResponse</code> 包含了消费组成员信息</li>
<li>leader消费者指定新的消费方案</li>
<li>各消费者向 协调者 发送 <code>SyncGroupRequest</code> 请求，其中 leader消费者的<code>SyncGroupRequest</code> 携带有相关的分配方案</li>
<li>协调者向各消费者下发分区分配方案</li>
</ul>
</li>
<li><em>避免非必要rebalance</em> ：设置合理的心跳发送时间；设置Consumer 消费时间最大间隔<h3 id="4-3-Kafka-消费者是否可以消费指定分区消息？"><a href="#4-3-Kafka-消费者是否可以消费指定分区消息？" class="headerlink" title="4.3 Kafka 消费者是否可以消费指定分区消息？"></a>4.3 Kafka 消费者是否可以消费指定分区消息？</h3>Kafa consumer消费消息时，向broker发出fetch请求去消费特定分区的消息，consumer指定消息在日志中的偏移量（offset），就可以消费从这个位置开始的消息，customer拥有了offset的控制权，可以向后回滚去重新消费之前的消息，这是很有意义的。<h3 id="4-4-讲一下-Kafka-Consumer-消费消息时的线程模型，为何如此设计？"><a href="#4-4-讲一下-Kafka-Consumer-消费消息时的线程模型，为何如此设计？" class="headerlink" title="4.4 讲一下 Kafka Consumer 消费消息时的线程模型，为何如此设计？"></a>4.4 讲一下 Kafka Consumer 消费消息时的线程模型，为何如此设计？</h3>Thread-Per-Consumer Model，这种多线程模型是利用Kafka的topic分多个partition的机制来实现并行：每个线程都有自己的consumer实例，负责消费若干个partition。各个线程之间是完全独立的，不涉及任何线程同步和同学通信，所以实现起来非常简单。<h2 id="5-副本"><a href="#5-副本" class="headerlink" title="5 副本"></a>5 副本</h2><h3 id="5-1-ISR集合-AR-OSR"><a href="#5-1-ISR集合-AR-OSR" class="headerlink" title="5.1 ISR集合,AR,OSR"></a>5.1 ISR集合,AR,OSR</h3></li>
<li><em>In-Sync Replicas 副本同步队列</em>，表示可用的副本集合，也就是和主副本差距不大</li>
<li>ISR 是由 leader 维护，follower从leader 同步数据有一些延迟（包括延迟时间和延迟条数）, 任意一个超过阈值都会把follower剔除出ISR, 存入OSR（Outof-Sync Replicas）列表，新加入的follower也会先存放在OSR中。AR=ISR+OSR</li>
<li>主要是解决<code>同步副本</code>与<code>异步复制</code>两种方案各自的缺陷<h3 id="5-2-HW-amp-LEO"><a href="#5-2-HW-amp-LEO" class="headerlink" title="5.2 HW&amp;LEO"></a>5.2 HW&amp;LEO</h3></li>
<li>HW（High Watermark）：消费端消费时只能拉取到小于HW的消息而HW及之后的消息对于消费者来说是不可见的，保证HW之前消息的可靠性</li>
<li>LEO（Log End Offset）：表示当前副本最新消息的下一个offset<h3 id="5-3-leader-epoch机制"><a href="#5-3-leader-epoch机制" class="headerlink" title="5.3 leader epoch机制"></a>5.3 leader epoch机制</h3>leader epoch表示一个键值对<epoch, offset>，其中epoch表示leader主副本的版本号，从0开始编码，当leader每变更一次就会+1，offset表示该epoch版本的主副本写入第一条消息的位置，比如<0,0>表示第一个主副本从位移0开始写入消息，<1,100>表示第二个主副本版本号为1并从位移100开始写入消息，主副本会将该信息保存在缓存中并定期写入到checkpoint文件中，每次发生主副本切换都会去从缓存中查询该信息<h2 id="6-拾遗"><a href="#6-拾遗" class="headerlink" title="6 拾遗"></a>6 拾遗</h2></li>
</ul>
<h3 id="6-1-除了kafka-还用过哪些消息队列-他和kafka-有哪些区别，优劣"><a href="#6-1-除了kafka-还用过哪些消息队列-他和kafka-有哪些区别，优劣" class="headerlink" title="6.1 除了kafka 还用过哪些消息队列 他和kafka 有哪些区别，优劣"></a>6.1 除了kafka 还用过哪些消息队列 他和kafka 有哪些区别，优劣</h3><h3 id="6-2-Kafka-高效文件存储设计特点"><a href="#6-2-Kafka-高效文件存储设计特点" class="headerlink" title="6.2 Kafka 高效文件存储设计特点"></a>6.2 Kafka 高效文件存储设计特点</h3><ul>
<li>Kafka把topic中一个parition大文件分成多个小文件段，通过多个小文件段，就容易定期清除或删除已经消费完文件，减少磁盘占用。</li>
<li>通过索引信息可以快速定位message和确定 response的最大大小。</li>
<li>通过index元数据全部映射到memory，可以避免segment file的IO磁盘操作。</li>
<li>通过索引文件稀疏存储，可以大幅降低 index 文件元数据占用空间大小</li>
</ul>
<h3 id="6-3-Kafka-数据一致性原理"><a href="#6-3-Kafka-数据一致性原理" class="headerlink" title="6.3 Kafka 数据一致性原理"></a>6.3 Kafka 数据一致性原理</h3><ul>
<li>一致性就是说不论是老的 Leader 还是新选举的 Leader，Consumer 都能读到一样的数据。</li>
<li>假设分区的副本为3，其中副本0是 Leader，副本1和副本2是 follower，并且在 ISR 列表里面。虽然副本0已经写入了 Message4，但是 Consumer 只能读取到 Message2。因为所有的 ISR 都同步了 Message2，只有 High Water Mark 以上的消息才支持 Consumer 读取，而 High Water Mark 取决于 ISR 列表里面偏移量最小的分区，类似于<strong>木桶原理</strong>。</li>
<li>还没有被足够多副本复制的消息被认为是“不安全”的，如果 Leader 发生崩溃，另一个副本成为新 Leader，那么这些消息很可能丢失了。如果我们允许消费者读取这些消息，可能就会破坏一致性。试想，一个消费者从当前 Leader（副本0） 读取并处理了 Message4，这个时候 Leader 挂掉了，选举了副本1为新的 Leader，这时候另一个消费者再去从新的 Leader 读取消息，发现这个消息其实并不存在，这就导致了数据不一致性问题。</li>
</ul>
<h3 id="6-4-数据传输的事务有几种？"><a href="#6-4-数据传输的事务有几种？" class="headerlink" title="6.4 数据传输的事务有几种？"></a>6.4 数据传输的事务有几种？</h3><ul>
<li>数据传输的事务定义通常有以下三种级别：</li>
<li>最多一次: 消息不会被重复发送，最多被传输一次，但也有可能一次不传输 </li>
<li>最少一次: 消息不会被漏发送，最少被传输一次，但也有可能被重复传输.</li>
<li>精确的一次（Exactly once）: 不会漏传输也不会重复传输,每个消息都传输被</li>
</ul>
<h3 id="6-5-kafka为什么不需要支持读写分离"><a href="#6-5-kafka为什么不需要支持读写分离" class="headerlink" title="6.5 kafka为什么不需要支持读写分离"></a>6.5 kafka为什么不需要支持读写分离</h3><ul>
<li>读写均衡</li>
<li>分区，压力都不大</li>
</ul>
<h3 id="6-6-Kafka-中-zookeeper-的作用？它是如何保证-kafka-高可用的？主节点选举机制？"><a href="#6-6-Kafka-中-zookeeper-的作用？它是如何保证-kafka-高可用的？主节点选举机制？" class="headerlink" title="6.6 Kafka 中 zookeeper 的作用？它是如何保证 kafka 高可用的？主节点选举机制？"></a>6.6 Kafka 中 zookeeper 的作用？它是如何保证 kafka 高可用的？主节点选举机制？</h3><ol>
<li>用于在集群中不同节点之间进行通信</li>
<li>提交偏移量</li>
<li>leader 检测、分布式同步、配置管理、识别新节点何时离开或连接、集群、节点实时状态<h3 id="6-7-使用-kafka-的时候，如何确定一个-topic-的-partition-数量？"><a href="#6-7-使用-kafka-的时候，如何确定一个-topic-的-partition-数量？" class="headerlink" title="6.7 使用 kafka 的时候，如何确定一个 topic 的 partition 数量？"></a>6.7 使用 kafka 的时候，如何确定一个 topic 的 partition 数量？</h3></li>
<li>单台broker上partition数量不超过4000, 整个集群partition数量不超过2000,000</li>
<li>更多的Partition可能导致不可用时间增长；增加端到端的延迟；使用过多的内存<h3 id="6-8-kafka消息积压如何处理"><a href="#6-8-kafka消息积压如何处理" class="headerlink" title="6.8 kafka消息积压如何处理"></a>6.8 kafka消息积压如何处理</h3></li>
</ol>
<ul>
<li>问题定位：<ul>
<li>消息生产端数据量是否存在陡升的情况</li>
<li>消息消费端消费能力是否有下降</li>
<li>消息积压是发生在所有的partition还是所有的partition都有积压情况</li>
</ul>
</li>
<li>解决：<ul>
<li>前两个可以多线程，批量消费等提高消费速度</li>
<li>后者<ul>
<li>新建一个 topic，partition 是原来的 10 倍，临时建立好原先 10 倍的 queue 数量</li>
<li>然后写一个临时的分发数据的 consumer 程序，这个程序部署上去消费积压的数据，<strong>消费之后不做耗时的处理</strong>，直接均匀轮询写入临时建立好的 10 倍数量的 queue</li>
<li>接着临时征用 10 倍的机器来部署 consumer，每一批 consumer 消费一个临时 queue 的数据。这种做法相当于是临时将 queue 资源和 consumer 资源扩大 10 倍，以正常的 10 倍速度来消费数据</li>
<li>等快速消费完积压数据之后，<strong>得恢复原先部署的架构</strong>，<strong>重新</strong>用原先的 consumer 机器来消费消息</li>
</ul>
</li>
</ul>
</li>
</ul>

    
    
  </div>

  

  

</article>
  
    
  <nav class="pagination">  
      
      <a class="prev" href="/page/5/">  
        <i class="iconfont icon-left"></i>  
        <span class="prev-text">Prev</span>  
      </a>  
      
      
      <a class="next" href="/page/7/">  
        <span class="next-text">Next</span>  
        <i class="iconfont icon-right"></i>  
      </a>  
      
  </nav>  
  

  
</section>
        </div>
      </div>
    </main>
    <footer id="footer" class="footer">
      <!-- Social Links -->

<div class="social-links">
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  

  
  <a href="/atom.xml" class="iconfont icon-rss" title="rss"></a>
  
</div>



<div class="copyright">
  <span class="power-by">
    Powered by <a class="hexo-link" target="_blank" rel="noopener" href="https://hexo.io/">Hexo</a>
  </span>
  <span class="division">|</span>
  <span class="theme-info">
    Theme -
    <a class="theme-link" target="_blank" rel="noopener" href="https://github.com/ahonn/hexo-theme-even">Even</a>
  </span>
  <span class="division">|</span>
  <span class="hosting-info">
    footer.hosting
  </span>

  <span class="copyright-year">
    <span>
      
      &copy;
      
      2019 - 2025      
    </span>

    <span class="heart">
      <i class="iconfont icon-heart"></i>
    </span>

    <span class="author">draco</span>
  </span>

</div>
    </footer>
    <div class="back-to-top" id="back-to-top"> <i class="iconfont icon-up"></i> </div>
  </div>
  







<script type="text/javascript" src="/lib/jquery/jquery.min.js"></script>



<script type="text/javascript" src="/lib/slideout/slideout.js"></script>



<script type="text/javascript" src="/lib/fancybox/jquery.fancybox.pack.js"></script>



  <script type="text/javascript" src="/js/src/even.js?v=3.0.0"></script>
</body>

</html>