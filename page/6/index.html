<!DOCTYPE html>
<html lang="en">

<head>
  <!-- Website mata -->
<meta charset="UTF-8" />
<meta http-equiv="X-UA-Compatible" content="IE=edge" />
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1" />

<!-- Disable transformation -->
<meta http-equiv="Cache-Control" content="no-transform" />
<meta http-equiv="Cache-Control" content="no-siteapp" />

<meta name="theme-color" content="#f8f5ec" />
<meta name="msapplication-navbutton-color" content="#f8f5ec">
<meta name="apple-mobile-web-app-capable" content="yes">
<meta name="apple-mobile-web-app-status-bar-style" content="#f8f5ec">

<!-- Website description -->


<!-- Website keywords -->




<!-- Website rss -->

<link rel="alternate" href="/atom.xml" title="Draco's Blog" type="application/atom+xml">


<!-- Website favicon -->

<link rel="shortcut icon" type="image/x-icon" href="/favicon.ico?v=3.0.0" />


<!-- Canonical, good for google search engine -->
<link rel="canonical" href="https://stardustorz.github.io/page/6/" />

<!-- Fancybox styling -->

<link rel="stylesheet" type="text/css" href="/lib/fancybox/jquery.fancybox.css" />


<!-- MathJax (LaTeX) support -->


<!-- Theme styling -->
<link rel="stylesheet" type="text/css" href="/css/style.css?v=3.0.0" />

<!-- Analytics and push -->



  



<!-- LeanCloud Counter -->


<script>
  window.config = {"leancloud":{"app_id":null,"app_key":null,"server_url":null,"cdn":null},"toc":true,"fancybox":true,"latex":false};
</script>
  
  <title>Draco&#39;s Blog</title>

<meta name="generator" content="Hexo 6.3.0"></head>

<body>
  <div class="scrollPercentage"></div>
  <div id="mobile-navbar" class="mobile-navbar">
  <div class="mobile-header-logo">
    <a href="/." class="logo">Draco&#39;s Blog</a>
  </div>
  <div class="mobile-navbar-icon">
    <span></span>
    <span></span>
    <span></span>
  </div>
</div>

<nav id="mobile-menu" class="mobile-menu slideout-menu">
  <ul class="mobile-menu-list">
    
    <a href="/">
      <li class="mobile-menu-item">
        
        
        Home              </li>
    </a>
    
    <a href="/archives/">
      <li class="mobile-menu-item">
        
        
        Archives              </li>
    </a>
    
    <a href="/tags/">
      <li class="mobile-menu-item">
        
        
        Tags              </li>
    </a>
    
    <a href="/categories/">
      <li class="mobile-menu-item">
        
        
        Categories              </li>
    </a>
    
    <a href="/links/">
      <li class="mobile-menu-item">
        
        
        Links              </li>
    </a>
    
    <a href="/about/">
      <li class="mobile-menu-item">
        
        
        About              </li>
    </a>
    
  </ul>
</nav>
  <div class="container" id="mobile-panel">
    <header id="header" class="header">
      <div class="logo-wrapper">  
  <a href="/." class="logo">Draco's Blog</a>  
</div>  
  
<nav class="site-navbar">  
    
    <ul id="menu" class="menu">  
        
        <li class="menu-item">  
          <a class="menu-item-link" href="/">  
              
              
              Home  
              
          </a>  
        </li>  
        
        <li class="menu-item">  
          <a class="menu-item-link" href="/archives/">  
              
              
              Archives  
              
          </a>  
        </li>  
        
        <li class="menu-item">  
          <a class="menu-item-link" href="/tags/">  
              
              
              Tags  
              
          </a>  
        </li>  
        
        <li class="menu-item">  
          <a class="menu-item-link" href="/categories/">  
              
              
              Categories  
              
          </a>  
        </li>  
        
        <li class="menu-item">  
          <a class="menu-item-link" href="/links/">  
              
              
              Links  
              
          </a>  
        </li>  
        
        <li class="menu-item">  
          <a class="menu-item-link" href="/about/">  
              
              
              About  
              
          </a>  
        </li>  
        
    </ul>  
    
</nav>  

    </header>
    <main id="main" class="main">
      <div class="content-wrapper">
        <div id="content" class="content">
          <section id="posts" class="posts">
  
  
  
  <article class="post">
  <header class="post-header">
    <h1 class="post-title">
      
      <a class="post-link" href="/2025/01/19/Golang/3%20%E4%BB%A3%E7%A0%81%E8%A7%84%E8%8C%83/Golang%20%E4%BB%A3%E7%A0%81%E8%A7%84%E8%8C%83/">[Go] Code Style</a>
      
    </h1>

    <div class="post-meta">
      <span class="post-time">
        2025-01-19
      </span>
      
      
      
    </div>
  </header>

  

  <div class="post-content">
    
    
    
    
    

    
    <blockquote>
<p>主要记录了一些容易犯错的地方，具体规范参考如下:</p>
</blockquote>
    <div class="read-more">
      <a href="/2025/01/19/Golang/3%20%E4%BB%A3%E7%A0%81%E8%A7%84%E8%8C%83/Golang%20%E4%BB%A3%E7%A0%81%E8%A7%84%E8%8C%83/" class="read-more-link">Read more..</a>
    </div>
    
    
  </div>

  

  

</article>
  
  <article class="post">
  <header class="post-header">
    <h1 class="post-title">
      
      <a class="post-link" href="/2025/01/16/Golang/4%20%E5%85%B6%E4%BB%96/Concatenate%20Strings/">[Go] Concatenate Strings</a>
      
    </h1>

    <div class="post-meta">
      <span class="post-time">
        2025-01-16
      </span>
      
      
      
    </div>
  </header>

  

  <div class="post-content">
    
    
    
    
    

    
    <blockquote>
<p>How to Efficiently Concatenate Strings in Go</p>
</blockquote>
    <div class="read-more">
      <a href="/2025/01/16/Golang/4%20%E5%85%B6%E4%BB%96/Concatenate%20Strings/" class="read-more-link">Read more..</a>
    </div>
    
    
  </div>

  

  

</article>
  
  <article class="post">
  <header class="post-header">
    <h1 class="post-title">
      
      <a class="post-link" href="/2025/01/16/Golang/4%20%E5%85%B6%E4%BB%96/%E6%9E%84%E5%BB%BADocker%E9%95%9C%E5%83%8F/">[Go] Build Docker Image</a>
      
    </h1>

    <div class="post-meta">
      <span class="post-time">
        2025-01-16
      </span>
      
      
      
    </div>
  </header>

  

  <div class="post-content">
    
    
    
    
    

    
    <blockquote>
<p>Golang应用通过Dockerfile构建Docker镜像</p>
</blockquote>
    <div class="read-more">
      <a href="/2025/01/16/Golang/4%20%E5%85%B6%E4%BB%96/%E6%9E%84%E5%BB%BADocker%E9%95%9C%E5%83%8F/" class="read-more-link">Read more..</a>
    </div>
    
    
  </div>

  

  

</article>
  
  <article class="post">
  <header class="post-header">
    <h1 class="post-title">
      
      <a class="post-link" href="/2025/01/15/Golang/4%20%E5%85%B6%E4%BB%96/http.Client%E8%AF%B7%E6%B1%82%E7%A8%8B%E5%BA%8F%E9%81%87%E5%88%B0%20Connection%20Reset%20by%20Peer%20%E6%88%96%20EOF%20%E9%97%AE%E9%A2%98/">[Go] Connection Reset by Peer or EOF</a>
      
    </h1>

    <div class="post-meta">
      <span class="post-time">
        2025-01-15
      </span>
      
      
      
    </div>
  </header>

  

  <div class="post-content">
    
    
    
    
    

    
    <blockquote>
<p>Golang http.Client请求程序遇到Connection Reset by peer 或 EOF 问题</p>
</blockquote>
    <div class="read-more">
      <a href="/2025/01/15/Golang/4%20%E5%85%B6%E4%BB%96/http.Client%E8%AF%B7%E6%B1%82%E7%A8%8B%E5%BA%8F%E9%81%87%E5%88%B0%20Connection%20Reset%20by%20Peer%20%E6%88%96%20EOF%20%E9%97%AE%E9%A2%98/" class="read-more-link">Read more..</a>
    </div>
    
    
  </div>

  

  

</article>
  
  <article class="post">
  <header class="post-header">
    <h1 class="post-title">
      
      <a class="post-link" href="/2025/01/13/Golang/4%20%E5%85%B6%E4%BB%96/WorkerPool/">[Go] WorkerPool</a>
      
    </h1>

    <div class="post-meta">
      <span class="post-time">
        2025-01-13
      </span>
      
      
      
    </div>
  </header>

  

  <div class="post-content">
    
    
    
    
    

    
    <blockquote>
<p>Golang实现一个工作池处理并发任务</p>
</blockquote>
    <div class="read-more">
      <a href="/2025/01/13/Golang/4%20%E5%85%B6%E4%BB%96/WorkerPool/" class="read-more-link">Read more..</a>
    </div>
    
    
  </div>

  

  

</article>
  
  <article class="post">
  <header class="post-header">
    <h1 class="post-title">
      
      <a class="post-link" href="/2025/01/13/Golang/4%20%E5%85%B6%E4%BB%96/Channel%E5%AE%9E%E7%8E%B0%E4%BA%92%E6%96%A5%E9%94%81/">[Go] Channel实现互斥锁</a>
      
    </h1>

    <div class="post-meta">
      <span class="post-time">
        2025-01-13
      </span>
      
      
      
    </div>
  </header>

  

  <div class="post-content">
    
    
    
    
    

    
    <blockquote>
<p>使用长度为1的有缓冲channel实现互斥锁</p>
</blockquote>
    <div class="read-more">
      <a href="/2025/01/13/Golang/4%20%E5%85%B6%E4%BB%96/Channel%E5%AE%9E%E7%8E%B0%E4%BA%92%E6%96%A5%E9%94%81/" class="read-more-link">Read more..</a>
    </div>
    
    
  </div>

  

  

</article>
  
  <article class="post">
  <header class="post-header">
    <h1 class="post-title">
      
      <a class="post-link" href="/2023/09/10/Framework/MySQL/">[Framework] MySQL</a>
      
    </h1>

    <div class="post-meta">
      <span class="post-time">
        2023-09-10
      </span>
      
      
      
    </div>
  </header>

  

  <div class="post-content">
    
    
    

    
    <span id="more"></span>
<h2 id="1-架构与简介"><a href="#1-架构与简介" class="headerlink" title="1 架构与简介"></a>1 架构与简介</h2><h3 id="1-1-MySQL-架构"><a href="#1-1-MySQL-架构" class="headerlink" title="1.1 MySQL 架构"></a>1.1 MySQL 架构</h3><ul>
<li><em>Server 层</em>：建立连接、分析和执行 SQL；主要包括连接器、查询缓存、分析器、优化器、执行器等，所有跨存储引擎的功能都在这一层实现，比如存储过程、触发器、视图，函数等，还有一个通用的日志模块 binglog 日志模块。</li>
<li><em>存储引擎层</em>：主要负责数据的存储和读取，采用可以替换的插件式架构，支持 InnoDB、MyISAM、Memory 等多个存储引擎，其中 InnoDB 引擎有自有的日志模块 redolog 模块。<strong>现在最常用的存储引擎是 InnoDB，它从 MySQL 5.5.5 版本开始就被当做默认存储引擎了。</strong></li>
</ul>
<h3 id="1-2-SQL-语句执行过程"><a href="#1-2-SQL-语句执行过程" class="headerlink" title="1.2 SQL 语句执行过程"></a>1.2 SQL 语句执行过程</h3><blockquote>
<p>MySQL 执行一条 select 查询语句，在 MySQL 中期间发生了什么？</p>
<ul>
<li><em>连接器</em>：TCP 三次握手连接</li>
<li><em>查询缓存</em>：先去查询缓存（ Query Cache ）里查找缓存数据</li>
<li><em>解析 SQL</em>：解析器进行词法分析和语法分析</li>
<li><em>执行 SQL</em>：<ul>
<li><code>预处理器</code>：查询表和字段是否存在</li>
<li><code>优化器</code>：确定 SQL 语句执行方案，选择最高效的索引<ul>
<li>explain：select_type 查询类型； type 连接方式；key 用到的索引；rows 扫描出的行数</li>
</ul>
</li>
<li><code>执行器</code>：<ul>
<li>主键索引查询：选择符合的记录</li>
<li>全表扫描</li>
<li><strong><em>索引下推</em></strong>：<code>减少二级索引在查询时的回表操作</code>，将查询条件下推到存储引擎层面进行判断，而不是将数据加载到内存中由应用层进行过滤</li>
<li>exp： <code>where age &gt; 20 and reward = 100000</code>, 其中 age 可以用到联合索引，通过下推后，直接在存储引擎中过滤出<code>reward = 100000</code>的记录再去回表；<h3 id="1-3-记录存储"><a href="#1-3-记录存储" class="headerlink" title="1.3 记录存储"></a>1.3 记录存储</h3></li>
</ul>
</li>
</ul>
</li>
<li>数据存放：表结构（t_order.frm），表数据（t_order.ibd）</li>
<li>表空间文件结构：段（segment）、区（extent）、页（page，16KB）、行（row）</li>
<li><code>null 存储</code>：Compact 行格式中会用「NULL值列表」来标记值为 NULL 的列，NULL 值并不会存储在行格式中的真实数据部分</li>
<li>页的大小和结构： 16KB 文件头 页头 最小和最大记录 用户记录 空闲空间 页目录 文件尾</li>
<li>innodb的行格式：<img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/mysql/row_format/COMPACT.drawio.png" alt=""><pre><code>  1. 变长字段的真实数据占用的字节数会按照列的顺序**逆序存放**    **使得位置靠前的记录的真实数据和数据对应的字段长度信息可以同时在一个 CPU Cache Line 中，这样就可以提高 CPU Cache 的命中率**。
  2. trx_id   事务id；roll_pointer  记录上一个版本的指针
</code></pre></li>
</ul>
</blockquote>
<h2 id="2-索引"><a href="#2-索引" class="headerlink" title="2 索引"></a>2 索引</h2><h3 id="2-1-索引简介与-B-树"><a href="#2-1-索引简介与-B-树" class="headerlink" title="2.1 索引简介与 B+树"></a>2.1 索引简介与 B+树</h3><h4 id="2-1-1-什么是索引？"><a href="#2-1-1-什么是索引？" class="headerlink" title="2.1.1 什么是索引？"></a>2.1.1 什么是索引？</h4><ul>
<li>帮助存储引擎快速获取数据的一种数据结构</li>
<li>缺点：本身会占据物理空间；创建索引和维护索引要耗费时间；降低表的增删改的效率</li>
<li>使用场合：字段有唯一性限制，表数据多，更新不频繁<h4 id="2-1-2-B-树"><a href="#2-1-2-B-树" class="headerlink" title="2.1.2 B+树"></a>2.1.2 B+树</h4><blockquote>
<p>主键索引和二级索引默认使用的是 B+Tree 索引</p>
</blockquote>
</li>
<li><em>什么是 B+树？</em><ul>
<li>B 树：多叉树，左小右大，每个节点都包含索引和数据</li>
<li><em>B+树</em>:就是 B 树的升级<ul>
<li>叶子节点（最底部的节点）才会存放实际数据（索引+记录），非叶子节点只会存放索引</li>
<li>所有索引都会在叶子节点出现，叶子节点之间构成一个<code>有序链表</code></li>
<li>非叶子节点中有多少个子节点，就有多少个索引</li>
<li>B+ 树点节点内容是数据页，数据页里存放了用户的记录以及各种信息，每个数据页默认大小是 16 KB</li>
</ul>
</li>
</ul>
</li>
<li><em>B+树优点</em>：<ul>
<li>B+树的非叶子节点可以存放更多的索引，出度更大</li>
<li>范围查询效率更高</li>
</ul>
</li>
<li>单表最大值：一般三层就可以存放两千万行数据，超过可能增加层级；内存放不下索引<h3 id="2-2-索引分类"><a href="#2-2-索引分类" class="headerlink" title="2.2 索引分类"></a>2.2 索引分类</h3></li>
<li>按数据结构： B+Tree 索引、HASH 索引、Full-Text 索引</li>
<li>按物理存储： <strong>聚簇索引（主键索引）、二级索引（辅助索引）</strong> 叶子节点存放的是主键值，还要回表</li>
<li>按字段特性： <strong>主键索引、唯一索引、普通索引、前缀索引</strong></li>
<li>按字段个数： <strong>单列索引、联合索引</strong>   <ul>
<li>最左匹配原则：按照最左优先的方式进行索引的匹配</li>
<li>exp：（a，b，c）的索引会先按 a 排序，在 a 相同的情况下按 b 排序，再按 c 排序，因此<code>b 和 c 是全局无序，局部相对有序的</code>，所以 <code>where b=2 and c=3；</code> 无法利用索引</li>
<li>where a &gt; 1 and b = 2  只有 a 能利用联合索引<h3 id="2-3-索引优化"><a href="#2-3-索引优化" class="headerlink" title="2.3 索引优化"></a>2.3 索引优化</h3></li>
</ul>
</li>
</ul>
<ol>
<li><code>前缀索引</code>优化： 可以减小索引项的大小，但是不能成为覆盖索引</li>
<li><code>覆盖索引</code>优化： 直接从二级索引获取数据，避免回表</li>
<li>主键索引<code>自增</code>：插入效率高；避免造成页分裂；主键字段的长度不要太大，减小二级索引规模</li>
<li>索引设置 NOT NULL：方便优化器选择<h3 id="2-4-索引失效"><a href="#2-4-索引失效" class="headerlink" title="2.4 索引失效"></a>2.4 索引失效</h3></li>
</ol>
<ul>
<li>使用左或者左右模糊匹配，like %xx</li>
<li>在查询条件中对索引列做了计算、函数、类型转换操作</li>
<li>联合索引未遵循最左匹配原则</li>
<li>WHERE 子句中， OR 前的条件列是索引列， OR 后不是，那么索引会失效<h2 id="3-事务"><a href="#3-事务" class="headerlink" title="3 事务"></a>3 事务</h2><h3 id="3-1-事务的特性-ACID"><a href="#3-1-事务的特性-ACID" class="headerlink" title="3.1 事务的特性 ACID"></a>3.1 事务的特性 ACID</h3></li>
<li><em><strong>原子性（Atomicity）</strong></em>：一个事务中的所有操作，要么全部完成，要么全部不完成，不会结束在中间某个环节，而且事务在执行过程中发生错误，会被回滚到事务开始前的状态； <code>由 undo log（回滚日志保证）</code></li>
<li><em><strong>一致性（Consistency）</strong></em>：是指事务操作前和操作后，数据满足完整性约束，数据库保持一致性状态  <code>由持久性+原子性+隔离性 共同保证</code></li>
<li><em><strong>隔离性（Isolation）</strong></em>：防止多个事务并发执行时由于交叉执行而导致数据的不一致   <code>MVCC（多版本并发控制） 或锁机制</code></li>
<li><em><strong>持久性（Durability）</strong></em>：事务处理结束后，对数据的修改就是永久的，即便系统故障也不会丢失。     <code>redo log （重做日志）</code><h3 id="3-2-并行事务的问题"><a href="#3-2-并行事务的问题" class="headerlink" title="3.2 并行事务的问题"></a>3.2 并行事务的问题</h3></li>
<li><strong>脏读</strong>： 一个事务「读到」了另一个「<strong>未提交事务修改过的数据</strong>」</li>
<li><strong>不可重复读</strong>：在一个事务内多次读取同一个数据，前后两次读到的<strong>数据</strong>不一样</li>
<li><strong>幻读</strong>：在一个事务内多次查询某个符合查询条件的「记录数量」，前后两次查询到的<strong>记录数量</strong>不一样<h3 id="3-3-事务的隔离级别"><a href="#3-3-事务的隔离级别" class="headerlink" title="3.3 事务的隔离级别"></a>3.3 事务的隔离级别</h3></li>
<li><strong>读未提交（<em>read uncommitted</em>）</strong>，指一个事务还没提交时，它做的变更就能被其他事务看到； <strong>会脏读</strong></li>
<li><strong>读提交（<em>read committed</em>）</strong>，指一个事务提交之后，它做的变更才能被其他事务看到； <strong>会不可重复读</strong></li>
<li><strong>可重复读（<em>repeatable read</em>）</strong>，指一个事务执行过程中看到的数据，一直跟这个事务启动时看到的数据是一致的，<strong>MySQL InnoDB 引擎的默认隔离级别</strong>； <strong>会幻读</strong></li>
<li><strong>串行化（<em>serializable</em> ）</strong>；会对记录加上读写锁，在多个事务对这条记录进行读写操作时，如果发生了读写冲突的时候，后访问的事务必须等前一个事务执行完成，才能继续执行；  都不会，但是影响性能</li>
<li><em>默认的隔离级别</em>：可重复读，用以下方法解决幻读<ul>
<li>针对<strong>快照读</strong>（普通 select 语句），是<strong>通过 MVCC 方式解决了幻读</strong></li>
<li>针对<strong>当前读</strong>（select … for update 等语句），是<strong>通过 next-key lock（记录锁+间隙锁）方式解决了幻读</strong></li>
</ul>
</li>
<li>幻读完全解决了吗？ 没有<ol>
<li>对于快照读，当事务 A 更新了一条事务 B 插入的记录，那么事务 A 前后两次查询的记录条目就不一样了，就会产生幻读</li>
<li>对于当前读，如果事务开启后，并没有执行当前读，而是先快照读，然后这期间如果其他事务插入了一条记录，那么事务后续使用当前读进行查询的时候，就会发现两次查询的记录条目就不一样了，所以就发生幻读。</li>
<li>在开启事务之后，马上执行 select … for update 这类当前读的语句</li>
</ol>
</li>
</ul>
<h3 id="3-4-MVCC-与-ReadView"><a href="#3-4-MVCC-与-ReadView" class="headerlink" title="3.4 MVCC 与 ReadView"></a>3.4 MVCC 与 ReadView</h3><ul>
<li><em>MVCC 原理</em>？<ul>
<li>Multi-Version Concurrency Control 多版本并发控制</li>
<li>核心思想是为每个事务创建一个独立的数据库快照，每个事务在操作时都会基于事务 ID 来访问数据库的对应版本</li>
</ul>
</li>
<li><em>ReadView 的数据结构</em>？  四个字段和聚簇索引记录中的两个隐藏列<ul>
<li><code>m_ids</code> ：指的是在创建 Read View 时，当前数据库中「活跃事务」的<strong>事务 id 列表</strong>，注意是一个列表，<strong>“活跃事务”指的就是，启动了但还没提交的事务</strong>。</li>
<li><code>min_trx_id</code> ：指的是在创建 Read View 时，当前数据库中「活跃事务」中事务 <strong>id 最小的事务</strong>，也就是 m_ids 的最小值。</li>
<li><code>max_trx_id</code> ：这个并不是 m_ids 的最大值，而是<strong>创建 Read View 时当前数据库中应该给下一个事务的 id 值</strong>，也就是全局事务中最大的事务 id 值 + 1；</li>
<li><code>creator_trx_id</code> ：指的是<strong>创建该 Read View 的事务的事务 id</strong>。</li>
<li><code>trx_id</code>，当一个事务对某条聚簇索引记录进行改动时，就会<strong>把该事务的事务 id 记录在 trx_id 隐藏列里</strong>；</li>
<li><code>roll_pointer</code>，每次对某条聚簇索引记录进行改动时，都会把旧版本的记录写入到 undo 日志中，然后<strong>这个隐藏列是个指针，指向每一个旧版本记录</strong>，于是就可以通过它找到修改前的记录。</li>
</ul>
</li>
<li><em>可重复读实现</em>？<ul>
<li>启动事务时生成一个 Read View，然后整个事务期间都在用这个 Read View</li>
</ul>
</li>
<li><em>读提交实现</em>？<ul>
<li>在每次读取数据时，都会生成一个新的 Read View</li>
</ul>
</li>
</ul>
<h2 id="4-锁"><a href="#4-锁" class="headerlink" title="4 锁"></a>4 锁</h2><h3 id="4-1-MySQL-有哪些锁？"><a href="#4-1-MySQL-有哪些锁？" class="headerlink" title="4.1 MySQL 有哪些锁？"></a>4.1 MySQL 有哪些锁？</h3><h4 id="4-1-1-全局锁"><a href="#4-1-1-全局锁" class="headerlink" title="4.1.1 全局锁"></a>4.1.1 全局锁</h4><ul>
<li><em>启用</em>：flush tables with read lock    数据库处于只读状态</li>
<li><em>使用场景</em>：全库备份</li>
<li>如果数据库的引擎支持的事务支持<strong>可重复读的隔离级别</strong>，那么在备份数据库之前先开启事务，会先创建 Read View，然后整个事务执行期间都在用这个 Read View，而且由于 MVCC 的支持，备份期间业务依然可以对数据进行更新操作<h4 id="4-1-2-表级锁"><a href="#4-1-2-表级锁" class="headerlink" title="4.1.2 表级锁"></a>4.1.2 表级锁</h4></li>
<li><em>表锁</em>：颗粒度太大，性能较差</li>
<li><em>元数据锁</em>：防止其他线程变更表结构</li>
<li><em>意向锁</em>：<strong>快速判断表里是否有记录被加锁</strong><ul>
<li>当执行插入、更新、删除操作，需要先对表加上「意向独占锁」，然后对该记录加独占锁</li>
</ul>
</li>
<li><em>AUTO-INC 锁</em>：实现主键自增<ul>
<li>在插入数据时，会加一个表级别的 AUTO-INC 锁，插入语句完成后就释放<h4 id="4-1-3-行级锁"><a href="#4-1-3-行级锁" class="headerlink" title="4.1.3 行级锁"></a>4.1.3 行级锁</h4></li>
</ul>
</li>
<li><em>Record Lock</em>：记录锁，锁住一条记录；只有 S 型记录锁兼容</li>
<li><em>Gap Lock</em>：间隙锁，解决可重复读隔离级别下的幻读现象； 如（3，5）会锁住 4</li>
<li><em>Next-Key Lock</em>：Record Lock + Gap Lock 的组合，锁定一个范围，并且锁定记录本身；（3，5] 锁住 4，5</li>
<li><em>插入意向锁</em>：插入有间隙锁位置会发生<strong>阻塞</strong>，生成一个<strong>插入意向锁</strong>，表明有事务想在某个区间插入新记录，但是现在处于等待状态</li>
<li>Innodb 在扫描记录的时，都是针对索引项这个单位去加锁的， update 不带索引就是全表扫描，也就是表里的索引项都加锁，相当于锁了整张表<h4 id="4-1-4-死锁"><a href="#4-1-4-死锁" class="headerlink" title="4.1.4 死锁"></a>4.1.4 死锁</h4></li>
<li>两个事务即使生成的间隙锁的范围是一样的，也不会发生冲突，因为间隙锁目的是为了防止其他事务插入数据，因此间隙锁与间隙锁之间是相互兼容的。</li>
<li>在执行插入语句时，如果插入的记录在其他事务持有间隙锁范围内，插入语句就会被阻塞，因为插入语句在碰到间隙锁时，会生成一个插入意向锁，然后插入意向锁和间隙锁之间是互斥的关系。</li>
<li>如果两个事务分别向对方持有的间隙锁范围内插入一条记录，而插入操作为了获取到插入意向锁，都在等待对方事务的间隙锁释放，于是就造成了循环等待，满足了死锁的四个条件：<strong>互斥、占有且等待、不可强占用、循环等待</strong>，因此发生了死锁</li>
<li>事务 A 和事务 B 在执行完后 update 语句后都持有范围为<code>(20, 30）</code>的间隙锁，而接下来的插入操作为了获取到插入意向锁，都在等待对方事务的间隙锁释放，于是就造成了循环等待</li>
</ul>
<h2 id="5-日志"><a href="#5-日志" class="headerlink" title="5 日志"></a>5 日志</h2><h3 id="5-1-undo-log（回滚日志）"><a href="#5-1-undo-log（回滚日志）" class="headerlink" title="5.1 undo log（回滚日志）"></a>5.1 undo log（回滚日志）</h3><ul>
<li>innodb 存储引擎层生成的日志，实现了事务中的 <em><strong>原子性</strong></em> ，主要用于事务回滚和 MVCC</li>
<li>当 InnoDB 引擎对一条记录进行操作（修改、删除、新增）时，要把回滚时需要的信息都记录到 undo log 里</li>
<li>在<code>事务没提交之前</code>，MySQL 会先记录更新前的数据到 undo log 日志文件里面</li>
<li><em>ReadView + undo log 实现 MVCC</em>：undo log 为每条记录保存多份历史数据，MySQL 在执行快照读（普通 select 语句）的时候，会根据事务的 Read View 里的信息，顺着 undo log 的<code>版本链</code>找到满足其<code>可见性</code>的记录</li>
<li>持久化：buffer pool 中有 undo 页，对 undo 页的修改也都会记录到<code>redo log</code>，redo log 会每秒刷盘，提交事务时也会刷盘<h3 id="5-2-Buffer-Pool-缓冲池"><a href="#5-2-Buffer-Pool-缓冲池" class="headerlink" title="5.2 Buffer Pool  缓冲池"></a>5.2 Buffer Pool  缓冲池</h3></li>
<li><em>基于内存，提高数据库的读写性能</em></li>
<li><em>Buffer Pool 缓存什么</em>：「索引页」和「数据页」，还包括了 Undo 页，插入缓存、自适应哈希索引、锁信息等</li>
<li>修改记录先缓存 到 change buffer，找机会去写入磁盘<pre><code>  1. 唯一索引不会用 change buffer，因为对应数据页已经加载到内存了--判断唯一性
  2. 优点：减少磁盘访问次数；提高内存利用率
</code></pre></li>
<li><strong>缓页管理方式</strong><pre><code>  1. Free List （空闲页链表），管理空闲页；
  2. Flush List （脏页链表），管理脏页；
  3. LRU List，管理脏页+干净页，将最近且经常查询的数据缓存在其中，而不常查询的数据就淘汰出去；分为 young 和 old 两个区域，先插入 old，被访问进入 young，解决数据批量访问，和大量热数据淘汰的问题；
</code></pre><h3 id="5-3-redo-log（物理日志）"><a href="#5-3-redo-log（物理日志）" class="headerlink" title="5.3 redo log（物理日志）"></a>5.3 redo log（物理日志）</h3></li>
<li>作用：记录了某个数据页做了什么修改，在事务提交时，只要先将 redo log 持久化到磁盘即可；记录了事务「<strong>完成后</strong>」的数据状态，记录的是更新<strong>之后</strong>的值</li>
<li><strong><em>预写日志WAL</em></strong>：写操作并不是立刻写到磁盘上，而是先写日志，后面再等待时机写入磁盘</li>
<li><strong><em>crash-safe</em></strong>（崩溃恢复）：即使数据库发生异常重启，之前已提交的记录都不会丢失，保证了持久性</li>
<li><strong>优点</strong>：redo log 是追加操作，所以是顺序写，开销更小</li>
<li><strong>刷盘时机</strong>： 事务提交；每秒；关闭数据库； redo log buffer占用过半</li>
<li>redo log满了？阻塞，刷新脏页到磁盘，擦除 对应的 redo log 记录腾出空间</li>
</ul>
<h3 id="5-4-bin-log"><a href="#5-4-bin-log" class="headerlink" title="5.4 bin log"></a>5.4 bin log</h3><ul>
<li>undo 和 redo 都是Innodb 存储引擎生成的，binlog 是 Server 层生成的</li>
<li>使用对象：Server 层实现的日志，所有存储引擎都可以使用</li>
<li>文件格式： STATEMENT（默认格式，记录 SQL）、ROW（记录行数据）、 MIXED</li>
<li>写入方式：追加写，会覆盖以前的日志，保存的是全量的日志。</li>
<li>作用：用于<strong>主从复制，备份恢复</strong></li>
<li>binlog cache刷盘：事务提交，内存超了</li>
<li><strong><em>主从复制实现</em></strong><ol>
<li><em>主从复制流程</em><ol>
<li><strong>写入 Binlog</strong>：主库写 binlog 日志，提交事务，并更新本地存储数据。</li>
<li><strong>同步 Binlog</strong>：把 binlog 复制到所有从库上，每个从库把 binlog 写到暂存日志中。</li>
<li><strong>回放 Binlog</strong>：回放 binlog，并更新存储引擎中的数据。</li>
</ol>
</li>
<li><em>复制步骤</em><ol>
<li>主节点log dump线程：当从节点连接主节点时，主节点会创建一个log dump 线程，用于发送bin-log的内容。在读取bin-log中的操作时，此线程会对主节点上的bin-log加锁，当读取完成，甚至在发动给从节点之前，锁会被释放。</li>
<li>从节点I/O线程：当从节点上执行<code>start slave</code>命令之后，从节点会创建一个I/O线程用来连接主节点，请求主库中更新的bin-log。I/O线程接收到主节点bin log dump 进程发来的更新之后，保存在本地relay-log中。</li>
<li>从节点SQL线程：SQL线程负责读取relay log中的内容，解析成具体的操作并执行，最终保证主从数据的一致性。</li>
</ol>
</li>
<li><em>复制模型</em><ol>
<li>同步复制：性能差</li>
<li>异步复制：主库宕机数据会丢失</li>
<li>半同步复制：从库成功一个就行</li>
</ol>
</li>
<li><em>主从同步延迟</em><ol>
<li>从库只有一个sql Thread，主库写压力大，复制很可能延时；或者从库有大型 query 产生锁等待</li>
<li>解决：要求高就走主库；sleep 一下；判断一下主备延迟</li>
</ol>
</li>
</ol>
</li>
<li><strong><em>两阶段提交</em></strong>    防止<strong>redo log</strong>和<strong>binlog</strong>不一致，导致主从数据不一致；内部 XA 事务<ol>
<li><strong><em>prepare</em> 阶段</strong>：将 redo log 对应的事务状态设置为 prepare，然后将 redo log 刷新到硬盘；</li>
<li><strong><em>commit 阶段</em></strong>：将 binlog 刷新到磁盘，接着调用引擎的提交事务接口，将 redo log 状态设置为 commit（将事务设置为 commit 状态后，刷入到磁盘 redo log 文件）；</li>
<li><strong>是否能在 binlog 中查找到与 redo log 相同的 XID</strong>，如果有就提交事务，如果没有就回滚事务。</li>
<li>组提交：<strong>有多个事务提交的时候，会将多个 binlog 刷盘操作合并成一个，从而减少磁盘 I/O 的次数</strong></li>
<li>问题：磁盘 IO 次数高，锁竞争激烈</li>
</ol>
</li>
</ul>
<h2 id="6-架构与-SQL-基础"><a href="#6-架构与-SQL-基础" class="headerlink" title="6 架构与 SQL 基础"></a>6 架构与 SQL 基础</h2><h3 id="6-1-SQL-基础"><a href="#6-1-SQL-基础" class="headerlink" title="6.1 SQL 基础"></a>6.1 SQL 基础</h3><ol>
<li><em>数据库四大范式</em><ol>
<li>第一范式（1NF）：属性不可拆分 或 无重复的列</li>
<li>第二范式（2NF）：非主属性对多属性候选键完全函数依赖</li>
<li>第三范式（3NF）：消除传递依赖  表中不包含已在其它表中已包含的非主属性信息。</li>
<li>BC范式（BCNF）：候选键存在多个属性时，多个主属性直接要消除传递依赖关系     主属性之间不应该有互相依赖。工号和身份证号是相互依赖。</li>
<li>第四范式（4NF）：对于候选键只能存在不超过1个多值属性。要求把同一表内的多对多关系删除。</li>
</ol>
</li>
<li><em>分页查询后期性能变慢的原因</em>    深分页问题<ol>
<li><strong>limit m n</strong>：查询从 m 开始的 n 条数据；扫 m+n 行 丢弃前 m 行</li>
<li><strong>limit n offset m</strong>：从 m 开始的 n 条</li>
<li><code>为什么慢</code>？ <ol>
<li>分页偏移量的增加，需要扫描和跳过的前面的行来到达指定的偏移量，造成浪费，也就是说<code>limit 100000,10</code>，就会扫描100010行</li>
<li><code>limit 100000,10</code> 扫描更多的行数，也意味着回表判断的次数更多</li>
</ol>
</li>
<li>优化：<ol>
<li>子查询优化：把条件转移到主键索引树，然后减少回表，比如先查到第 10000 个</li>
<li>INNER JOIN 延迟关联：先通过二级索引树查询到满足条件的主键ID，再与原表通过主键ID内连接</li>
<li>基于游标的分页：使用游标或主键来定位结果集中的特定行，而不是使用偏移量。这种方法通常比OFFSET更高效</li>
<li>使用between…and…：转换成已知位置的查询</li>
<li>使用合适的索引：确保查询中使用了适当的索引，以减少排序和过滤操作的成本</li>
</ol>
</li>
</ol>
</li>
<li>SQL(聚集函数，group by， having 子句， order by, 连接(内连接、外连接(左右)))<ol>
<li><strong>group by</strong>： 根据一个或多个列对结果集进行分组</li>
<li><strong>having</strong>：筛选分组后的各组数据    where在group by前， having在group by 之后</li>
<li><strong>order by</strong>：排序  desc 降序； asc 升序</li>
<li>连接：<ol>
<li>inner join：  只取交集</li>
<li>left join：左表所有行和右表匹配的，不匹配的行返回 null</li>
<li>right join：和上面类似</li>
<li>full join：全连接，取并集</li>
</ol>
</li>
</ol>
</li>
<li>慢查询日志<ol>
<li>set global slow_query_log = on;  long_query_time</li>
<li>mysqldumpslow进行分析<h3 id="6-2-架构"><a href="#6-2-架构" class="headerlink" title="6.2 架构"></a>6.2 架构</h3></li>
</ol>
</li>
<li>MySQL集群的结构有哪些？各自优缺点？<ol>
<li>主从架构  读写分离，数据备份</li>
<li>主主互备  </li>
</ol>
</li>
<li>分库分表的场景？   数据库性能瓶颈  <strong>IO瓶颈</strong>   <strong>CPU瓶颈</strong><ol>
<li>水平分库： 按 hash 或者 range 策略分到多个库里； 应对高并发</li>
<li>水平分表：将一个表中的数据拆分到多个表中；单表数据太多，影响 SQL 效率；</li>
<li>垂直分库：按业务归属不同分库；可以抽象出单独的业务模块</li>
<li>垂直分表：按照字段的活跃性，将表中字段拆到不同的表（主表和扩展表）中。  字段多，热点数据分离出来；不可用 join</li>
<li>分配策略： hash 取模；范围分片；地理位置；时间</li>
</ol>
</li>
<li>如何不停服迁移库表？<ol>
<li><strong>不停服，增加缓冲层（MQ），数据迁移过程中增量数据写入缓存，在数据迁移完成、缓冲层数据消费完成后，打开开关开始双写数据库</strong></li>
</ol>
</li>
<li>怎么分库分表才能均匀？分库分表后某些分片热点写入怎么解决？<ol>
<li>使用哈希算法：对于分片键（通常是某个列或多个列的组合），使用哈希算法来决定数据应该存储在哪个分片上。这样可以确保数据在分片之间均匀分布，减少热点问题。</li>
<li>增加分片数量：**如果你发现某些分片写入热点问题，可以考虑增加分片的数量。这会增加分片的数量，减少每个分片的负载，提高了吞吐量。</li>
<li>负载均衡：使用负载均衡策略来确保访问请求均匀地分布到不同的分片上。负载均衡可以在应用层或数据库代理层实现。</li>
<li>随机数分片：使用随机数来分配数据到分片，这可以减少数据的热点写入问题，但可能增加查询的复杂性。</li>
<li>分片键设计：精心设计分片键是解决热点写入问题的关键。尽量避免选择容易导致热点的分片键，例如自增主键。</li>
<li>数据迁移：定期监测数据分布，如果发现某个分片过于热点，可以考虑进行数据迁移，将一些数据从热点分片移到其他分片上，以实现负载均衡。</li>
<li>垂直分片：考虑将表按照功能或业务需求进行垂直分片，将不同类型的数据存储在不同的分片上。这可以减少写入热点问题。</li>
<li>缓存：使用缓存来缓解数据库写入压力。将热点数据缓存到内存中，减少对数据库的频繁写入请求。</li>
<li>异步写入：如果一些写入操作不需要立即生效，可以考虑将它们异步化，以减轻数据库的写入负载。例如，使用消息队列将写入操作异步处理。</li>
</ol>
</li>
<li>数据库主库挂了，在存在主从延时的情况下，切从的过程中，查询的数据不一致怎么处理<ol>
<li><strong>等待同步完成</strong>：在进行主从切换前，可以等待从库追赶主库的进度，确保从库的数据已经和主库同步完全。这可以通过监测主从延时来确定。一旦主从延时减少到可以接受的水平，再进行切换。</li>
<li><strong>切换到可用从库</strong>：如果主从切换后发现某个从库数据不一致，可以尝试切换到另一个可用的从库。这需要确保备用从库与主库的数据同步是正常的。</li>
<li><strong>手动同步数据</strong>：在切换完成后，可以考虑手动同步数据以修复不一致。这可能涉及将缺失的数据从主库手动导入到从库，以确保一致性。</li>
<li><strong>数据一致性检查</strong>：在切换后，可以运行一些数据一致性检查工具或脚本来检查数据是否一致。如果发现不一致的数据，可以进行修复。</li>
<li><strong>定期备份</strong>：在数据库正常运行期间，定期进行数据库备份，包括主库和从库。在切换后，如果出现数据不一致问题，可以使用备份进行恢复。</li>
<li><strong>容错和监控</strong>：实现主从切换时，确保有足够的监控和容错机制。这样，如果出现问题，可以迅速发现并采取措施来减小数据不一致的风险。</li>
<li><strong>故障回滚</strong>：如果切换后发现数据不一致问题无法解决，可以考虑回滚到原来的主库，然后采取更谨慎的方式来进行切换，例如逐渐减小主从延时。</li>
</ol>
</li>
</ol>

    
    
  </div>

  

  

</article>
  
  <article class="post">
  <header class="post-header">
    <h1 class="post-title">
      
      <a class="post-link" href="/2023/09/09/Framework/Kafka/">[Framework] Kafka</a>
      
    </h1>

    <div class="post-meta">
      <span class="post-time">
        2023-09-09
      </span>
      
      
      
    </div>
  </header>

  

  <div class="post-content">
    
    
    

    
    <span id="more"></span>
<h2 id="1-Kafka-基础"><a href="#1-Kafka-基础" class="headerlink" title="1 Kafka 基础"></a>1 Kafka 基础</h2><h3 id="1-1-架构"><a href="#1-1-架构" class="headerlink" title="1.1 架构"></a>1.1 架构</h3><blockquote>
<p>分布式的、分区化、可复制提交的日志服务<br><img src="https://pic1.zhimg.com/80/v2-672b6f858c187b5c8182c553cd597f14_1440w.webp" alt=""></p>
<ul>
<li><em>Producer</em>：消息生产者，就是向 kafka broker 发消息的客户端。</li>
<li><em>Consumer</em> ：消息消费者，向 kafka broker 取消息的客户端。</li>
<li><em>Topic</em> ：可以理解为一个队列，一个 Topic 又分为一个或多个分区。</li>
<li><em>Consumer Group</em>：这是 kafka 用来实现一个 topic 消息的广播（发给所有的 consumer）和单播（发给任意一个 consumer）的手段。一个 topic 可以有多个 Consumer Group。</li>
<li><em>Broker</em> ：一台 kafka 服务器就是一个 broker。一个集群由多个 broker 组成。一个 broker 可以容纳多个 topic。</li>
<li><em>Partition</em>：为了实现扩展性，一个非常大的 topic 可以分布到多个 broker上，每个 partition 是一个有序的队列。partition 中的每条消息都会被分配一个有序的id（offset）。将消息发给 consumer，kafka 只保证按一个 partition 中的消息的顺序，不保证一个 topic 的整体（多个 partition 间）的顺序。</li>
<li><em>Offset</em>：kafka 的存储文件都是按照 offset.kafka 来命名，用 offset 做名字的好处是方便查找。例如你想找位于 2049 的位置，只要找到 2048.kafka 的文件即可。当然 the first offset 就是00000000000.kafka。<h3 id="1-2-特点"><a href="#1-2-特点" class="headerlink" title="1.2 特点"></a>1.2 特点</h3></li>
<li><em>高吞吐量、低延迟</em>：每秒可以处理几十万条消息，它的延迟最低只有几毫秒，每个topic可以分多个partition, consumer group 对partition进行consume操作。</li>
<li><em>可扩展性</em>：kafka集群支持热扩展</li>
<li><em>持久性、可靠性</em>：消息被持久化到本地磁盘，并且支持数据备份防止数据丢失</li>
<li><em>容错性</em>：允许集群中节点失败（若副本数量为n,则允许n-1个节点失败）</li>
<li><em>高并发</em>：支持数千个客户端同时读写<h3 id="1-3-怎么实现高吞吐量的？"><a href="#1-3-怎么实现高吞吐量的？" class="headerlink" title="1.3 怎么实现高吞吐量的？"></a>1.3 怎么实现高吞吐量的？</h3></li>
<li><em>分区</em>：多分区通过负载均衡提高了消息并发写入和消费的能力</li>
<li><em>批量发送和压缩消息</em>：<ul>
<li><code>批量发送</code>：将消息缓存在内存中的双端队列中，然后Sender线程将从各分区对应的队列中获取已准备好的消息批次，将消息进行批量发送，减少网络传输频次，提高传输效率。</li>
<li><code>端到端压缩消息</code>：将一批消息打包后进行压缩，在 Consumer 端进行解压</li>
</ul>
</li>
<li><em>顺序读写</em>：将消息messaga追加到本地磁盘文件的末尾</li>
<li><em>零拷贝ZeroCopy</em>：将数据直接从磁盘文件复制到网卡设备中，避免重新复制数据<ul>
<li>操作系统从磁盘读取数据到内核空间的 pagecache</li>
<li>应用程序读取内核空间的数据到用户空间的缓冲区</li>
<li>应用程序将数据(用户空间的缓冲区)写回内核空间到套接字缓冲区(内核空间)</li>
<li>操作系统将数据从套接字缓冲区(内核空间)复制到通过网络发送的 NIC 缓冲区</li>
</ul>
</li>
<li><em>PageCache</em>：利用了现代操作系统分页存储 Page Cache 来利用内存提高 I/O 效率<h3 id="1-4-高可靠性实现"><a href="#1-4-高可靠性实现" class="headerlink" title="1.4 高可靠性实现"></a>1.4 高可靠性实现</h3></li>
<li>副本机制</li>
<li><h3 id="1-5-使用场景"><a href="#1-5-使用场景" class="headerlink" title="1.5 使用场景"></a>1.5 使用场景</h3></li>
<li>日志收集</li>
<li>消息系统</li>
<li>用户活动跟踪<h2 id="2-主题与日志"><a href="#2-主题与日志" class="headerlink" title="2 主题与日志"></a>2 主题与日志</h2><h3 id="2-1-Kafka创建Topic时如何将分区放置到不同的Broker中"><a href="#2-1-Kafka创建Topic时如何将分区放置到不同的Broker中" class="headerlink" title="2.1 Kafka创建Topic时如何将分区放置到不同的Broker中"></a>2.1 Kafka创建Topic时如何将分区放置到不同的Broker中</h3></li>
<li>副本因子不能大于 Broker 的个数；</li>
<li>第一个分区（编号为0）的第一个副本放置位置是随机从 brokerList 选择的；</li>
<li>其他分区的第一个副本放置位置相对于第0个分区依次往后移。也就是如果我们有5个 Broker，5个分区，假设第一个分区放在第四个 Broker 上，那么第二个分区将会放在第五个 Broker 上；第三个分区将会放在第一个 Broker 上；第四个分区将会放在第二个 Broker 上，依次类推；</li>
<li>剩余的副本相对于第一个副本放置位置其实是由 nextReplicaShift 决定的，而这个数也是随机产生的<h3 id="2-2-Kafka-分区数可以增加或减少吗？为什么？"><a href="#2-2-Kafka-分区数可以增加或减少吗？为什么？" class="headerlink" title="2.2 Kafka 分区数可以增加或减少吗？为什么？"></a>2.2 Kafka 分区数可以增加或减少吗？为什么？</h3></li>
<li>可以使用 bin/kafka-topics.sh命令对 Kafka 增加 Kafka 的分区数据，但是 Kafka 不支持减少分区数。</li>
<li>Kafka 分区数据不支持减少是由很多原因的，比如减少的分区其数据放到哪里去？是删除，还是保留？删除的话，那么这些没消费的消息不就丢了。如果保留这些消息如何放到其他分区里面？追加到其他分区后面的话那么就破坏了 Kafka 单个分区的有序性。如果要保证删除分区数据插入到其他分区保证有序性，那么实现起来逻辑就会非常复杂</li>
<li>会在含有分区目录最少的文件夹中创建新的分区目录<h3 id="2-3-kafka分区是不是越多越好"><a href="#2-3-kafka分区是不是越多越好" class="headerlink" title="2.3 kafka分区是不是越多越好"></a>2.3 kafka分区是不是越多越好</h3></li>
<li>句柄开销过大：每增加一个分区，对应的也会增加一个文件描述符，而一个进程所能支配的文件描述符是有限的，这也就是通常说的文件句柄开销。当分区数量超过进程能支配的文件描述符数量时，将出现 <code>Too many open files</code>错误.</li>
<li>生产端占用内存过大：kafka 发送消息时不是立刻发送的，而是会先将每个分区的消息先进行缓存（缓存区大小由<code>batch.size</code>设置，默认16KB），缓存满了后才会发送消息。分区越多的情况下，分区占用的缓存区也将更大。</li>
<li>影响系统可用性：broker数量一定的情况下，分区数量越大则每个broker 中所拥有的分区leader副本数量也将更多。broker出现故障后需要进行leader角色切换的分区数量会很大，导致故障恢复时间较长。<h2 id="3-Producer"><a href="#3-Producer" class="headerlink" title="3 Producer"></a>3 Producer</h2><h3 id="3-1-消息分区选择"><a href="#3-1-消息分区选择" class="headerlink" title="3.1 消息分区选择"></a>3.1 消息分区选择</h3><h3 id="3-2-Kafka-分区的目的？"><a href="#3-2-Kafka-分区的目的？" class="headerlink" title="3.2 Kafka 分区的目的？"></a>3.2 Kafka 分区的目的？</h3>分区对于 Kafka 集群的好处是：实现负载均衡。分区对于消费者来说，可以提高并发度，提高效率。<h3 id="3-3-ack参数设置及意义"><a href="#3-3-ack参数设置及意义" class="headerlink" title="3.3 ack参数设置及意义"></a>3.3 ack参数设置及意义</h3>参数设置： 设置 <code>request.required.acks=-1</code> ，只有 ISR 中所有副本都成功写入消息后才认为 kafka 消息成功写入。acks 参数其他配置项意义如下：</li>
<li><code>acks = 1</code>(默认)：分区leader 副本写入成功即认为消息成功写入，只确保leader发送成功</li>
<li><code>acks = 0</code> ：不需要等待任何服务端的响应都可认为消息成功写入，安全性最低但是效率最高。</li>
<li><code>acks = -1/ all</code> ：代表producer往集群发送数据需要所有的follower都完成从leader的同步才会发送下一条，确保 leader发送成功和所有的副本都完成备份。<h3 id="3-4-幂等特性"><a href="#3-4-幂等特性" class="headerlink" title="3.4 幂等特性"></a>3.4 幂等特性</h3></li>
<li>一次或者多次请求某一个资源对于资源本身应该具有同样的结果</li>
<li><strong>唯一标识</strong>：判断某个请求是否重复，需要有一个唯一性标识，然后服务端就能根据这个唯一标识来判断是否为重复请求。</li>
<li><strong>记录已经处理过的请求</strong>：服务端需要记录已经处理过的请求，然后根据唯一标识来判断是否是重复请求，如果已经处理过，则直接拒绝或者不做任何操作返回成功。</li>
<li>只能保证生产端在单个会话内的幂等，如果生产端因为某些原因意外挂掉然后重启，此时是没办法保证幂等的，因为这时没办法获取到之前的状态信息，即无法做到跨会话级别的幂等。</li>
<li>幂等性不能跨多个主题分区，只能保证单个分区内的幂等，涉及到多个消息分区时，中间的状态并没有同步<h3 id="3-5-Kafka-是如何做到消息的有序性？"><a href="#3-5-Kafka-是如何做到消息的有序性？" class="headerlink" title="3.5 Kafka 是如何做到消息的有序性？"></a>3.5 Kafka 是如何做到消息的有序性？</h3></li>
<li>kafka 中的每个 partition 中的消息在写入时都是有序的，而且单独一个 partition 只能由一个消费者去消费，可以在里面保证消息的顺序性。但是分区之间的消息是不保证有序的。</li>
<li>设置一个topic一个partition，消费者单线程消费</li>
<li>消息发送指定key，确保相同key的消息发送到同一个partition<h3 id="3-6-Kafka如何保证消息不丢失"><a href="#3-6-Kafka如何保证消息不丢失" class="headerlink" title="3.6 Kafka如何保证消息不丢失"></a>3.6 Kafka如何保证消息不丢失</h3></li>
<li><em>生产者</em>：ACK 机制</li>
<li><em>broker</em>：多副本和副本同步机制；保证ISR副本数量大于等于二</li>
<li><em>消费者</em>：<ul>
<li>消息消费关闭自动提交，改为手动提交offset，确保消息可再次消费</li>
<li>在第一点的前提下，涉及到消息的重复消费，所以消费端应做好消息的幂等处理<h3 id="3-7-Kafka-Producer-的执行过程？"><a href="#3-7-Kafka-Producer-的执行过程？" class="headerlink" title="3.7 Kafka Producer 的执行过程？"></a>3.7 Kafka Producer 的执行过程？</h3></li>
</ul>
</li>
<li>Producer生产消息</li>
<li>从Zookeeper找到Partition的Leader</li>
<li>推送消息</li>
<li>通过ISR列表通知给Follower</li>
<li>Follower从Leader拉取消息，并发送ack</li>
<li>Leader收到所有副本的ack，更新Offset，并向Producer发送ack，表示消息写入成功。<h3 id="3-8-Kafka消息是采用Pull模式，还是Push模式？"><a href="#3-8-Kafka消息是采用Pull模式，还是Push模式？" class="headerlink" title="3.8 Kafka消息是采用Pull模式，还是Push模式？"></a>3.8 Kafka消息是采用Pull模式，还是Push模式？</h3></li>
<li>producer将消息推送到broker，consumer从broker拉取消息</li>
<li>consumer可以自主的根据消费能力和策略决定是否批量的从broker拉取数据<h3 id="3-9-如何保证消息不被重复消费？"><a href="#3-9-如何保证消息不被重复消费？" class="headerlink" title="3.9 如何保证消息不被重复消费？"></a>3.9 如何保证消息不被重复消费？</h3></li>
<li>生产者在向Kafka写数据时，每条消息会有一个offset，表示消息写入顺序的序号。当消费者消费后，<strong>每隔一段时间会把自己已消费消息的offset通过Zookeeper提交给Kafka</strong>，告知Kafka自己offset的位置。这样一来，如果消费者重启，则会从Kafka记录的offset之后的数据开始消费，从而避免重复消费。</li>
<li>在发生重复消费后，如何<strong>保证消息消费时的幂等性</strong>。如果消费者可以在消费消息时先判断一下，自己是否已经消费了该消息，如果是就不消费，那么就可以保证系统的幂等性。<ul>
<li>数据库查询</li>
<li>redis 用 set 去重</li>
<li>全局 id</li>
</ul>
</li>
</ul>
</blockquote>
<h2 id="4-Consumer"><a href="#4-Consumer" class="headerlink" title="4 Consumer"></a>4 Consumer</h2><h3 id="4-1-消费组"><a href="#4-1-消费组" class="headerlink" title="4.1 消费组"></a>4.1 消费组</h3><ul>
<li>多个消费者可以组成一个消费组，每个消费者只属于一个消费组。</li>
<li>消费组订阅主题的每个分区只会分配给该消费组中的某个消费者处理，不同的消费组之间彼此隔离无依赖。</li>
<li>同一个消息只会被消费组中的一个消费者消费，如果想要让同一个消息被多个消费者消费，那么每个消费者需要属于不同的消费组，且对应消费组中只有该一个消费者，消费组的引入可以实现消费的“独占”或“广播”效果。<h3 id="4-2-重平衡机制"><a href="#4-2-重平衡机制" class="headerlink" title="4.2 重平衡机制"></a>4.2 重平衡机制</h3></li>
<li><em>触发条件</em>：<ul>
<li>消费者数量变化： 新消费者加入、消费者下线、消费者主动退出消费组</li>
<li>消费组内订阅的主题或者主题的分区数量发生变化</li>
<li>消费组对应的 GroupCoorinator 节点发生变化</li>
</ul>
</li>
<li><em>rebalance过程</em>：<ul>
<li>寻找到消费组的 协调者(GroupCoordination)，消费者组提交组位移的 partiotion 所在的 broker</li>
<li>所有消费者向协调者发送 JoinGroup 请求</li>
<li>协调者为消费组选择新的leader</li>
<li>协调者发送 <code>JoinGroupResponse</code> 给各个消费组，其中leader消费者的 <code>JoinGroupResponse</code> 包含了消费组成员信息</li>
<li>leader消费者指定新的消费方案</li>
<li>各消费者向 协调者 发送 <code>SyncGroupRequest</code> 请求，其中 leader消费者的<code>SyncGroupRequest</code> 携带有相关的分配方案</li>
<li>协调者向各消费者下发分区分配方案</li>
</ul>
</li>
<li><em>避免非必要rebalance</em> ：设置合理的心跳发送时间；设置Consumer 消费时间最大间隔<h3 id="4-3-Kafka-消费者是否可以消费指定分区消息？"><a href="#4-3-Kafka-消费者是否可以消费指定分区消息？" class="headerlink" title="4.3 Kafka 消费者是否可以消费指定分区消息？"></a>4.3 Kafka 消费者是否可以消费指定分区消息？</h3>Kafa consumer消费消息时，向broker发出fetch请求去消费特定分区的消息，consumer指定消息在日志中的偏移量（offset），就可以消费从这个位置开始的消息，customer拥有了offset的控制权，可以向后回滚去重新消费之前的消息，这是很有意义的。<h3 id="4-4-讲一下-Kafka-Consumer-消费消息时的线程模型，为何如此设计？"><a href="#4-4-讲一下-Kafka-Consumer-消费消息时的线程模型，为何如此设计？" class="headerlink" title="4.4 讲一下 Kafka Consumer 消费消息时的线程模型，为何如此设计？"></a>4.4 讲一下 Kafka Consumer 消费消息时的线程模型，为何如此设计？</h3>Thread-Per-Consumer Model，这种多线程模型是利用Kafka的topic分多个partition的机制来实现并行：每个线程都有自己的consumer实例，负责消费若干个partition。各个线程之间是完全独立的，不涉及任何线程同步和同学通信，所以实现起来非常简单。<h2 id="5-副本"><a href="#5-副本" class="headerlink" title="5 副本"></a>5 副本</h2><h3 id="5-1-ISR集合-AR-OSR"><a href="#5-1-ISR集合-AR-OSR" class="headerlink" title="5.1 ISR集合,AR,OSR"></a>5.1 ISR集合,AR,OSR</h3></li>
<li><em>In-Sync Replicas 副本同步队列</em>，表示可用的副本集合，也就是和主副本差距不大</li>
<li>ISR 是由 leader 维护，follower从leader 同步数据有一些延迟（包括延迟时间和延迟条数）, 任意一个超过阈值都会把follower剔除出ISR, 存入OSR（Outof-Sync Replicas）列表，新加入的follower也会先存放在OSR中。AR=ISR+OSR</li>
<li>主要是解决<code>同步副本</code>与<code>异步复制</code>两种方案各自的缺陷<h3 id="5-2-HW-amp-LEO"><a href="#5-2-HW-amp-LEO" class="headerlink" title="5.2 HW&amp;LEO"></a>5.2 HW&amp;LEO</h3></li>
<li>HW（High Watermark）：消费端消费时只能拉取到小于HW的消息而HW及之后的消息对于消费者来说是不可见的，保证HW之前消息的可靠性</li>
<li>LEO（Log End Offset）：表示当前副本最新消息的下一个offset<h3 id="5-3-leader-epoch机制"><a href="#5-3-leader-epoch机制" class="headerlink" title="5.3 leader epoch机制"></a>5.3 leader epoch机制</h3>leader epoch表示一个键值对<epoch, offset>，其中epoch表示leader主副本的版本号，从0开始编码，当leader每变更一次就会+1，offset表示该epoch版本的主副本写入第一条消息的位置，比如<0,0>表示第一个主副本从位移0开始写入消息，<1,100>表示第二个主副本版本号为1并从位移100开始写入消息，主副本会将该信息保存在缓存中并定期写入到checkpoint文件中，每次发生主副本切换都会去从缓存中查询该信息<h2 id="6-拾遗"><a href="#6-拾遗" class="headerlink" title="6 拾遗"></a>6 拾遗</h2></li>
</ul>
<h3 id="6-1-除了kafka-还用过哪些消息队列-他和kafka-有哪些区别，优劣"><a href="#6-1-除了kafka-还用过哪些消息队列-他和kafka-有哪些区别，优劣" class="headerlink" title="6.1 除了kafka 还用过哪些消息队列 他和kafka 有哪些区别，优劣"></a>6.1 除了kafka 还用过哪些消息队列 他和kafka 有哪些区别，优劣</h3><h3 id="6-2-Kafka-高效文件存储设计特点"><a href="#6-2-Kafka-高效文件存储设计特点" class="headerlink" title="6.2 Kafka 高效文件存储设计特点"></a>6.2 Kafka 高效文件存储设计特点</h3><ul>
<li>Kafka把topic中一个parition大文件分成多个小文件段，通过多个小文件段，就容易定期清除或删除已经消费完文件，减少磁盘占用。</li>
<li>通过索引信息可以快速定位message和确定 response的最大大小。</li>
<li>通过index元数据全部映射到memory，可以避免segment file的IO磁盘操作。</li>
<li>通过索引文件稀疏存储，可以大幅降低 index 文件元数据占用空间大小</li>
</ul>
<h3 id="6-3-Kafka-数据一致性原理"><a href="#6-3-Kafka-数据一致性原理" class="headerlink" title="6.3 Kafka 数据一致性原理"></a>6.3 Kafka 数据一致性原理</h3><ul>
<li>一致性就是说不论是老的 Leader 还是新选举的 Leader，Consumer 都能读到一样的数据。</li>
<li>假设分区的副本为3，其中副本0是 Leader，副本1和副本2是 follower，并且在 ISR 列表里面。虽然副本0已经写入了 Message4，但是 Consumer 只能读取到 Message2。因为所有的 ISR 都同步了 Message2，只有 High Water Mark 以上的消息才支持 Consumer 读取，而 High Water Mark 取决于 ISR 列表里面偏移量最小的分区，类似于<strong>木桶原理</strong>。</li>
<li>还没有被足够多副本复制的消息被认为是“不安全”的，如果 Leader 发生崩溃，另一个副本成为新 Leader，那么这些消息很可能丢失了。如果我们允许消费者读取这些消息，可能就会破坏一致性。试想，一个消费者从当前 Leader（副本0） 读取并处理了 Message4，这个时候 Leader 挂掉了，选举了副本1为新的 Leader，这时候另一个消费者再去从新的 Leader 读取消息，发现这个消息其实并不存在，这就导致了数据不一致性问题。</li>
</ul>
<h3 id="6-4-数据传输的事务有几种？"><a href="#6-4-数据传输的事务有几种？" class="headerlink" title="6.4 数据传输的事务有几种？"></a>6.4 数据传输的事务有几种？</h3><ul>
<li>数据传输的事务定义通常有以下三种级别：</li>
<li>最多一次: 消息不会被重复发送，最多被传输一次，但也有可能一次不传输 </li>
<li>最少一次: 消息不会被漏发送，最少被传输一次，但也有可能被重复传输.</li>
<li>精确的一次（Exactly once）: 不会漏传输也不会重复传输,每个消息都传输被</li>
</ul>
<h3 id="6-5-kafka为什么不需要支持读写分离"><a href="#6-5-kafka为什么不需要支持读写分离" class="headerlink" title="6.5 kafka为什么不需要支持读写分离"></a>6.5 kafka为什么不需要支持读写分离</h3><ul>
<li>读写均衡</li>
<li>分区，压力都不大</li>
</ul>
<h3 id="6-6-Kafka-中-zookeeper-的作用？它是如何保证-kafka-高可用的？主节点选举机制？"><a href="#6-6-Kafka-中-zookeeper-的作用？它是如何保证-kafka-高可用的？主节点选举机制？" class="headerlink" title="6.6 Kafka 中 zookeeper 的作用？它是如何保证 kafka 高可用的？主节点选举机制？"></a>6.6 Kafka 中 zookeeper 的作用？它是如何保证 kafka 高可用的？主节点选举机制？</h3><ol>
<li>用于在集群中不同节点之间进行通信</li>
<li>提交偏移量</li>
<li>leader 检测、分布式同步、配置管理、识别新节点何时离开或连接、集群、节点实时状态<h3 id="6-7-使用-kafka-的时候，如何确定一个-topic-的-partition-数量？"><a href="#6-7-使用-kafka-的时候，如何确定一个-topic-的-partition-数量？" class="headerlink" title="6.7 使用 kafka 的时候，如何确定一个 topic 的 partition 数量？"></a>6.7 使用 kafka 的时候，如何确定一个 topic 的 partition 数量？</h3></li>
<li>单台broker上partition数量不超过4000, 整个集群partition数量不超过2000,000</li>
<li>更多的Partition可能导致不可用时间增长；增加端到端的延迟；使用过多的内存<h3 id="6-8-kafka消息积压如何处理"><a href="#6-8-kafka消息积压如何处理" class="headerlink" title="6.8 kafka消息积压如何处理"></a>6.8 kafka消息积压如何处理</h3></li>
</ol>
<ul>
<li>问题定位：<ul>
<li>消息生产端数据量是否存在陡升的情况</li>
<li>消息消费端消费能力是否有下降</li>
<li>消息积压是发生在所有的partition还是所有的partition都有积压情况</li>
</ul>
</li>
<li>解决：<ul>
<li>前两个可以多线程，批量消费等提高消费速度</li>
<li>后者<ul>
<li>新建一个 topic，partition 是原来的 10 倍，临时建立好原先 10 倍的 queue 数量</li>
<li>然后写一个临时的分发数据的 consumer 程序，这个程序部署上去消费积压的数据，<strong>消费之后不做耗时的处理</strong>，直接均匀轮询写入临时建立好的 10 倍数量的 queue</li>
<li>接着临时征用 10 倍的机器来部署 consumer，每一批 consumer 消费一个临时 queue 的数据。这种做法相当于是临时将 queue 资源和 consumer 资源扩大 10 倍，以正常的 10 倍速度来消费数据</li>
<li>等快速消费完积压数据之后，<strong>得恢复原先部署的架构</strong>，<strong>重新</strong>用原先的 consumer 机器来消费消息</li>
</ul>
</li>
</ul>
</li>
</ul>

    
    
  </div>

  

  

</article>
  
  <article class="post">
  <header class="post-header">
    <h1 class="post-title">
      
      <a class="post-link" href="/2023/09/05/Framework/Redis/">[Framework] Redis</a>
      
    </h1>

    <div class="post-meta">
      <span class="post-time">
        2023-09-05
      </span>
      
      
      
    </div>
  </header>

  

  <div class="post-content">
    
    
    

    
    <span id="more"></span>
<h2 id="1-基础知识"><a href="#1-基础知识" class="headerlink" title="1 基础知识"></a>1 基础知识</h2><h3 id="1-1-简介"><a href="#1-1-简介" class="headerlink" title="1.1 简介"></a>1.1 简介</h3><ul>
<li>Redis 为什么快：基于<code>内存</code>的数据库，单线程执行命令，没有并发问题，QPS 能轻松破 10w； I/O 多路复用机制；还有就是实现的数据结构能高效的处理数据操作；</li>
<li>使用场景：<strong>缓存，消息队列、分布式锁等场景</strong>。<h3 id="1-2-线程模型"><a href="#1-2-线程模型" class="headerlink" title="1.2 线程模型"></a>1.2 线程模型</h3><h4 id="1-2-1-Redis-是单线程吗？"><a href="#1-2-1-Redis-是单线程吗？" class="headerlink" title="1.2.1 Redis 是单线程吗？"></a>1.2.1 Redis 是单线程吗？</h4></li>
<li>接收客户端请求-&gt;解析请求 -&gt;进行数据读写等操作-&gt;发送数据给客户端 是单线程完成的</li>
<li>会启动后台线程（BIO）：<ul>
<li>2.6 版本：两个线程分别处理<code>关闭文件</code>、<code>AOF 刷盘</code></li>
<li>4.0 版本：新增lazyfree 线程，异步释放内存，避免 del 大 key 卡顿主线程,应该用 <code>unlink</code> 命令<code>异步删除</code>大 key<h4 id="1-2-2-单线程模式是怎样的？"><a href="#1-2-2-单线程模式是怎样的？" class="headerlink" title="1.2.2 单线程模式是怎样的？"></a>1.2.2 单线程模式是怎样的？</h4></li>
</ul>
</li>
<li>调用 epoll_create() 创建一个 epoll 对象和调用 socket() 创建一个服务端 socket</li>
<li>调用 bind() 绑定端口和调用 listen() 监听该 socket</li>
<li>将调用 epoll_ctl() 将 listen socket 加入到 epoll，同时注册「连接事件」处理函数</li>
<li>先调用<strong>处理发送队列函数</strong>，看是发送队列里是否有任务，如果有发送任务，则通过 write 函数将客户端发送缓存区里的数据发送出去，如果这一轮数据没有发送完，就会注册写事件处理函数，等待 epoll_wait 发现可写后再处理</li>
<li>调用 epoll_wait 函数等待事件的到来：<strong>连接事件</strong>，<strong>读事件</strong>，<strong>写事件</strong><h4 id="1-2-3-单线程模式为什么快？"><a href="#1-2-3-单线程模式为什么快？" class="headerlink" title="1.2.3 单线程模式为什么快？"></a>1.2.3 单线程模式为什么快？</h4></li>
<li>大部分操作都在<code>内存</code>中完成，并且采用了<code>高效的数据结构</code>，因此 Redis <code>瓶颈</code>可能是机器的内存或者网络带宽，而并非 CPU</li>
<li>采用单线程模型可以避免了多线程之间的竞争和切换带来的开销</li>
<li>采用了<code>I/O 多路复用机制</code>处理大量的客户端 Socket 请求，IO 多路复用机制是指一个线程处理多个 IO 流，就是我们经常听到的 select/epoll 机制。简单来说，在 Redis 只运行单线程的情况下，该机制允许内核中，同时存在多个监听 Socket 和已连接 Socket。内核会一直监听这些 Socket 上的<code>连接请求或数据请求</code>。一旦有请求到达，就会交给 Redis 线程处理，这就实现了一个 Redis 线程处理多个 IO 流的效果<h4 id="1-2-4-为什么引入多线程？"><a href="#1-2-4-为什么引入多线程？" class="headerlink" title="1.2.4 为什么引入多线程？"></a>1.2.4 为什么引入多线程？</h4></li>
<li>采用了多个 I/O 线程来处理网络请求，这是因为随着网络硬件的性能提升，Redis 的性能瓶颈有时会出现在<code>网络 I/O</code> 的处理上。 ^6bcb8c</li>
<li><strong>命令的执行，Redis 仍然使用单线程来处理</strong><h2 id="2-2-数据类型和结构"><a href="#2-2-数据类型和结构" class="headerlink" title="2 2.数据类型和结构"></a>2 2.数据类型和结构</h2><h3 id="2-1-数据类型和使用场景"><a href="#2-1-数据类型和使用场景" class="headerlink" title="2.1 数据类型和使用场景"></a>2.1 数据类型和使用场景</h3><h4 id="2-1-1-String-字符串"><a href="#2-1-1-String-字符串" class="headerlink" title="2.1.1 String 字符串"></a>2.1.1 String 字符串</h4></li>
<li><em>介绍</em>：key-value 结构,最大 512M</li>
<li><em>内部实现</em>：int 和 <code>SDS 简单动态字符串</code> </li>
<li><em>使用场景</em>：缓存对象、常规计数、分布式锁、共享 session 信息等</li>
<li><em>分布式锁</em>：SETNX  「key不存在才插入」<h4 id="2-1-2-List-列表"><a href="#2-1-2-List-列表" class="headerlink" title="2.1.2 List 列表"></a>2.1.2 List 列表</h4></li>
<li><em>介绍</em>：简单的字符串列表,最大长度为 <code>2^32 - 1</code>   40亿</li>
<li><em>内部实现</em>：<ul>
<li><code>压缩列表</code>：列表元素小于 512 个，且都小于 64 字节</li>
<li><code>双向链表</code>：不满足以上</li>
<li><code>quicklist</code>：Redis3.2 版本后</li>
</ul>
</li>
<li><em>使用场景</em>：消息队列<h4 id="2-1-3-Hash"><a href="#2-1-3-Hash" class="headerlink" title="2.1.3 Hash"></a>2.1.3 Hash</h4></li>
<li><em>介绍</em>：键值对集合</li>
<li><em>内部实现</em>：<ul>
<li><code>压缩列表</code>：列表元素小于 512 个，且都小于 64 字节</li>
<li><code>哈希表</code>：不满足以上</li>
<li><code>listpack</code>：Redis7.0 版本后</li>
</ul>
</li>
<li><em>使用场景</em>：缓存对象，比如实现购物车<h4 id="2-1-4-Set"><a href="#2-1-4-Set" class="headerlink" title="2.1.4 Set"></a>2.1.4 Set</h4></li>
<li><em>介绍</em>：无序并唯一的键值集合  2^32-1</li>
<li><em>内部实现</em>：<ul>
<li><code>整数集合</code>：列表元素小于 512 个，且都是整数</li>
<li><code>哈希表</code>：不满足以上</li>
</ul>
</li>
<li><em>使用场景</em>：点赞，共同关注（交集），抽奖<h4 id="2-1-5-ZSet"><a href="#2-1-5-ZSet" class="headerlink" title="2.1.5 ZSet"></a>2.1.5 ZSet</h4></li>
<li><em>介绍</em>：有序并唯一的键值集合，多了排序属性 Score</li>
<li><em>内部实现</em>：<ul>
<li><code>压缩列表</code>：元素小于 128 个，且都小于 64 字节</li>
<li><code>跳表</code>：不满足以上</li>
<li><code>listpack</code>：Redis7.0 版本后，压缩列表废弃了</li>
</ul>
</li>
<li><em>使用场景</em>：排行榜,电话排序</li>
<li><em>复杂度</em>： zrange：O [ (LogN)+M]； ZSCORE：O(1) ；zrank：O(logn)<h4 id="2-1-6-BitMap"><a href="#2-1-6-BitMap" class="headerlink" title="2.1.6 BitMap"></a>2.1.6 BitMap</h4></li>
<li><em>介绍</em>：位图，连续的二进制数组</li>
<li><em>内部实现</em>：<ul>
<li><code>String 类型</code>：String 会保存为二进制的字节数组</li>
</ul>
</li>
<li><em>使用场景</em>：二值统计，签到打卡，用户登录<h3 id="2-2-数据结构"><a href="#2-2-数据结构" class="headerlink" title="2.2 数据结构"></a>2.2 数据结构</h3><h4 id="2-2-1-SDS-简单动态字符串"><a href="#2-2-1-SDS-简单动态字符串" class="headerlink" title="2.2.1 SDS 简单动态字符串"></a>2.2.1 SDS 简单动态字符串</h4></li>
<li><em>C 语言字符串的问题</em>：<ul>
<li>获取字符串长度的时间复杂度为 O（N）</li>
<li>字符串的结尾是以 “\0” 字符标识，字符串里面不能包含有 “\0” 字符，因此不能保存二进制数据；</li>
<li>字符串操作函数不高效且不安全，比如有缓冲区溢出的风险，有可能会造成程序运行终止；</li>
</ul>
</li>
<li><em>SDS 结构设计</em><ul>
<li><code>len</code>，记录了字符串长度；<code>alloc</code>，分配给字符数组的空间长度；<code>flags</code>，用来表示不同类型的 SDS; <code>buf[]</code>，字符数组，用来保存实际数据</li>
</ul>
</li>
<li><em>特点</em>：添加了三个元数据解决 C 语言字符串的缺陷，二进制安全，节约内存空间<h4 id="2-2-2-链表"><a href="#2-2-2-链表" class="headerlink" title="2.2.2 链表"></a>2.2.2 链表</h4></li>
<li><em>链表结构设计</em>：添加了前驱指针</li>
<li>3.0 版本前，数据量少的情况下会用压缩列表作为底层结构实现<h4 id="2-2-3-压缩列表"><a href="#2-2-3-压缩列表" class="headerlink" title="2.2.3 压缩列表"></a>2.2.3 压缩列表</h4></li>
<li><em>目的</em>：为了节约内存，由连续内存块组成的顺序型数据结构</li>
<li><em>节点结构设计</em>：<ul>
<li>prevlen，记录了「前一个节点」的长度</li>
<li>encoding，记录了当前节点实际数据的「类型和长度」</li>
<li>data，记录了当前节点的实际数据</li>
</ul>
</li>
<li><em>连锁更新</em>：有多个连续的、长度在 250～253 之间的节点，prelen 会用一个字节保存长度，如果有大于 254 字节的新节点加入，prelen 要扩展到 5 字节，引起连锁更新</li>
<li>quicklist（Redis 3.2 引入） 和 listpack（Redis 5.0 引入）解决连锁更新<h4 id="2-2-4-哈希表"><a href="#2-2-4-哈希表" class="headerlink" title="2.2.4 哈希表"></a>2.2.4 哈希表</h4></li>
<li><em>特点</em>：通过 hash 计算，以 O(1) 的复杂度快速查询数据，通过<code>「链式哈希」</code>来解决哈希冲突</li>
<li><em>结构设计</em>：哈希表是一个<code>数组</code>（dictEntry table），数组的每个元素是一个指向「哈希表节点（dictEntry）」的指针</li>
<li><em>rehash</em>： 渐进式 rehash   <code>触发条件</code>：负载因子大于 1（没有 bgsve） 和 5（强制）<ul>
<li>给「哈希表 2」 分配空间，一般会比「哈希表 1」 大 2 倍</li>
<li>在 rehash 进行期间，每次哈希表元素进行新增、删除、查找或者更新操作时，Redis 除了会执行对应的操作之外，还会顺序将「哈希表 1 」中索引位置上的所有 key-value <code>迁移</code>到「哈希表 2」 上</li>
<li>迁移完成后，「哈希表 1 」的空间会被释放，并把「哈希表 2」 设置为「哈希表 1」，然后在「哈希表 2」 新创建一个空白的哈希表，为下次 rehash 做准备<h4 id="2-2-5-整数集合"><a href="#2-2-5-整数集合" class="headerlink" title="2.2.5 整数集合"></a>2.2.5 整数集合</h4></li>
</ul>
</li>
<li><em>特点</em>：当 Set 对象只包含整数值元素，并且元素数量不大时，就会使用整数集这个数据结构作为底层实现</li>
<li><em>升级</em>：将一个新元素加入到整数集合里面，如果新元素的类型（int32_t）比整数集合现有所有元素的类型（int16_t）都要长时，整数集合需要先进行升级，也就是按<code>新元素的类型</code>（int32_t）扩展 contents 数组的空间大小，然后才能将新元素加入到整数集合里   <code>节省内存资源</code><h4 id="2-2-6-跳表"><a href="#2-2-6-跳表" class="headerlink" title="2.2.6 跳表"></a>2.2.6 跳表</h4><blockquote>
<p>Zset底层包括 跳表和哈希表 实现高效的范围查询和单点查询</p>
</blockquote>
</li>
<li><em>结构设计</em>：在链表基础上实现了一种多层有序链表<ul>
<li>多层级实现：zskiplistLevel 结构体类型的 level 数组</li>
<li>跨度：将沿途所有层的跨度累加就是节点在跳表中的排位</li>
</ul>
</li>
<li><em>节点查询过程</em><ul>
<li>当前节点的权重「小于」要查找的权重时，访问该层的下一个节点</li>
<li>当前节点的权重「等于」要查找的权重时，当前节点的 SDS 类型数据「小于」要查找的数据时，跳表就会访问该层上的下一个节点</li>
<li>都不满足，去下一层继续查找</li>
</ul>
</li>
<li><em>节点层数设置</em>：相邻两层理想比例为 2：1，复杂度为 O(logN)<ul>
<li>在创建节点时候，会生成范围为[0-1]的一个随机数，如果这个随机数小于 0.25（相当于概率 25%），那么层数就增加 1 层，然后继续生成下一个随机数，直到随机数的结果大于 0.25 结束，最终确定该节点的层数</li>
</ul>
</li>
<li><em>为什么不用平衡树</em><ul>
<li><code>内存占用</code>：平衡树每个节点两个指针，跳表只有 1.33</li>
<li><code>范围查询</code>：平衡树需要中序遍历，跳表直接遍历就行</li>
<li><code>实现难度</code>：平衡树插入删除要调整子树，跳表只要调整相邻节点</li>
</ul>
</li>
</ul>
<h4 id="2-2-7-quicklist"><a href="#2-2-7-quicklist" class="headerlink" title="2.2.7 quicklist"></a>2.2.7 quicklist</h4><ul>
<li><em>介绍</em>：3.2后 <code>List</code>对象的底层改由 quicklist 数据结构</li>
<li><em>结构设计</em>：<code>双向链表</code>，链表的元素是<code>压缩列表</code></li>
<li><em>优点</em>：控制每个链表节点中的<code>压缩列表的大小</code>或者元素个数，来规避连锁更新的问题。因为压缩列表元素越少，连锁更新带来的影响就越小，从而提供了更好的访问性能<h4 id="2-2-8-listpack"><a href="#2-2-8-listpack" class="headerlink" title="2.2.8 listpack"></a>2.2.8 listpack</h4></li>
<li><em>介绍</em>：目的是替换压缩列表，每个节点不再包含前一个节点的长度</li>
<li><em>结构设计</em>：借鉴<code>压缩列表</code>设计</li>
<li><em>优点</em>：listpack 只记录当前节点的长度，当我们向 listpack 加入一个新元素的时候，不会影响其他节点的长度字段的变化，从而避免了压缩列表的连锁更新问题</li>
</ul>
<h2 id="3-3-持久化"><a href="#3-3-持久化" class="headerlink" title="3 3.持久化"></a>3 3.持久化</h2><h3 id="3-1-AOF-日志"><a href="#3-1-AOF-日志" class="headerlink" title="3.1 AOF 日志 :"></a>3.1 AOF 日志 :</h3><ol>
<li>实现：先执行写操作命令，然后将命令追加到日志文件</li>
<li>优缺点：不会阻塞当前命令的执行；可能丢失数据</li>
<li>写回策略：<strong>Always</strong> 总是；<strong>Everysec</strong> 每秒；No 操作系统决定</li>
<li><strong>AOF 重写</strong>： <strong>后台子进程 <em>bgrewriteaof</em></strong>； 扫描数据库中所有数据，逐一把内存数据的键值对转换成一条命令，再将命令记录到重写日志； 状态一样,<code>文件体积更小</code><ol>
<li>重写过程中，主进程依然可以正常处理命令</li>
<li>在重写 AOF 期间,将这个写命令写入到 「AOF 缓冲区」和 「AOF 重写缓冲区」</li>
<li>将 AOF 重写缓冲区中的所有内容追加到新的 AOF 的文件中，使得新旧两个 AOF 文件所保存的数据库状态一致<h3 id="3-2-RDB-快照"><a href="#3-2-RDB-快照" class="headerlink" title="3.2 RDB 快照"></a>3.2 RDB 快照</h3>将某一时刻的内存数据，以二进制的方式写入磁盘; </li>
</ol>
</li>
<li>save ：主线程实现，可能阻塞</li>
<li>bgsave： 子进程</li>
<li>写时复制：如果主线程执行写操作，则被修改的数据会复制一份副本，然后 bgsave 子进程会把该副本数据写入 RDB 文件<h3 id="3-3-混合持久化"><a href="#3-3-混合持久化" class="headerlink" title="3.3 混合持久化"></a>3.3 混合持久化</h3>AOF重写时以 RDB 为开头;<strong>前半部分是 RDB 格式的全量数据，后半部分是 AOF 格式的增量数据</strong>。保证了 Redis 重启速度，又降低数据丢失风险。  <h3 id="3-4-大-key-对持久化的影响"><a href="#3-4-大-key-对持久化的影响" class="headerlink" title="3.4 大 key 对持久化的影响"></a>3.4 大 key 对持久化的影响</h3></li>
</ol>
<ul>
<li><em>大 Key 对 AOF 日志的影响</em>：使用 Always 策略的时候，如果写入是一个大 Key，主线程在执行 fsync() 函数的时候，阻塞的时间会比较久，因为当写入的数据量很大的时候，数据同步到硬盘这个过程是很耗时的</li>
<li><em>大 Key 对 AOF 重写和 RDB 的影响</em>：<ul>
<li>创建子进程的途中，由于要复制父进程的页表等数据结构，阻塞的时间跟页表的大小有关，页表越大，阻塞的时间也越长；</li>
<li>创建完子进程后，如果子进程或者父进程修改了共享数据，就会发生写时复制，这期间会拷贝物理内存，如果内存越大，自然阻塞的时间也越长；</li>
</ul>
</li>
<li><em>其他影响</em>：<ul>
<li><code>客户端超时阻塞</code>。由于 Redis 执行命令是单线程处理，然后在操作大 key 时会比较耗时，那么就会阻塞 Redis，从客户端这一视角看，就是很久很久都没有响应。</li>
<li><code>引发网络阻塞</code>。每次获取大 key 产生的网络流量较大，如果一个 key 的大小是 1 MB，每秒访问量为 1000，那么每秒会产生 1000MB 的流量，这对于普通千兆网卡的服务器来说是灾难性的。</li>
<li><code>阻塞工作线程</code>。如果使用 del 删除大 key 时，会阻塞工作线程，这样就没办法处理后续的命令。</li>
<li><code>内存分布不均</code>。集群模型在 slot 分片均匀情况下，会出现数据和查询倾斜情况，部分有大 key 的 Redis 节点占用内存多，QPS 也会比较大。</li>
</ul>
</li>
<li>删除用 unlink 进行异步删除<h2 id="4-4-集群"><a href="#4-4-集群" class="headerlink" title="4 4.集群"></a>4 4.集群</h2><h3 id="4-1-主从复制"><a href="#4-1-主从复制" class="headerlink" title="4.1 主从复制"></a>4.1 主从复制</h3><blockquote>
<p>主从之间采用<code>读写分离</code></p>
</blockquote>
</li>
</ul>
<ol>
<li><strong>第一次同步数据</strong>： 使用 <code>replicaof</code> 命令<pre><code> 1. _建立链接、协商同步_：从服务器发送 `psync `要求同步，主服务器回应 `FULLRESYNC`，同步复制的`进度`
 2. _主同步数据给从_：主服务器生成 RBD 文件发送给从服务器，期间执行的命令会写入` replication buffer` 缓冲区
 3. _发送新写操作命令给从_：将缓冲区中的命令发送给从服务器
</code></pre></li>
<li><strong>命令传播</strong>：维护 TCP 长连接</li>
<li>分摊主服务器的压力：从服务器同步给其他</li>
<li><em>增量复制</em>：同步<strong>网络断开</strong>期间的写操作; 环形缓冲区(<strong>repl_backlog_buffer</strong>) 和 <strong>replication offset</strong>标记同步进度<h3 id="4-2-哨兵机制"><a href="#4-2-哨兵机制" class="headerlink" title="4.2 哨兵机制"></a>4.2 哨兵机制</h3></li>
</ol>
<ul>
<li><em>作用</em>：主从节点故障转移；主要负责<code>监控,选主,通知</code></li>
<li><em>判断故障</em>：每隔 1 秒给所有主从节点发送 PING 命令，没有响应就主观下线；　因为可能网络延迟，不一定真的就挂了</li>
<li><em>客观下线</em>：判断主观下线后，哨兵集群进行投票，超过半数同意就判定客观下线；</li>
<li><em>主从故障转移</em>：<pre><code>  1. `Leader选举`：到半数以上的赞成票，作为 leader 实现主从切换
  2. `选出新主节点`：**优先级、复制进度、ID 号**
  3. `将从节点指向新主节点`；通知客户的主节点已更换；将旧主节点变为从节
  4. `通知客户的主节点已更换`
</code></pre></li>
<li>哨兵集群组成：通过 Redis 的发布者/订阅者机制来相互发现；10 秒一次的频率向主节点发送 INFO 命令来获取所有「从节点」的信息<h3 id="4-3-脑裂"><a href="#4-3-脑裂" class="headerlink" title="4.3 脑裂"></a>4.3 脑裂</h3></li>
<li>由于网络问题，集群节点之间失去联系。主从数据不同步；重新平衡选举，产生两个主服务。等网络恢复，旧主节点会降级为从节点，再与新主节点进行同步复制的时候，由于会从节点会清空自己的缓冲区，所以导致之前客户端写入的数据丢失了。</li>
<li><strong>主节点连接的从节点中至少有 N 个从节点，「并且」主节点进行数据复制时的 ACK 消息延迟不能超过 T 秒</strong>，否则，主节点就不会再接收客户端的写请求了。</li>
<li>等到新主节点上线时，就只有新主节点能接收和处理客户端请求，此时，新写的数据会被直接写到新主节点中。而原主节点会被哨兵降为从节点，即使它的数据被清空了，也不会有新数据丢失。<h2 id="5-过期删除和内存淘汰"><a href="#5-过期删除和内存淘汰" class="headerlink" title="5 过期删除和内存淘汰"></a>5 过期删除和内存淘汰</h2><blockquote>
<p>过期删除策略是删除已经过期的 key，当 Redis 的运行内存超过最大内存后，会用内存淘汰策略删除符合条件的 key</p>
<h3 id="5-1-过期删除策略"><a href="#5-1-过期删除策略" class="headerlink" title="5.1 过期删除策略"></a>5.1 过期删除策略</h3></blockquote>
</li>
<li>可以给 key 设置过期时间，会有个过期字典保存所有 key 的过期时间</li>
<li><em>定时删除</em>：在设置 key 的过期时间时，同时创建一个定时事件，当时间到达时，由事件处理器自动执行 key 的删除操作；<code>内存友好但是 CPU 不友好</code></li>
<li><em>惰性删除</em>：不主动删除过期键，每次从数据库访问 key 时，都检测 key 是否过期，如果过期则删除该 key。<code>CPU友好但是内存不友好</code></li>
<li><em>定期删除</em>：每隔一段时间「随机」从数据库中取出一定数量的 key 进行检查，并删除其中的过期key</li>
<li><em>Redis 的策略</em>：「惰性删除+定期删除」配和使用<h3 id="5-2-内存淘汰策略"><a href="#5-2-内存淘汰策略" class="headerlink" title="5.2 内存淘汰策略"></a>5.2 内存淘汰策略</h3></li>
<li>不进行数据淘汰的策略：直接返回错误</li>
<li>进行数据淘汰的策略<ul>
<li>在设置了过期时间的数据中进行淘汰<ul>
<li>随机； 最久未使用； 最少使用；更早过期</li>
</ul>
</li>
<li>在所有数据范围内进行淘汰<ul>
<li>随机； 最久未使用； 最少使用<h2 id="6-缓存设计"><a href="#6-缓存设计" class="headerlink" title="6 缓存设计"></a>6 缓存设计</h2><h3 id="6-1-缓存雪崩"><a href="#6-1-缓存雪崩" class="headerlink" title="6.1 缓存雪崩"></a>6.1 缓存雪崩</h3></li>
</ul>
</li>
</ul>
</li>
<li><em>现象</em>：大量缓存数据在同一时间过期（失效）或者 Redis 故障宕机，请求全部直接访问数据库，导致系统崩溃</li>
<li><em>解决过期</em>：<ul>
<li><code>均匀设置过期时间</code>：过期时间加上一个随机数    </li>
<li><code>互斥锁</code>：如果发现访问的数据不在 Redis 里，就加个互斥锁，保证同一时间内只有一个请求来构建缓存</li>
<li><code>双 key 策略</code>：</li>
<li><code>后台更新缓存</code>：让缓存“永久有效”，并将更新缓存的工作交由后台线程定时更新</li>
</ul>
</li>
<li><em>解决宕机</em>：服务熔断或请求限流机制；Redis 缓存高可靠集群<h3 id="6-2-缓存击穿"><a href="#6-2-缓存击穿" class="headerlink" title="6.2 缓存击穿"></a>6.2 缓存击穿</h3></li>
<li><em>现象</em>：某个热点数据过期，大量请求访问该数据，直接打到了数据库中</li>
<li><em>解决</em><ul>
<li><code>互斥锁</code>：同一时间只有一个业务线程更新缓存，未能获取互斥锁的请求，要么等待锁释放后重新读取缓存，要么就返回空值或者默认值</li>
<li>不给热点数据设置过期时间，由后台异步更新缓存，或者在热点数据准备要过期前，提前通知后台线程更新缓存以及重新设置过期时间<h3 id="6-3-缓存穿透"><a href="#6-3-缓存穿透" class="headerlink" title="6.3 缓存穿透"></a>6.3 缓存穿透</h3></li>
</ul>
</li>
<li><em>现象</em>： 请求的数据<strong>既不在缓存中，也不在数据库中</strong>请求全到数据库</li>
<li><em>解决</em>：<ul>
<li>限制<code>非法请求</code></li>
<li>出现缓存穿透，可以<code>缓存空值或者默认值</code></li>
<li>使用<code>布隆过滤器</code>快速判断数据是否存在</li>
</ul>
</li>
<li><em>布隆过滤器</em>  [[布隆过滤器]]<h3 id="6-4-数据库和缓存一致性"><a href="#6-4-数据库和缓存一致性" class="headerlink" title="6.4 数据库和缓存一致性"></a>6.4 数据库和缓存一致性</h3></li>
<li>先更新数据库还是缓存？<ul>
<li>先更新数据库，再更新缓存：在并发情况下同时更新一个数据可能导致数据不一致</li>
<li>先更新缓存，再更新数据库：也可能因为并发导致不一致</li>
</ul>
</li>
<li>先更新数据库还是先删除缓存？  <code>旁路缓存策略（Cache Aside）</code><ul>
<li><em>先删除缓存，再更新数据库</em>：可能会在缓存删除且数据库没更新时出现问题</li>
<li><strong><em>先更新数据库，再删除缓存</em></strong>：理论上会出现不一致（请求 B 在请求 A 没写入缓存前更新了数据并删除了缓存），但是因为缓存的写入快于数据库的写入，出现概率不高；为了确保，还可以加上<code>过期时间</code>或者选择延迟双删</li>
<li><code>延迟双删</code>：先删缓存，然后更新数据库，等一会再删除缓存</li>
</ul>
</li>
<li>怎么保证更新数据库和删除缓存成功？<ul>
<li><code>重试机制</code>：用<code>消息队列</code>进行重试</li>
<li><code>订阅 binlog</code>：Canal，订阅日志拿到要操作的数据再执行缓存删除</li>
<li>都是<code>异步</code>操作缓存<h2 id="7-其他"><a href="#7-其他" class="headerlink" title="7 其他"></a>7 其他</h2><h3 id="7-1-redis分布式锁"><a href="#7-1-redis分布式锁" class="headerlink" title="7.1 redis分布式锁"></a>7.1 redis分布式锁</h3></li>
</ul>
</li>
</ul>
<ol>
<li>SET 命令有个 NX 参数可以实现「key不存在才插入」</li>
<li>缺点：主从复制模式中的数据是异步复制的，这样导致分布式锁的不可靠性</li>
<li>分布式锁算法 Redlock（红锁）：客户端和多个独立的 Redis 节点依次请求申请加锁，在加锁超时时间内获得半数以上的节点的锁，就获得分布式锁，否则加锁失败。  </li>
<li>使用 redis 做分布式锁怎么做？如何保证set key 和设置过期时间的原子性？除了 lua 脚本有没有其他方法？</li>
<li><p>Redis 分布式锁 如果watch dog续期线程阻塞了 导致锁释放，锁不安全了怎么办，或者续期次数到达限制 任务还没执行完怎么办（数据库乐观锁保证只有一条数据成功）</p>
<h3 id="7-2-实现一个延迟队列"><a href="#7-2-实现一个延迟队列" class="headerlink" title="7.2 实现一个延迟队列"></a>7.2 实现一个延迟队列</h3></li>
<li><p>使用有序集合（ZSet）的方式来实现 score 记录延迟的时间</p>
</li>
<li>如果想重复消费？</li>
</ol>

    
    
  </div>

  

  

</article>
  
    
  <nav class="pagination">  
      
      <a class="prev" href="/page/5/">  
        <i class="iconfont icon-left"></i>  
        <span class="prev-text">Prev</span>  
      </a>  
      
      
  </nav>  
  

  
</section>
        </div>
      </div>
    </main>
    <footer id="footer" class="footer">
      <!-- Social Links -->

<div class="social-links">
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  

  
  <a href="/atom.xml" class="iconfont icon-rss" title="rss"></a>
  
</div>



<div class="copyright">
  <span class="power-by">
    Powered by <a class="hexo-link" target="_blank" rel="noopener" href="https://hexo.io/">Hexo</a>
  </span>
  <span class="division">|</span>
  <span class="theme-info">
    Theme -
    <a class="theme-link" target="_blank" rel="noopener" href="https://github.com/ahonn/hexo-theme-even">Even</a>
  </span>
  <span class="division">|</span>
  <span class="hosting-info">
    footer.hosting
  </span>

  <span class="copyright-year">
    <span>
      
      &copy;
      
      2019 - 2025      
    </span>

    <span class="heart">
      <i class="iconfont icon-heart"></i>
    </span>

    <span class="author">draco</span>
  </span>

</div>
    </footer>
    <div class="back-to-top" id="back-to-top"> <i class="iconfont icon-up"></i> </div>
  </div>
  







<script type="text/javascript" src="/lib/jquery/jquery.min.js"></script>



<script type="text/javascript" src="/lib/slideout/slideout.js"></script>



<script type="text/javascript" src="/lib/fancybox/jquery.fancybox.pack.js"></script>



  <script type="text/javascript" src="/js/src/even.js?v=3.0.0"></script>
</body>

</html>