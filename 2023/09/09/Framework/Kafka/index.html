<!DOCTYPE html>
<html lang="en">

<head>
  <!-- Website mata -->
<meta charset="UTF-8" />
<meta http-equiv="X-UA-Compatible" content="IE=edge" />
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1" />

<!-- Disable transformation -->
<meta http-equiv="Cache-Control" content="no-transform" />
<meta http-equiv="Cache-Control" content="no-siteapp" />

<meta name="theme-color" content="#f8f5ec" />
<meta name="msapplication-navbutton-color" content="#f8f5ec">
<meta name="apple-mobile-web-app-capable" content="yes">
<meta name="apple-mobile-web-app-status-bar-style" content="#f8f5ec">

<!-- Website description -->


<!-- Website keywords -->




<!-- Website rss -->

<link rel="alternate" href="/atom.xml" title="Draco's Blog" type="application/atom+xml">


<!-- Website favicon -->

<link rel="shortcut icon" type="image/x-icon" href="/favicon.ico?v=3.0.0" />


<!-- Canonical, good for google search engine -->
<link rel="canonical" href="https://stardustorz.github.io/2023/09/09/Framework/Kafka/" />

<!-- Fancybox styling -->

<link rel="stylesheet" type="text/css" href="/lib/fancybox/jquery.fancybox.css" />


<!-- MathJax (LaTeX) support -->


<!-- Theme styling -->
<link rel="stylesheet" type="text/css" href="/css/style.css?v=3.0.0" />

<!-- Analytics and push -->



  



<!-- LeanCloud Counter -->


<script>
  window.config = {"leancloud":{"app_id":null,"app_key":null,"server_url":null,"cdn":null},"toc":true,"fancybox":true,"latex":false};
</script>
  
  <title> - Draco&#39;s Blog</title>

<meta name="generator" content="Hexo 6.3.0"></head>

<body>
  <div class="scrollPercentage"></div>
  <div id="mobile-navbar" class="mobile-navbar">
  <div class="mobile-header-logo">
    <a href="/." class="logo">Draco&#39;s Blog</a>
  </div>
  <div class="mobile-navbar-icon">
    <span></span>
    <span></span>
    <span></span>
  </div>
</div>

<nav id="mobile-menu" class="mobile-menu slideout-menu">
  <ul class="mobile-menu-list">
    
    <a href="/">
      <li class="mobile-menu-item">
        
        
        Home              </li>
    </a>
    
    <a href="/archives/">
      <li class="mobile-menu-item">
        
        
        Archives              </li>
    </a>
    
    <a href="/tags/">
      <li class="mobile-menu-item">
        
        
        Tags              </li>
    </a>
    
    <a href="/categories/">
      <li class="mobile-menu-item">
        
        
        Categories              </li>
    </a>
    
    <a href="/links/">
      <li class="mobile-menu-item">
        
        
        Links              </li>
    </a>
    
    <a href="/about/">
      <li class="mobile-menu-item">
        
        
        About              </li>
    </a>
    
  </ul>
</nav>
  <div class="container" id="mobile-panel">
    <header id="header" class="header">
      <div class="logo-wrapper">  
  <a href="/." class="logo">Draco's Blog</a>  
</div>  
  
<nav class="site-navbar">  
    
    <ul id="menu" class="menu">  
        
        <li class="menu-item">  
          <a class="menu-item-link" href="/">  
              
              
              Home  
              
          </a>  
        </li>  
        
        <li class="menu-item">  
          <a class="menu-item-link" href="/archives/">  
              
              
              Archives  
              
          </a>  
        </li>  
        
        <li class="menu-item">  
          <a class="menu-item-link" href="/tags/">  
              
              
              Tags  
              
          </a>  
        </li>  
        
        <li class="menu-item">  
          <a class="menu-item-link" href="/categories/">  
              
              
              Categories  
              
          </a>  
        </li>  
        
        <li class="menu-item">  
          <a class="menu-item-link" href="/links/">  
              
              
              Links  
              
          </a>  
        </li>  
        
        <li class="menu-item">  
          <a class="menu-item-link" href="/about/">  
              
              
              About  
              
          </a>  
        </li>  
        
    </ul>  
    
</nav>  

    </header>
    <main id="main" class="main">
      <div class="content-wrapper">
        <div id="content" class="content">
          <article class="post">
  <header class="post-header">
    <h1 class="post-title">
      
      
      
    </h1>

    <div class="post-meta">
      <span class="post-time">
        2023-09-09
      </span>
      
      
      
    </div>
  </header>

  
  <div class="post-toc" id="post-toc">
    <h2 class="post-toc-title">Contents</h2>
    <div class="post-toc-content">
      <ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#Kafka-%E5%9F%BA%E7%A1%80"><span class="toc-number">1.</span> <span class="toc-text">Kafka 基础</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#1-%E6%9E%B6%E6%9E%84"><span class="toc-number">1.1.</span> <span class="toc-text">1 架构</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2-%E7%89%B9%E7%82%B9"><span class="toc-number">1.2.</span> <span class="toc-text">2 特点</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#3-%E6%80%8E%E4%B9%88%E5%AE%9E%E7%8E%B0%E9%AB%98%E5%90%9E%E5%90%90%E9%87%8F%E7%9A%84%EF%BC%9F"><span class="toc-number">1.3.</span> <span class="toc-text">3 怎么实现高吞吐量的？</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#4-%E9%AB%98%E5%8F%AF%E9%9D%A0%E6%80%A7%E5%AE%9E%E7%8E%B0"><span class="toc-number">1.4.</span> <span class="toc-text">4 高可靠性实现</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#5-%E4%BD%BF%E7%94%A8%E5%9C%BA%E6%99%AF"><span class="toc-number">1.5.</span> <span class="toc-text">5 使用场景</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%B8%BB%E9%A2%98%E4%B8%8E%E6%97%A5%E5%BF%97"><span class="toc-number">2.</span> <span class="toc-text">主题与日志</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#1-Kafka%E5%88%9B%E5%BB%BATopic%E6%97%B6%E5%A6%82%E4%BD%95%E5%B0%86%E5%88%86%E5%8C%BA%E6%94%BE%E7%BD%AE%E5%88%B0%E4%B8%8D%E5%90%8C%E7%9A%84Broker%E4%B8%AD"><span class="toc-number">2.1.</span> <span class="toc-text">1 Kafka创建Topic时如何将分区放置到不同的Broker中</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2-Kafka-%E5%88%86%E5%8C%BA%E6%95%B0%E5%8F%AF%E4%BB%A5%E5%A2%9E%E5%8A%A0%E6%88%96%E5%87%8F%E5%B0%91%E5%90%97%EF%BC%9F%E4%B8%BA%E4%BB%80%E4%B9%88%EF%BC%9F"><span class="toc-number">2.2.</span> <span class="toc-text">2 Kafka 分区数可以增加或减少吗？为什么？</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#3-kafka%E5%88%86%E5%8C%BA%E6%98%AF%E4%B8%8D%E6%98%AF%E8%B6%8A%E5%A4%9A%E8%B6%8A%E5%A5%BD"><span class="toc-number">2.3.</span> <span class="toc-text">3 kafka分区是不是越多越好</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Producer"><span class="toc-number">3.</span> <span class="toc-text">Producer</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#1-%E6%B6%88%E6%81%AF%E5%88%86%E5%8C%BA%E9%80%89%E6%8B%A9"><span class="toc-number">3.1.</span> <span class="toc-text">1 消息分区选择</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2-Kafka-%E5%88%86%E5%8C%BA%E7%9A%84%E7%9B%AE%E7%9A%84%EF%BC%9F"><span class="toc-number">3.2.</span> <span class="toc-text">2 Kafka 分区的目的？</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#3-ack%E5%8F%82%E6%95%B0%E8%AE%BE%E7%BD%AE%E5%8F%8A%E6%84%8F%E4%B9%89"><span class="toc-number">3.3.</span> <span class="toc-text">3 ack参数设置及意义</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#4-%E5%B9%82%E7%AD%89%E7%89%B9%E6%80%A7"><span class="toc-number">3.4.</span> <span class="toc-text">4 幂等特性</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#5-Kafka-%E6%98%AF%E5%A6%82%E4%BD%95%E5%81%9A%E5%88%B0%E6%B6%88%E6%81%AF%E7%9A%84%E6%9C%89%E5%BA%8F%E6%80%A7%EF%BC%9F"><span class="toc-number">3.5.</span> <span class="toc-text">5 Kafka 是如何做到消息的有序性？</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#6-Kafka%E5%A6%82%E4%BD%95%E4%BF%9D%E8%AF%81%E6%B6%88%E6%81%AF%E4%B8%8D%E4%B8%A2%E5%A4%B1"><span class="toc-number">3.6.</span> <span class="toc-text">6 Kafka如何保证消息不丢失</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#7-Kafka-Producer-%E7%9A%84%E6%89%A7%E8%A1%8C%E8%BF%87%E7%A8%8B%EF%BC%9F"><span class="toc-number">3.7.</span> <span class="toc-text">7 Kafka Producer 的执行过程？</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#8-Kafka%E6%B6%88%E6%81%AF%E6%98%AF%E9%87%87%E7%94%A8Pull%E6%A8%A1%E5%BC%8F%EF%BC%8C%E8%BF%98%E6%98%AFPush%E6%A8%A1%E5%BC%8F%EF%BC%9F"><span class="toc-number">3.8.</span> <span class="toc-text">8 Kafka消息是采用Pull模式，还是Push模式？</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#9-%E5%A6%82%E4%BD%95%E4%BF%9D%E8%AF%81%E6%B6%88%E6%81%AF%E4%B8%8D%E8%A2%AB%E9%87%8D%E5%A4%8D%E6%B6%88%E8%B4%B9%EF%BC%9F"><span class="toc-number">3.9.</span> <span class="toc-text">9 如何保证消息不被重复消费？</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Consumer"><span class="toc-number">4.</span> <span class="toc-text">Consumer</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#1-%E6%B6%88%E8%B4%B9%E7%BB%84"><span class="toc-number">4.1.</span> <span class="toc-text">1 消费组</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2-%E9%87%8D%E5%B9%B3%E8%A1%A1%E6%9C%BA%E5%88%B6"><span class="toc-number">4.2.</span> <span class="toc-text">2 重平衡机制</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#3-Kafka-%E6%B6%88%E8%B4%B9%E8%80%85%E6%98%AF%E5%90%A6%E5%8F%AF%E4%BB%A5%E6%B6%88%E8%B4%B9%E6%8C%87%E5%AE%9A%E5%88%86%E5%8C%BA%E6%B6%88%E6%81%AF%EF%BC%9F"><span class="toc-number">4.3.</span> <span class="toc-text">3 Kafka 消费者是否可以消费指定分区消息？</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#4-%E8%AE%B2%E4%B8%80%E4%B8%8B-Kafka-Consumer-%E6%B6%88%E8%B4%B9%E6%B6%88%E6%81%AF%E6%97%B6%E7%9A%84%E7%BA%BF%E7%A8%8B%E6%A8%A1%E5%9E%8B%EF%BC%8C%E4%B8%BA%E4%BD%95%E5%A6%82%E6%AD%A4%E8%AE%BE%E8%AE%A1%EF%BC%9F"><span class="toc-number">4.4.</span> <span class="toc-text">4 讲一下 Kafka Consumer 消费消息时的线程模型，为何如此设计？</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%89%AF%E6%9C%AC"><span class="toc-number">5.</span> <span class="toc-text">副本</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#1-ISR%E9%9B%86%E5%90%88-AR-OSR"><span class="toc-number">5.1.</span> <span class="toc-text">1 ISR集合,AR,OSR</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2-HW-amp-LEO"><span class="toc-number">5.2.</span> <span class="toc-text">2 HW&amp;LEO</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#3-leader-epoch%E6%9C%BA%E5%88%B6"><span class="toc-number">5.3.</span> <span class="toc-text">3 leader epoch机制</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%8B%BE%E9%81%97"><span class="toc-number">6.</span> <span class="toc-text">拾遗</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#1-%E9%99%A4%E4%BA%86kafka-%E8%BF%98%E7%94%A8%E8%BF%87%E5%93%AA%E4%BA%9B%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97-%E4%BB%96%E5%92%8Ckafka-%E6%9C%89%E5%93%AA%E4%BA%9B%E5%8C%BA%E5%88%AB%EF%BC%8C%E4%BC%98%E5%8A%A3"><span class="toc-number">6.1.</span> <span class="toc-text">1 除了kafka 还用过哪些消息队列 他和kafka 有哪些区别，优劣</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2-Kafka-%E9%AB%98%E6%95%88%E6%96%87%E4%BB%B6%E5%AD%98%E5%82%A8%E8%AE%BE%E8%AE%A1%E7%89%B9%E7%82%B9"><span class="toc-number">6.2.</span> <span class="toc-text">2 Kafka 高效文件存储设计特点</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#3-Kafka-%E6%95%B0%E6%8D%AE%E4%B8%80%E8%87%B4%E6%80%A7%E5%8E%9F%E7%90%86"><span class="toc-number">6.3.</span> <span class="toc-text">3 Kafka 数据一致性原理</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#4-%E6%95%B0%E6%8D%AE%E4%BC%A0%E8%BE%93%E7%9A%84%E4%BA%8B%E5%8A%A1%E6%9C%89%E5%87%A0%E7%A7%8D%EF%BC%9F"><span class="toc-number">6.4.</span> <span class="toc-text">4 数据传输的事务有几种？</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#5-kafka%E4%B8%BA%E4%BB%80%E4%B9%88%E4%B8%8D%E9%9C%80%E8%A6%81%E6%94%AF%E6%8C%81%E8%AF%BB%E5%86%99%E5%88%86%E7%A6%BB"><span class="toc-number">6.5.</span> <span class="toc-text">5 kafka为什么不需要支持读写分离</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#6-Kafka-%E4%B8%AD-zookeeper-%E7%9A%84%E4%BD%9C%E7%94%A8%EF%BC%9F%E5%AE%83%E6%98%AF%E5%A6%82%E4%BD%95%E4%BF%9D%E8%AF%81-kafka-%E9%AB%98%E5%8F%AF%E7%94%A8%E7%9A%84%EF%BC%9F%E4%B8%BB%E8%8A%82%E7%82%B9%E9%80%89%E4%B8%BE%E6%9C%BA%E5%88%B6%EF%BC%9F"><span class="toc-number">6.6.</span> <span class="toc-text">6 Kafka 中 zookeeper 的作用？它是如何保证 kafka 高可用的？主节点选举机制？</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#7-%E4%BD%BF%E7%94%A8-kafka-%E7%9A%84%E6%97%B6%E5%80%99%EF%BC%8C%E5%A6%82%E4%BD%95%E7%A1%AE%E5%AE%9A%E4%B8%80%E4%B8%AA-topic-%E7%9A%84-partition-%E6%95%B0%E9%87%8F%EF%BC%9F"><span class="toc-number">6.7.</span> <span class="toc-text">7 使用 kafka 的时候，如何确定一个 topic 的 partition 数量？</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#8-kafka%E6%B6%88%E6%81%AF%E7%A7%AF%E5%8E%8B%E5%A6%82%E4%BD%95%E5%A4%84%E7%90%86"><span class="toc-number">6.8.</span> <span class="toc-text">8 kafka消息积压如何处理</span></a></li></ol></li></ol>
    </div>
  </div>
  

  <div class="post-content">
    
    <figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"></span><br></pre></td></tr></table></figure>
<h2 id="Kafka-基础"><a href="#Kafka-基础" class="headerlink" title="Kafka 基础"></a>Kafka 基础</h2><h3 id="1-架构"><a href="#1-架构" class="headerlink" title="1 架构"></a>1 架构</h3><blockquote>
<p>分布式的、分区化、可复制提交的日志服务<br><img src="https://pic1.zhimg.com/80/v2-672b6f858c187b5c8182c553cd597f14_1440w.webp" alt=""></p>
<ul>
<li><em>Producer</em>：消息生产者，就是向 kafka broker 发消息的客户端。</li>
<li><em>Consumer</em> ：消息消费者，向 kafka broker 取消息的客户端。</li>
<li><em>Topic</em> ：可以理解为一个队列，一个 Topic 又分为一个或多个分区。</li>
<li><em>Consumer Group</em>：这是 kafka 用来实现一个 topic 消息的广播（发给所有的 consumer）和单播（发给任意一个 consumer）的手段。一个 topic 可以有多个 Consumer Group。</li>
<li><em>Broker</em> ：一台 kafka 服务器就是一个 broker。一个集群由多个 broker 组成。一个 broker 可以容纳多个 topic。</li>
<li><em>Partition</em>：为了实现扩展性，一个非常大的 topic 可以分布到多个 broker上，每个 partition 是一个有序的队列。partition 中的每条消息都会被分配一个有序的id（offset）。将消息发给 consumer，kafka 只保证按一个 partition 中的消息的顺序，不保证一个 topic 的整体（多个 partition 间）的顺序。</li>
<li><em>Offset</em>：kafka 的存储文件都是按照 offset.kafka 来命名，用 offset 做名字的好处是方便查找。例如你想找位于 2049 的位置，只要找到 2048.kafka 的文件即可。当然 the first offset 就是00000000000.kafka。<h3 id="2-特点"><a href="#2-特点" class="headerlink" title="2 特点"></a>2 特点</h3></li>
<li><em>高吞吐量、低延迟</em>：每秒可以处理几十万条消息，它的延迟最低只有几毫秒，每个topic可以分多个partition, consumer group 对partition进行consume操作。</li>
<li><em>可扩展性</em>：kafka集群支持热扩展</li>
<li><em>持久性、可靠性</em>：消息被持久化到本地磁盘，并且支持数据备份防止数据丢失</li>
<li><em>容错性</em>：允许集群中节点失败（若副本数量为n,则允许n-1个节点失败）</li>
<li><em>高并发</em>：支持数千个客户端同时读写<h3 id="3-怎么实现高吞吐量的？"><a href="#3-怎么实现高吞吐量的？" class="headerlink" title="3 怎么实现高吞吐量的？"></a>3 怎么实现高吞吐量的？</h3></li>
<li><em>分区</em>：多分区通过负载均衡提高了消息并发写入和消费的能力</li>
<li><em>批量发送和压缩消息</em>：<ul>
<li><code>批量发送</code>：将消息缓存在内存中的双端队列中，然后Sender线程将从各分区对应的队列中获取已准备好的消息批次，将消息进行批量发送，减少网络传输频次，提高传输效率。</li>
<li><code>端到端压缩消息</code>：将一批消息打包后进行压缩，在 Consumer 端进行解压</li>
</ul>
</li>
<li><em>顺序读写</em>：将消息messaga追加到本地磁盘文件的末尾</li>
<li><em>零拷贝ZeroCopy</em>：将数据直接从磁盘文件复制到网卡设备中，避免重新复制数据<ul>
<li>操作系统从磁盘读取数据到内核空间的 pagecache</li>
<li>应用程序读取内核空间的数据到用户空间的缓冲区</li>
<li>应用程序将数据(用户空间的缓冲区)写回内核空间到套接字缓冲区(内核空间)</li>
<li>操作系统将数据从套接字缓冲区(内核空间)复制到通过网络发送的 NIC 缓冲区</li>
</ul>
</li>
<li><em>PageCache</em>：利用了现代操作系统分页存储 Page Cache 来利用内存提高 I/O 效率<h3 id="4-高可靠性实现"><a href="#4-高可靠性实现" class="headerlink" title="4 高可靠性实现"></a>4 高可靠性实现</h3></li>
<li>副本机制</li>
<li><h3 id="5-使用场景"><a href="#5-使用场景" class="headerlink" title="5 使用场景"></a>5 使用场景</h3></li>
<li>日志收集</li>
<li>消息系统</li>
<li>用户活动跟踪<h2 id="主题与日志"><a href="#主题与日志" class="headerlink" title="主题与日志"></a>主题与日志</h2><h3 id="1-Kafka创建Topic时如何将分区放置到不同的Broker中"><a href="#1-Kafka创建Topic时如何将分区放置到不同的Broker中" class="headerlink" title="1 Kafka创建Topic时如何将分区放置到不同的Broker中"></a>1 Kafka创建Topic时如何将分区放置到不同的Broker中</h3></li>
<li>副本因子不能大于 Broker 的个数；</li>
<li>第一个分区（编号为0）的第一个副本放置位置是随机从 brokerList 选择的；</li>
<li>其他分区的第一个副本放置位置相对于第0个分区依次往后移。也就是如果我们有5个 Broker，5个分区，假设第一个分区放在第四个 Broker 上，那么第二个分区将会放在第五个 Broker 上；第三个分区将会放在第一个 Broker 上；第四个分区将会放在第二个 Broker 上，依次类推；</li>
<li>剩余的副本相对于第一个副本放置位置其实是由 nextReplicaShift 决定的，而这个数也是随机产生的<h3 id="2-Kafka-分区数可以增加或减少吗？为什么？"><a href="#2-Kafka-分区数可以增加或减少吗？为什么？" class="headerlink" title="2 Kafka 分区数可以增加或减少吗？为什么？"></a>2 Kafka 分区数可以增加或减少吗？为什么？</h3></li>
<li>可以使用 bin/kafka-topics.sh命令对 Kafka 增加 Kafka 的分区数据，但是 Kafka 不支持减少分区数。</li>
<li>Kafka 分区数据不支持减少是由很多原因的，比如减少的分区其数据放到哪里去？是删除，还是保留？删除的话，那么这些没消费的消息不就丢了。如果保留这些消息如何放到其他分区里面？追加到其他分区后面的话那么就破坏了 Kafka 单个分区的有序性。如果要保证删除分区数据插入到其他分区保证有序性，那么实现起来逻辑就会非常复杂</li>
<li>会在含有分区目录最少的文件夹中创建新的分区目录<h3 id="3-kafka分区是不是越多越好"><a href="#3-kafka分区是不是越多越好" class="headerlink" title="3 kafka分区是不是越多越好"></a>3 kafka分区是不是越多越好</h3></li>
<li>句柄开销过大：每增加一个分区，对应的也会增加一个文件描述符，而一个进程所能支配的文件描述符是有限的，这也就是通常说的文件句柄开销。当分区数量超过进程能支配的文件描述符数量时，将出现 <code>Too many open files</code>错误.</li>
<li>生产端占用内存过大：kafka 发送消息时不是立刻发送的，而是会先将每个分区的消息先进行缓存（缓存区大小由<code>batch.size</code>设置，默认16KB），缓存满了后才会发送消息。分区越多的情况下，分区占用的缓存区也将更大。</li>
<li>影响系统可用性：broker数量一定的情况下，分区数量越大则每个broker 中所拥有的分区leader副本数量也将更多。broker出现故障后需要进行leader角色切换的分区数量会很大，导致故障恢复时间较长。<h2 id="Producer"><a href="#Producer" class="headerlink" title="Producer"></a>Producer</h2><h3 id="1-消息分区选择"><a href="#1-消息分区选择" class="headerlink" title="1 消息分区选择"></a>1 消息分区选择</h3><h3 id="2-Kafka-分区的目的？"><a href="#2-Kafka-分区的目的？" class="headerlink" title="2 Kafka 分区的目的？"></a>2 Kafka 分区的目的？</h3>分区对于 Kafka 集群的好处是：实现负载均衡。分区对于消费者来说，可以提高并发度，提高效率。<h3 id="3-ack参数设置及意义"><a href="#3-ack参数设置及意义" class="headerlink" title="3 ack参数设置及意义"></a>3 ack参数设置及意义</h3>参数设置： 设置 <code>request.required.acks=-1</code> ，只有 ISR 中所有副本都成功写入消息后才认为 kafka 消息成功写入。acks 参数其他配置项意义如下：</li>
<li><code>acks = 1</code>(默认)：分区leader 副本写入成功即认为消息成功写入，只确保leader发送成功</li>
<li><code>acks = 0</code> ：不需要等待任何服务端的响应都可认为消息成功写入，安全性最低但是效率最高。</li>
<li><code>acks = -1/ all</code> ：代表producer往集群发送数据需要所有的follower都完成从leader的同步才会发送下一条，确保 leader发送成功和所有的副本都完成备份。<h3 id="4-幂等特性"><a href="#4-幂等特性" class="headerlink" title="4 幂等特性"></a>4 幂等特性</h3></li>
<li>一次或者多次请求某一个资源对于资源本身应该具有同样的结果</li>
<li><strong>唯一标识</strong>：判断某个请求是否重复，需要有一个唯一性标识，然后服务端就能根据这个唯一标识来判断是否为重复请求。</li>
<li><strong>记录已经处理过的请求</strong>：服务端需要记录已经处理过的请求，然后根据唯一标识来判断是否是重复请求，如果已经处理过，则直接拒绝或者不做任何操作返回成功。</li>
<li>只能保证生产端在单个会话内的幂等，如果生产端因为某些原因意外挂掉然后重启，此时是没办法保证幂等的，因为这时没办法获取到之前的状态信息，即无法做到跨会话级别的幂等。</li>
<li>幂等性不能跨多个主题分区，只能保证单个分区内的幂等，涉及到多个消息分区时，中间的状态并没有同步<h3 id="5-Kafka-是如何做到消息的有序性？"><a href="#5-Kafka-是如何做到消息的有序性？" class="headerlink" title="5 Kafka 是如何做到消息的有序性？"></a>5 Kafka 是如何做到消息的有序性？</h3></li>
<li>kafka 中的每个 partition 中的消息在写入时都是有序的，而且单独一个 partition 只能由一个消费者去消费，可以在里面保证消息的顺序性。但是分区之间的消息是不保证有序的。</li>
<li>设置一个topic一个partition，消费者单线程消费</li>
<li>消息发送指定key，确保相同key的消息发送到同一个partition<h3 id="6-Kafka如何保证消息不丢失"><a href="#6-Kafka如何保证消息不丢失" class="headerlink" title="6 Kafka如何保证消息不丢失"></a>6 Kafka如何保证消息不丢失</h3></li>
<li><em>生产者</em>：ACK 机制</li>
<li><em>broker</em>：多副本和副本同步机制；保证ISR副本数量大于等于二</li>
<li><em>消费者</em>：<ul>
<li>消息消费关闭自动提交，改为手动提交offset，确保消息可再次消费</li>
<li>在第一点的前提下，涉及到消息的重复消费，所以消费端应做好消息的幂等处理<h3 id="7-Kafka-Producer-的执行过程？"><a href="#7-Kafka-Producer-的执行过程？" class="headerlink" title="7 Kafka Producer 的执行过程？"></a>7 Kafka Producer 的执行过程？</h3></li>
</ul>
</li>
<li>Producer生产消息</li>
<li>从Zookeeper找到Partition的Leader</li>
<li>推送消息</li>
<li>通过ISR列表通知给Follower</li>
<li>Follower从Leader拉取消息，并发送ack</li>
<li>Leader收到所有副本的ack，更新Offset，并向Producer发送ack，表示消息写入成功。<h3 id="8-Kafka消息是采用Pull模式，还是Push模式？"><a href="#8-Kafka消息是采用Pull模式，还是Push模式？" class="headerlink" title="8 Kafka消息是采用Pull模式，还是Push模式？"></a>8 Kafka消息是采用Pull模式，还是Push模式？</h3></li>
<li>producer将消息推送到broker，consumer从broker拉取消息</li>
<li>consumer可以自主的根据消费能力和策略决定是否批量的从broker拉取数据<h3 id="9-如何保证消息不被重复消费？"><a href="#9-如何保证消息不被重复消费？" class="headerlink" title="9 如何保证消息不被重复消费？"></a>9 如何保证消息不被重复消费？</h3></li>
<li>生产者在向Kafka写数据时，每条消息会有一个offset，表示消息写入顺序的序号。当消费者消费后，<strong>每隔一段时间会把自己已消费消息的offset通过Zookeeper提交给Kafka</strong>，告知Kafka自己offset的位置。这样一来，如果消费者重启，则会从Kafka记录的offset之后的数据开始消费，从而避免重复消费。</li>
<li>在发生重复消费后，如何<strong>保证消息消费时的幂等性</strong>。如果消费者可以在消费消息时先判断一下，自己是否已经消费了该消息，如果是就不消费，那么就可以保证系统的幂等性。<ul>
<li>数据库查询</li>
<li>redis 用 set 去重</li>
<li>全局 id</li>
</ul>
</li>
</ul>
</blockquote>
<h2 id="Consumer"><a href="#Consumer" class="headerlink" title="Consumer"></a>Consumer</h2><h3 id="1-消费组"><a href="#1-消费组" class="headerlink" title="1 消费组"></a>1 消费组</h3><ul>
<li>多个消费者可以组成一个消费组，每个消费者只属于一个消费组。</li>
<li>消费组订阅主题的每个分区只会分配给该消费组中的某个消费者处理，不同的消费组之间彼此隔离无依赖。</li>
<li>同一个消息只会被消费组中的一个消费者消费，如果想要让同一个消息被多个消费者消费，那么每个消费者需要属于不同的消费组，且对应消费组中只有该一个消费者，消费组的引入可以实现消费的“独占”或“广播”效果。<h3 id="2-重平衡机制"><a href="#2-重平衡机制" class="headerlink" title="2 重平衡机制"></a>2 重平衡机制</h3></li>
<li><em>触发条件</em>：<ul>
<li>消费者数量变化： 新消费者加入、消费者下线、消费者主动退出消费组</li>
<li>消费组内订阅的主题或者主题的分区数量发生变化</li>
<li>消费组对应的 GroupCoorinator 节点发生变化</li>
</ul>
</li>
<li><em>rebalance过程</em>：<ul>
<li>寻找到消费组的 协调者(GroupCoordination)，消费者组提交组位移的 partiotion 所在的 broker</li>
<li>所有消费者向协调者发送 JoinGroup 请求</li>
<li>协调者为消费组选择新的leader</li>
<li>协调者发送 <code>JoinGroupResponse</code> 给各个消费组，其中leader消费者的 <code>JoinGroupResponse</code> 包含了消费组成员信息</li>
<li>leader消费者指定新的消费方案</li>
<li>各消费者向 协调者 发送 <code>SyncGroupRequest</code> 请求，其中 leader消费者的<code>SyncGroupRequest</code> 携带有相关的分配方案</li>
<li>协调者向各消费者下发分区分配方案</li>
</ul>
</li>
<li><em>避免非必要rebalance</em> ：设置合理的心跳发送时间；设置Consumer 消费时间最大间隔<h3 id="3-Kafka-消费者是否可以消费指定分区消息？"><a href="#3-Kafka-消费者是否可以消费指定分区消息？" class="headerlink" title="3 Kafka 消费者是否可以消费指定分区消息？"></a>3 Kafka 消费者是否可以消费指定分区消息？</h3>Kafa consumer消费消息时，向broker发出fetch请求去消费特定分区的消息，consumer指定消息在日志中的偏移量（offset），就可以消费从这个位置开始的消息，customer拥有了offset的控制权，可以向后回滚去重新消费之前的消息，这是很有意义的。<h3 id="4-讲一下-Kafka-Consumer-消费消息时的线程模型，为何如此设计？"><a href="#4-讲一下-Kafka-Consumer-消费消息时的线程模型，为何如此设计？" class="headerlink" title="4 讲一下 Kafka Consumer 消费消息时的线程模型，为何如此设计？"></a>4 讲一下 Kafka Consumer 消费消息时的线程模型，为何如此设计？</h3>Thread-Per-Consumer Model，这种多线程模型是利用Kafka的topic分多个partition的机制来实现并行：每个线程都有自己的consumer实例，负责消费若干个partition。各个线程之间是完全独立的，不涉及任何线程同步和同学通信，所以实现起来非常简单。<h2 id="副本"><a href="#副本" class="headerlink" title="副本"></a>副本</h2><h3 id="1-ISR集合-AR-OSR"><a href="#1-ISR集合-AR-OSR" class="headerlink" title="1 ISR集合,AR,OSR"></a>1 ISR集合,AR,OSR</h3></li>
<li><em>In-Sync Replicas 副本同步队列</em>，表示可用的副本集合，也就是和主副本差距不大</li>
<li>ISR 是由 leader 维护，follower从leader 同步数据有一些延迟（包括延迟时间和延迟条数）, 任意一个超过阈值都会把follower剔除出ISR, 存入OSR（Outof-Sync Replicas）列表，新加入的follower也会先存放在OSR中。AR=ISR+OSR</li>
<li>主要是解决<code>同步副本</code>与<code>异步复制</code>两种方案各自的缺陷<h3 id="2-HW-amp-LEO"><a href="#2-HW-amp-LEO" class="headerlink" title="2 HW&amp;LEO"></a>2 HW&amp;LEO</h3></li>
<li>HW（High Watermark）：消费端消费时只能拉取到小于HW的消息而HW及之后的消息对于消费者来说是不可见的，保证HW之前消息的可靠性</li>
<li>LEO（Log End Offset）：表示当前副本最新消息的下一个offset<h3 id="3-leader-epoch机制"><a href="#3-leader-epoch机制" class="headerlink" title="3 leader epoch机制"></a>3 leader epoch机制</h3>leader epoch表示一个键值对<epoch, offset>，其中epoch表示leader主副本的版本号，从0开始编码，当leader每变更一次就会+1，offset表示该epoch版本的主副本写入第一条消息的位置，比如<0,0>表示第一个主副本从位移0开始写入消息，<1,100>表示第二个主副本版本号为1并从位移100开始写入消息，主副本会将该信息保存在缓存中并定期写入到checkpoint文件中，每次发生主副本切换都会去从缓存中查询该信息<h2 id="拾遗"><a href="#拾遗" class="headerlink" title="拾遗"></a>拾遗</h2></li>
</ul>
<h3 id="1-除了kafka-还用过哪些消息队列-他和kafka-有哪些区别，优劣"><a href="#1-除了kafka-还用过哪些消息队列-他和kafka-有哪些区别，优劣" class="headerlink" title="1 除了kafka 还用过哪些消息队列 他和kafka 有哪些区别，优劣"></a>1 除了kafka 还用过哪些消息队列 他和kafka 有哪些区别，优劣</h3><h3 id="2-Kafka-高效文件存储设计特点"><a href="#2-Kafka-高效文件存储设计特点" class="headerlink" title="2 Kafka 高效文件存储设计特点"></a>2 Kafka 高效文件存储设计特点</h3><ul>
<li>Kafka把topic中一个parition大文件分成多个小文件段，通过多个小文件段，就容易定期清除或删除已经消费完文件，减少磁盘占用。</li>
<li>通过索引信息可以快速定位message和确定 response的最大大小。</li>
<li>通过index元数据全部映射到memory，可以避免segment file的IO磁盘操作。</li>
<li>通过索引文件稀疏存储，可以大幅降低 index 文件元数据占用空间大小</li>
</ul>
<h3 id="3-Kafka-数据一致性原理"><a href="#3-Kafka-数据一致性原理" class="headerlink" title="3 Kafka 数据一致性原理"></a>3 Kafka 数据一致性原理</h3><ul>
<li>一致性就是说不论是老的 Leader 还是新选举的 Leader，Consumer 都能读到一样的数据。</li>
<li>假设分区的副本为3，其中副本0是 Leader，副本1和副本2是 follower，并且在 ISR 列表里面。虽然副本0已经写入了 Message4，但是 Consumer 只能读取到 Message2。因为所有的 ISR 都同步了 Message2，只有 High Water Mark 以上的消息才支持 Consumer 读取，而 High Water Mark 取决于 ISR 列表里面偏移量最小的分区，类似于<strong>木桶原理</strong>。</li>
<li>还没有被足够多副本复制的消息被认为是“不安全”的，如果 Leader 发生崩溃，另一个副本成为新 Leader，那么这些消息很可能丢失了。如果我们允许消费者读取这些消息，可能就会破坏一致性。试想，一个消费者从当前 Leader（副本0） 读取并处理了 Message4，这个时候 Leader 挂掉了，选举了副本1为新的 Leader，这时候另一个消费者再去从新的 Leader 读取消息，发现这个消息其实并不存在，这就导致了数据不一致性问题。</li>
</ul>
<h3 id="4-数据传输的事务有几种？"><a href="#4-数据传输的事务有几种？" class="headerlink" title="4 数据传输的事务有几种？"></a>4 数据传输的事务有几种？</h3><ul>
<li>数据传输的事务定义通常有以下三种级别：</li>
<li>最多一次: 消息不会被重复发送，最多被传输一次，但也有可能一次不传输 </li>
<li>最少一次: 消息不会被漏发送，最少被传输一次，但也有可能被重复传输.</li>
<li>精确的一次（Exactly once）: 不会漏传输也不会重复传输,每个消息都传输被</li>
</ul>
<h3 id="5-kafka为什么不需要支持读写分离"><a href="#5-kafka为什么不需要支持读写分离" class="headerlink" title="5 kafka为什么不需要支持读写分离"></a>5 kafka为什么不需要支持读写分离</h3><ul>
<li>读写均衡</li>
<li>分区，压力都不大</li>
</ul>
<h3 id="6-Kafka-中-zookeeper-的作用？它是如何保证-kafka-高可用的？主节点选举机制？"><a href="#6-Kafka-中-zookeeper-的作用？它是如何保证-kafka-高可用的？主节点选举机制？" class="headerlink" title="6 Kafka 中 zookeeper 的作用？它是如何保证 kafka 高可用的？主节点选举机制？"></a>6 Kafka 中 zookeeper 的作用？它是如何保证 kafka 高可用的？主节点选举机制？</h3><ol>
<li>用于在集群中不同节点之间进行通信</li>
<li>提交偏移量</li>
<li>leader 检测、分布式同步、配置管理、识别新节点何时离开或连接、集群、节点实时状态<h3 id="7-使用-kafka-的时候，如何确定一个-topic-的-partition-数量？"><a href="#7-使用-kafka-的时候，如何确定一个-topic-的-partition-数量？" class="headerlink" title="7 使用 kafka 的时候，如何确定一个 topic 的 partition 数量？"></a>7 使用 kafka 的时候，如何确定一个 topic 的 partition 数量？</h3></li>
<li>单台broker上partition数量不超过4000, 整个集群partition数量不超过2000,000</li>
<li>更多的Partition可能导致不可用时间增长；增加端到端的延迟；使用过多的内存<h3 id="8-kafka消息积压如何处理"><a href="#8-kafka消息积压如何处理" class="headerlink" title="8 kafka消息积压如何处理"></a>8 kafka消息积压如何处理</h3></li>
</ol>
<ul>
<li>问题定位：<ul>
<li>消息生产端数据量是否存在陡升的情况</li>
<li>消息消费端消费能力是否有下降</li>
<li>消息积压是发生在所有的partition还是所有的partition都有积压情况</li>
</ul>
</li>
<li>解决：<ul>
<li>前两个可以多线程，批量消费等提高消费速度</li>
<li>后者<ul>
<li>新建一个 topic，partition 是原来的 10 倍，临时建立好原先 10 倍的 queue 数量</li>
<li>然后写一个临时的分发数据的 consumer 程序，这个程序部署上去消费积压的数据，<strong>消费之后不做耗时的处理</strong>，直接均匀轮询写入临时建立好的 10 倍数量的 queue</li>
<li>接着临时征用 10 倍的机器来部署 consumer，每一批 consumer 消费一个临时 queue 的数据。这种做法相当于是临时将 queue 资源和 consumer 资源扩大 10 倍，以正常的 10 倍速度来消费数据</li>
<li>等快速消费完积压数据之后，<strong>得恢复原先部署的架构</strong>，<strong>重新</strong>用原先的 consumer 机器来消费消息</li>
</ul>
</li>
</ul>
</li>
</ul>

    
  </div>

  
  <!-- Post Copyright -->

<div class="post-copyright">
  <p class="copyright-item">
    <span>Author: </span>
    <a href="https://stardustorz.github.io">draco</a>
  </p>
  <p class="copyright-item">
    <span>Link: </span>
    <a href="https://stardustorz.github.io/2023/09/09/Framework/Kafka/">https://stardustorz.github.io/2023/09/09/Framework/Kafka/</a>
  </p>
  <p class="copyright-item">
    <span>License: </span>
    
    <a rel="license" href="http://creativecommons.org/licenses/by-nc/4.0/" target="_blank">知识共享署名-非商业性使用 4.0 国际许可协议</a>
  </p>
</div>

    

  

  
  <footer class="post-footer">
    
      
  <nav class="post-nav">  
      
      <a class="prev" href="/2023/09/10/Framework/MySQL/">  
        <i class="iconfont icon-left"></i>  
        <span class="prev-text nav-default"></span>  
        <span class="prev-text nav-mobile">Prev</span>  
      </a>  
      
      
      <a class="next" href="/2023/09/05/Framework/Redis/">  
        <span class="next-text nav-default"></span>  
        <span class="prev-text nav-mobile">Next</span>  
        <i class="iconfont icon-right"></i>  
      </a>  
      
  </nav>  
  

  </footer>
  

</article>
        </div>
      </div>
    </main>
    <footer id="footer" class="footer">
      <!-- Social Links -->

<div class="social-links">
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  

  
  <a href="/atom.xml" class="iconfont icon-rss" title="rss"></a>
  
</div>



<div class="copyright">
  <span class="power-by">
    Powered by <a class="hexo-link" target="_blank" rel="noopener" href="https://hexo.io/">Hexo</a>
  </span>
  <span class="division">|</span>
  <span class="theme-info">
    Theme -
    <a class="theme-link" target="_blank" rel="noopener" href="https://github.com/ahonn/hexo-theme-even">Even</a>
  </span>
  <span class="division">|</span>
  <span class="hosting-info">
    footer.hosting
  </span>

  <span class="copyright-year">
    <span>
      
      &copy;
      
      2019 - 2025      
    </span>

    <span class="heart">
      <i class="iconfont icon-heart"></i>
    </span>

    <span class="author">draco</span>
  </span>

</div>
    </footer>
    <div class="back-to-top" id="back-to-top"> <i class="iconfont icon-up"></i> </div>
  </div>
  







<script type="text/javascript" src="/lib/jquery/jquery.min.js"></script>



<script type="text/javascript" src="/lib/slideout/slideout.js"></script>



<script type="text/javascript" src="/lib/fancybox/jquery.fancybox.pack.js"></script>



  <script type="text/javascript" src="/js/src/even.js?v=3.0.0"></script>
</body>

</html>