---
title: "[DDIA] 分区"
date: 2023-06-18
tags:
  - DDIA
categories:
  - 阅读笔记
  - DDIA
published: true
toc: "true"
comments: "true"
description:
---
> 解决数据集尺度与单机容量、负载不匹配的问题

<!--more-->

1. **分片（Partition）**：解决数据集尺度与单机容量、负载不匹配的问题，分片之后可以利用多机容量和负载。
2. **复制（Replication**）：系统机器一多，单机故障概率便增大，为了防止数据丢失以及服务高可用，需要做多副本。
通常来说，数据系统在分布式系统中会有三级划分：数据集（如 Database、Bucket）——分片（Partition）——数据条目（Row、KV）。通常，每个分片只属于一个数据集，每个数据条目只属于一个分片。单个分片，就像一个小点的数据库。但是，跨分区的操作的，就要复杂的多。


## 1 分片和复制
分片通常和复制结合使用。每个分片有多个副本，可以分散到多机上去（更泛化一点：多个容错阈）；同时，每个机器含有多个分片，但通常不会有一个分片的两个副本放到一个机器上。
**如果使用多副本使用主从模型，则分片、副本、机器关系如下：**
1. 从一个分片的角度看，主副本在一个机器上，从副本们在另外机器上。
2. 从一个机器的角度看，既有一些主副本分片，也有一些从副本分片。实践中，也会尽量保证主副本在集群中均匀分布，避免过多的集中到一台机器上。

## 2 键值对集的分片
键值对是数据的一种最通用、泛化的表示，其他种类数据库都可以转化为键值对表示
**分片（Partition）** 的本质是对数据集合的划分。但在实践中，可以细分为两个步骤：
1. 对数据集进行**逻辑**划分
2. 将逻辑分片调度到**物理**节点
**一些基本要求：**
1. 分片过程中，要保证每个分片的数据量多少尽量均匀，否则会有**数据偏斜**（**skew**），甚而形成**数据热点**。
2. 分片后，需要保存路由信息，给一个 KV 条目，能知道去**哪个**机器上去查；稍差一些，可以知道去**哪几个**机器上去找；最差的，如果需要去所有机器逐一查询，但性能一般不可接受。


有三种常用的策略：
1. 通过某种固定规则，比如哈希，算出一个位置。
2. 使用内存，保存所有数据条目到机器的映射。
3. 结合两种，首先通过规则算出到逻辑分片的映射，然后通过内存保存逻辑分片到物理节点的映射。

### 2.1 按键范围分区
对于 KV 数据来说，Key 通常会有个定义域，且在定义域内可（按某种维度）排序。则，将该连续的定义域进行切分，保存每个切分的上下界，在给出某个 Key 时，就能通过比较，定位其所在分区。
好处在于可以进行**快速的范围查询（Rang Query）**
坏处在于，数据分散不均匀，且容易造成热点。可能需要动态的调整的分区边界，以维护分片的相对均匀。
一个解决办法是**分级**或者**混合**，使用拼接主键，分散到不同的机器上

### 2.2 按键散列分区
- 选择散列函数的**依据**是，使得数据散列尽量均匀：即给定一个 Key，经过散列函数后，以等概率在哈希区间（如 `[0, 2^32-1)`）内产生一个值。即使原 Key 相似，他的散列值也能均匀分布。
- 选定哈希函数后，将原 Key 定义域映射到新的散列值阈，而散列值是均匀的，因此可以对散列值阈按给定分区数进行等分。
- 还有一种常提的哈希方法叫做[一致性哈希](https://zh.m.wikipedia.org/zh-hans/%E4%B8%80%E8%87%B4%E5%93%88%E5%B8%8C) 。其特点是，会考虑逻辑分片和物理拓扑，将数据和物理节点按同样的哈希函数进行哈希，来决定如何将哈希分片路由到不同机器上。它可以避免在内存中维护**逻辑分片到物理节点的映射**，而是每次计算出来。即用一套算法同时解决了我们在最初提出的逻辑分片和物理路由的两个问题。
两种分区方式区别在于，一个使用应用相关值（ `Key` ）分区，一个使用应用无关值（`Hash(key)`）分区，前者支持高效范围查询，后者可以均摊负载。但可使用多个字段，组合使用两种方式，使用一个字段进行分区，使用另一个字段在分区内进行排序，兼取两者优点。

### 2.3 负载偏斜和热点消除
- 在数据层，可以通过哈希将数据均匀散列，以期将对数据的请求均摊；但如果在应用层，不同数据条目的负载本就有倾斜，存在对某些键的热点。那么仅在数据层哈希，就不能起到消除热点的作用。
	- 在社交网络中的大 V，其发布的信息，天然会引起同一个键（假设键是用户 id）大量数据的写入，因为可能会有针对该用户信息的大量评论和互动。
- 只能在应用层进行热点消除，如可以用拼接主键，对这些大 V 用户主键进行“分身”，即在用户主键开始或者结尾添加一个随机数，两个十进制后缀就可以增加 100 中拆分可能。但这无疑需要应用层做额外的工作，请求时需要进行拆分，返回时需要进行合并。

## 3 分片和次级索引
**次级索引（secondary index）**，即主键以外的列的索引；由于分区都是基于主键的，在针对有分区的数据建立次级索引时，就会遇到一些困难。
常见的建立次级索引的方法有：
1. 本地索引（local index），书中又称 document-based index
2. 全局索引（global index），书中又称 term-based index
### 3.1 本地索引
次级索引会对每个数据条目建立一个索引条目，这给数据库的实现带来了一些问题：
1. 当数据库已有数据时，建立索引，何时针对存量数据构建索引。
2. 当数据库中数据条目发生更改时，如何维护数据和索引的一致性，尤其是多客户端并发修改时。

本地**索引（local index）**，就是对**每个数据分区独立地建立次级索引**，即，次级索引只针对本分区数据，而不关心其他分区数据。本地索引的**优点**是维护方便，在更新数据时，只需要在该分区所在机器同时更新索引即可。但**缺点**是，查询效率相对较低，所有基于索引的查询请求，都要发送到所有分区，并将结果合并，该过程也称为 **scatter/gather** 。但即使用多分区并发（而非顺序）进行索引查询优化，也仍然容易在某些机器上发生**长尾请求**（由于机器负载过高或者网络问题，导致改请求返回特别慢，称为长尾请求），导致整个请求过程变慢。

### 3.2 全局索引
为了避免查询索引时将请求发到所有分区，可以建立**全局索引**，即每个次级索引条目都是针对全局数据。但为了避免索引查询热点，我们会将索引数据本身也分片，分散到多个机器上。

全局索引能避免索引查询时的 scatter/gather 操作，但维护起来较为复杂，因为每个数据的插入，可能会影响多个索引分区

为了避免增加写入延迟，在实践中，全局索引多为异步更新。但由此会带来短暂（有时可能会比较长）的数据和索引不一致。如果想要保证强一致性，需要引入跨分区的分布式事务（实现复杂度高，且会带来较大的性能损耗）

## 4 分片均衡
数据库在运行过程中，数据和机器都会发生一些变化：
1. 查询吞吐增加，需要增加机器以应对增加的负载。
2. 数据集变大，需要增加磁盘和 RAM 来存储增加数据。
3. 有机器故障，需要其他机器来接管故障机器数据。

这些问题都会引起数据分片在节点间的迁移，我们将之称为：**均衡（rebalancing）**。对于 rebalancing 我们期望：
1. 均衡后负载（存储、读写）在节点间均匀分布
2. 均衡时不能禁止读写，并且尽量减小影响
3. 尽量减少不必要的数据移动，尽量降低网络和磁盘 IO

### 4.1 均衡策略
分区策略会影响均衡策略。比如动态分区、静态分区，对应的均衡策略就不太一样；此外，分区的粒度和数量也会影响均衡策略。

### 4.2 不要使用：hash mod N
不能应对机器数量的变化，如果要增删节点，就会有大量的数据需要发生迁移，否则，就不能保证数据在 `hash(key) mod N` 标号的机器上。在大规模集群中，机器节点增删比较频繁，这种策略更是不可接受。

### 4.3 静态分区
静态分区，即，逻辑分区阶段的**分区数量是固定的**，并且最好让分区数量大于（比如高一个数量级）机器节点。相比**动态分区**策略（比如，允许分区分裂和合并），固定数量分区更容易实现和维护。
对于数据量会超预期增长的数据集，静态分区策略就会让用户进退两难，已经有很多数据，重新分区代价很大，不重新分区又难以应对数据量的进一步增长。

### 4.4 动态分区
动态分区好处在于，小数据量使用少量分区，减少开销；大数据量增加分区，以均摊负载。

### 4.5 与节点成比例分区
1. 静态均衡的分区数量一开始就固定的，但是单分区尺寸会随着总数量增大而增大。
2. 动态均衡会按着数据量多少进行动态切合，单分区尺寸相对保持不变，一直于某个设定的上下界。
他们的分区数量都和集群节点数量没有直接关系。而另一种均衡策略，则是保持**总分区数量**和节点数量成正比，也即，保持每个节点分区数量不变。


## 5 请求路由
将分区放到节点上去后，当客户端请求到来时，我们如何决定将请求路由到哪台机器？这势必要求我们**以某种方式**记下：
1. 数据条目到逻辑分区的映射。
2. 逻辑分区到物理机器的映射。

其次，是在哪里记下这些路由（映射）信息，泛化一下，是一个**服务发现**（service discovery）问题。概括来说，由内而外，有几种方案：
1. **每个节点都有全局路由表**。客户端可以连接集群中任意一个节点，如该节点恰有该分区，则处理后返回；否则，根据路由信息，将其路由合适节点。
2. **由一个专门的路由层来记录**。客户端所有请求都打到路由层，路由层依据分区路由信息，将请求转发给相关节点。路由层只负责请求路由，并不处理具体逻辑。
3. **让客户端感知分区到节点映射**。客户端可以直接根据该映射，向某个节点发送请求。

如何让所有节点就路由信息快速达成一致？
- **依赖外部协调组件**。如 Zookeeper、Etcd，他们各自使用某种共识协议保持高可用，可以维护轻量的路由表，并提供发布订阅接口，在有路由信息更新时，让外部所有节点快速达成一致。
- **使用内部元数据服务器**。如三节点的 Meta 服务器，每个节点都存储一份路由数据，使用某种共识协议达成一致。如 TiDB 的 Placement Driver。
- **使用某种协议点对点同步**。如 Dynamo、Cassandra 和 Riak 使用流言协议（Gossip Protocol），在集群内所有机器节点间就路由信息进行传播，并最终达成一致

### 5.1 并行查询执行
对于关系型数据库产品，尤其是支持 **大规模并行处理（MPP, Massively parallel processing）** 数仓，一个查询语句在执行层要复杂的多，可能会：
1. Stage：由多个阶段组成。
2. Partition：每个阶段包含多个针对每个分区的并行的子查询计划。